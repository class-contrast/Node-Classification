{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a698c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea38d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c5ce4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/9e/0d/91a9fd2c202f2b1d97a38ab591890f86480ecbb596cbc56d035f6f23fdcc/pandas-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pandas-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.0.3 pytz-2023.3 tzdata-2023.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6d39db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.1-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from torch)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/00/45/ec3407adf6f6b5bf867a4462b2b0af27597a26bd3cd6e2534cb6ab029938/filelock-3.12.2-py3-none-any.whl.metadata\n",
      "  Downloading filelock-3.12.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch) (4.7.1)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: jinja2 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch)\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch)\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
      "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch)\n",
      "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch)\n",
      "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch)\n",
      "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch)\n",
      "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch)\n",
      "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Collecting triton==2.0.0 (from torch)\n",
      "  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (68.0.0)\n",
      "Requirement already satisfied: wheel in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Collecting cmake (from triton==2.0.0->torch)\n",
      "  Obtaining dependency information for cmake from https://files.pythonhosted.org/packages/2e/51/3a4672a819b4532a378bfefad8f886cfe71057556e0d4eefb64523fd370a/cmake-3.27.2-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading cmake-3.27.2-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting lit (from triton==2.0.0->torch)\n",
      "  Using cached lit-16.0.6.tar.gz (153 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Downloading cmake-3.27.2-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.1/26.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: lit\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-16.0.6-py3-none-any.whl size=93583 sha256=66a7156e8d6396948355b5df3bc1776e86e6a85c570bdc97612331cf158f4554\n",
      "  Stored in directory: /home/bcypher/.cache/pip/wheels/a5/36/d6/cac2e6fb891889b33a548f2fddb8b4b7726399aaa2ed32b188\n",
      "Successfully built lit\n",
      "Installing collected packages: mpmath, lit, cmake, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, networkx, filelock, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
      "Successfully installed cmake-3.27.2 filelock-3.12.2 lit-16.0.6 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 sympy-1.12 torch-2.0.1 triton-2.0.0\n",
      "Collecting torch_geometric\n",
      "  Using cached torch_geometric-2.3.1-py3-none-any.whl\n",
      "Collecting tqdm (from torch_geometric)\n",
      "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch_geometric) (1.23.5)\n",
      "Requirement already satisfied: scipy in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch_geometric) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch_geometric) (2.31.0)\n",
      "Collecting pyparsing (from torch_geometric)\n",
      "  Obtaining dependency information for pyparsing from https://files.pythonhosted.org/packages/39/92/8486ede85fcc088f1b3dba4ce92dd29d126fd96b0008ea213167940a2475/pyparsing-3.1.1-py3-none-any.whl.metadata\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting scikit-learn (from torch_geometric)\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/d4/61/966d3238f6cbcbb13350d31bd0accfc5efdf9e349cd2a42d9761b8b67a18/scikit_learn-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading scikit_learn-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch_geometric) (5.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from jinja2->torch_geometric) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from requests->torch_geometric) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from requests->torch_geometric) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from requests->torch_geometric) (2023.7.22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting joblib>=1.1.1 (from scikit-learn->torch_geometric)\n",
      "  Obtaining dependency information for joblib>=1.1.1 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->torch_geometric)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m463.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m38.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: tqdm, threadpoolctl, pyparsing, joblib, scikit-learn, torch_geometric\n",
      "Successfully installed joblib-1.3.2 pyparsing-3.1.1 scikit-learn-1.3.0 threadpoolctl-3.2.0 torch_geometric-2.3.1 tqdm-4.66.1\n",
      "Collecting ogb\n",
      "  Using cached ogb-1.3.6-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from ogb) (2.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from ogb) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.29.0 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from ogb) (4.66.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from ogb) (1.3.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from ogb) (2.0.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from ogb) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from ogb) (1.26.16)\n",
      "Collecting outdated>=0.2.0 (from ogb)\n",
      "  Using cached outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: setuptools>=44 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from outdated>=0.2.0->ogb) (68.0.0)\n",
      "Collecting littleutils (from outdated>=0.2.0->ogb)\n",
      "  Using cached littleutils-0.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from outdated>=0.2.0->ogb) (2.31.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from pandas>=0.24.0->ogb) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from pandas>=0.24.0->ogb) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from scikit-learn>=0.20.0->ogb) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from scikit-learn>=0.20.0->ogb) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from scikit-learn>=0.20.0->ogb) (3.2.0)\n",
      "Requirement already satisfied: filelock in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (1.12)\n",
      "Requirement already satisfied: networkx in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (2.0.0)\n",
      "Requirement already satisfied: wheel in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->ogb) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.6.0->ogb) (3.27.2)\n",
      "Requirement already satisfied: lit in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.6.0->ogb) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->ogb) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from requests->outdated>=0.2.0->ogb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from requests->outdated>=0.2.0->ogb) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from requests->outdated>=0.2.0->ogb) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: littleutils, outdated, ogb\n",
      "Successfully installed littleutils-0.2.2 ogb-1.3.6 outdated-0.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip  install torch\n",
    "!pip install torch_geometric\n",
    "!pip install ogb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c695e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import ogb\n",
    "from ogb.nodeproppred import NodePropPredDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "# Download and process data at './dataset/ogbg_molhiv/'\n",
    "dataset = NodePropPredDataset(name = \"ogbn-arxiv\")\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "graph = dataset[0] # pyg graph object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "624f28c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/8c/3a/c9c5d4d5c49b132ef15ac7b5ccf56ef1c82efe36cd19414771762e97c00e/xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: numpy in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in /home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages (from xgboost) (1.11.1)\n",
      "Using cached xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.6\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c2d4c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'edge_index': array([[104447,  15858, 107156, ...,  45118,  45118,  45118],\n",
      "       [ 13091,  47283,  69161, ..., 162473, 162537,  72717]]), 'edge_feat': None, 'node_feat': array([[-0.057943, -0.05253 , -0.072603, ...,  0.173364, -0.172796,\n",
      "        -0.140059],\n",
      "       [-0.1245  , -0.070665, -0.325202, ...,  0.068524, -0.372111,\n",
      "        -0.301036],\n",
      "       [-0.080242, -0.023328, -0.183787, ...,  0.109919,  0.117589,\n",
      "        -0.139883],\n",
      "       ...,\n",
      "       [-0.22053 , -0.036568, -0.402199, ...,  0.11336 , -0.161393,\n",
      "        -0.145171],\n",
      "       [-0.138236,  0.040885, -0.251811, ..., -0.08929 , -0.041253,\n",
      "        -0.376132],\n",
      "       [-0.029875,  0.268417, -0.161124, ...,  0.120807,  0.077647,\n",
      "        -0.091018]], dtype=float32), 'node_year': array([[2013],\n",
      "       [2015],\n",
      "       [2014],\n",
      "       ...,\n",
      "       [2020],\n",
      "       [2020],\n",
      "       [2020]]), 'num_nodes': 169343}\n",
      "[104447  15858 107156 ...  45118  45118  45118]\n",
      "[ 13091  47283  69161 ... 162473 162537  72717]\n",
      "[ 4  5 28 ... 10  4  1]\n",
      "['w_0', 'w_1', 'w_2', 'w_3', 'w_4', 'w_5', 'w_6', 'w_7', 'w_8', 'w_9', 'w_10', 'w_11', 'w_12', 'w_13', 'w_14', 'w_15', 'w_16', 'w_17', 'w_18', 'w_19', 'w_20', 'w_21', 'w_22', 'w_23', 'w_24', 'w_25', 'w_26', 'w_27', 'w_28', 'w_29', 'w_30', 'w_31', 'w_32', 'w_33', 'w_34', 'w_35', 'w_36', 'w_37', 'w_38', 'w_39', 'w_40', 'w_41', 'w_42', 'w_43', 'w_44', 'w_45', 'w_46', 'w_47', 'w_48', 'w_49', 'w_50', 'w_51', 'w_52', 'w_53', 'w_54', 'w_55', 'w_56', 'w_57', 'w_58', 'w_59', 'w_60', 'w_61', 'w_62', 'w_63', 'w_64', 'w_65', 'w_66', 'w_67', 'w_68', 'w_69', 'w_70', 'w_71', 'w_72', 'w_73', 'w_74', 'w_75', 'w_76', 'w_77', 'w_78', 'w_79', 'w_80', 'w_81', 'w_82', 'w_83', 'w_84', 'w_85', 'w_86', 'w_87', 'w_88', 'w_89', 'w_90', 'w_91', 'w_92', 'w_93', 'w_94', 'w_95', 'w_96', 'w_97', 'w_98', 'w_99', 'w_100', 'w_101', 'w_102', 'w_103', 'w_104', 'w_105', 'w_106', 'w_107', 'w_108', 'w_109', 'w_110', 'w_111', 'w_112', 'w_113', 'w_114', 'w_115', 'w_116', 'w_117', 'w_118', 'w_119', 'w_120', 'w_121', 'w_122', 'w_123', 'w_124', 'w_125', 'w_126', 'w_127']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "D=graph[0]\n",
    "print(D)\n",
    "\n",
    "E=D['edge_index']\n",
    "print(E[0])\n",
    "print(E[1])\n",
    "\n",
    "Class=graph[1]\n",
    "Node_Class=Class[:,0]\n",
    "print(Node_Class)\n",
    "df1 = pd.DataFrame(Class,columns=[\"Class\"])\n",
    "df1.head()\n",
    "\n",
    "feature_names = [\"w_{}\".format(ii) for ii in range(128)]\n",
    "print(feature_names)\n",
    "Node_Fec=list(D['node_feat'])\n",
    "df2 = pd.DataFrame(Node_Fec,columns=feature_names)\n",
    "df2.head()\n",
    "\n",
    "Data=pd.concat([df1, df2],axis=1)\n",
    "\n",
    "catagories=Data['Class'].to_numpy()\n",
    "data_by_class = {cls: Data.loc[Data['Class'] == cls].drop(['Class'], axis=1) for cls in range(max(catagories) + 1)}\n",
    "def Average(lst):\n",
    "    # average function\n",
    "    avg = np.average(lst)\n",
    "    return(avg)\n",
    "sel_basis = [[Average(list(df[f'w_{i}'].to_numpy()))\n",
    "              for i in range(len(df.columns))]\n",
    "             for df in data_by_class.values()]\n",
    "feature_names = [\"w_{}\".format(ii) for ii in range(128)]\n",
    "Fec=[]\n",
    "n=169343\n",
    "\n",
    "\n",
    "Node_Year=D['node_year']\n",
    "#print(Node_Year)\n",
    "#print(len(Node_Year))\n",
    "Node_Year_list=list(Node_Year[:,0])\n",
    "Class=graph[1]\n",
    "Node_Class=list(Class[:,0])\n",
    "#print(Class)\n",
    "#print(np.unique(Class))\n",
    "#print(Node_Class)\n",
    "E=D['edge_index']\n",
    "EdgeL=E[0]\n",
    "EdgeR=E[1]\n",
    "\n",
    "Node_Year_list.index(2019)\n",
    "list_size = len(Node_Year_list)\n",
    "NIndex_19_20 = []\n",
    "# declare for loop\n",
    "for itr in range(list_size):\n",
    "\n",
    "    # check the condition\n",
    "    if (Node_Year_list[itr] == 2019):\n",
    "        NIndex_19_20.append(itr)\n",
    "    if (Node_Year_list[itr] == 2020):\n",
    "        NIndex_19_20.append(itr)\n",
    "N_class_train=Node_Class\n",
    "for d in NIndex_19_20:\n",
    "    N_class_train[d]=40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "06e4722c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>a_0</th>\n",
       "      <th>b_0</th>\n",
       "      <th>a_1</th>\n",
       "      <th>b_1</th>\n",
       "      <th>a_2</th>\n",
       "      <th>b_2</th>\n",
       "      <th>a_3</th>\n",
       "      <th>b_3</th>\n",
       "      <th>a_4</th>\n",
       "      <th>...</th>\n",
       "      <th>C_31</th>\n",
       "      <th>C_32</th>\n",
       "      <th>C_33</th>\n",
       "      <th>C_34</th>\n",
       "      <th>C_35</th>\n",
       "      <th>C_36</th>\n",
       "      <th>C_37</th>\n",
       "      <th>C_38</th>\n",
       "      <th>C_39</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.377229</td>\n",
       "      <td>1.454818</td>\n",
       "      <td>1.507436</td>\n",
       "      <td>1.475130</td>\n",
       "      <td>1.321142</td>\n",
       "      <td>1.332594</td>\n",
       "      <td>1.402960</td>\n",
       "      <td>1.464580</td>\n",
       "      <td>1.529985</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.287860</td>\n",
       "      <td>1.287285</td>\n",
       "      <td>1.232101</td>\n",
       "      <td>1.173206</td>\n",
       "      <td>1.212150</td>\n",
       "      <td>1.203949</td>\n",
       "      <td>1.218569</td>\n",
       "      <td>1.392768</td>\n",
       "      <td>1.229372</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.066779</td>\n",
       "      <td>1.054476</td>\n",
       "      <td>1.090065</td>\n",
       "      <td>1.106729</td>\n",
       "      <td>1.018415</td>\n",
       "      <td>1.048563</td>\n",
       "      <td>1.055761</td>\n",
       "      <td>0.872858</td>\n",
       "      <td>1.053669</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.212923</td>\n",
       "      <td>1.329790</td>\n",
       "      <td>1.380889</td>\n",
       "      <td>1.407620</td>\n",
       "      <td>1.317958</td>\n",
       "      <td>1.232171</td>\n",
       "      <td>1.227022</td>\n",
       "      <td>1.067227</td>\n",
       "      <td>1.403863</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.312554</td>\n",
       "      <td>1.071757</td>\n",
       "      <td>1.061597</td>\n",
       "      <td>0.951873</td>\n",
       "      <td>1.278025</td>\n",
       "      <td>1.154286</td>\n",
       "      <td>1.212957</td>\n",
       "      <td>1.561437</td>\n",
       "      <td>1.054831</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.078765</td>\n",
       "      <td>0.970090</td>\n",
       "      <td>1.012655</td>\n",
       "      <td>0.896012</td>\n",
       "      <td>0.998846</td>\n",
       "      <td>0.993356</td>\n",
       "      <td>1.029007</td>\n",
       "      <td>1.191400</td>\n",
       "      <td>0.891102</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.241842</td>\n",
       "      <td>1.335402</td>\n",
       "      <td>1.582994</td>\n",
       "      <td>1.495853</td>\n",
       "      <td>1.341021</td>\n",
       "      <td>1.469382</td>\n",
       "      <td>1.239008</td>\n",
       "      <td>1.392586</td>\n",
       "      <td>1.587203</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.199062</td>\n",
       "      <td>1.267383</td>\n",
       "      <td>1.210855</td>\n",
       "      <td>1.198600</td>\n",
       "      <td>1.190745</td>\n",
       "      <td>1.114602</td>\n",
       "      <td>1.144420</td>\n",
       "      <td>1.301582</td>\n",
       "      <td>1.228871</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.786019</td>\n",
       "      <td>1.951015</td>\n",
       "      <td>2.015311</td>\n",
       "      <td>2.024879</td>\n",
       "      <td>1.892484</td>\n",
       "      <td>1.863353</td>\n",
       "      <td>1.859816</td>\n",
       "      <td>1.721218</td>\n",
       "      <td>2.049513</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.262207</td>\n",
       "      <td>1.185521</td>\n",
       "      <td>1.250311</td>\n",
       "      <td>1.150641</td>\n",
       "      <td>1.267055</td>\n",
       "      <td>1.228752</td>\n",
       "      <td>1.230345</td>\n",
       "      <td>1.561975</td>\n",
       "      <td>1.293345</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  a_0  b_0  a_1  b_1  a_2  b_2  a_3  b_3  a_4  ...      C_31  \\\n",
       "0           0    0    0    0    1    0    0    0    0    0  ...  1.377229   \n",
       "1           1    0    0    0    0    0    0    0    0    0  ...  1.287860   \n",
       "2           2    0    0    0    0    0    0    0    0    0  ...  1.066779   \n",
       "3           3    0    0    0    0    0    0    0    0    0  ...  1.212923   \n",
       "4           4    0    0    0    0    0    0    0    0    0  ...  1.312554   \n",
       "5           5    0    0    0    0    0    0    0    0    0  ...  1.078765   \n",
       "6           6    0    0    0    0    0    0    0    0    0  ...  1.241842   \n",
       "7           7    0    0    0    0    0    0    0    0    1  ...  1.199062   \n",
       "8           8    0    0    0    0    0    0    0    0    0  ...  1.786019   \n",
       "9           9    0    0    0    0    0    0    0    0    0  ...  1.262207   \n",
       "\n",
       "       C_32      C_33      C_34      C_35      C_36      C_37      C_38  \\\n",
       "0  1.454818  1.507436  1.475130  1.321142  1.332594  1.402960  1.464580   \n",
       "1  1.287285  1.232101  1.173206  1.212150  1.203949  1.218569  1.392768   \n",
       "2  1.054476  1.090065  1.106729  1.018415  1.048563  1.055761  0.872858   \n",
       "3  1.329790  1.380889  1.407620  1.317958  1.232171  1.227022  1.067227   \n",
       "4  1.071757  1.061597  0.951873  1.278025  1.154286  1.212957  1.561437   \n",
       "5  0.970090  1.012655  0.896012  0.998846  0.993356  1.029007  1.191400   \n",
       "6  1.335402  1.582994  1.495853  1.341021  1.469382  1.239008  1.392586   \n",
       "7  1.267383  1.210855  1.198600  1.190745  1.114602  1.144420  1.301582   \n",
       "8  1.951015  2.015311  2.024879  1.892484  1.863353  1.859816  1.721218   \n",
       "9  1.185521  1.250311  1.150641  1.267055  1.228752  1.230345  1.561975   \n",
       "\n",
       "       C_39  Class  \n",
       "0  1.529985      4  \n",
       "1  1.229372      5  \n",
       "2  1.053669     28  \n",
       "3  1.403863      8  \n",
       "4  1.054831     27  \n",
       "5  0.891102     34  \n",
       "6  1.587203      6  \n",
       "7  1.228871      4  \n",
       "8  2.049513      3  \n",
       "9  1.293345     28  \n",
       "\n",
       "[10 rows x 124 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Feature_nbd_Sel_OGB_Arxiv.csv')\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "97fbae6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_0</th>\n",
       "      <th>b_0</th>\n",
       "      <th>a_1</th>\n",
       "      <th>b_1</th>\n",
       "      <th>a_2</th>\n",
       "      <th>b_2</th>\n",
       "      <th>a_3</th>\n",
       "      <th>b_3</th>\n",
       "      <th>a_4</th>\n",
       "      <th>b_4</th>\n",
       "      <th>...</th>\n",
       "      <th>C_31</th>\n",
       "      <th>C_32</th>\n",
       "      <th>C_33</th>\n",
       "      <th>C_34</th>\n",
       "      <th>C_35</th>\n",
       "      <th>C_36</th>\n",
       "      <th>C_37</th>\n",
       "      <th>C_38</th>\n",
       "      <th>C_39</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>1.377229</td>\n",
       "      <td>1.454818</td>\n",
       "      <td>1.507436</td>\n",
       "      <td>1.475130</td>\n",
       "      <td>1.321142</td>\n",
       "      <td>1.332594</td>\n",
       "      <td>1.402960</td>\n",
       "      <td>1.464580</td>\n",
       "      <td>1.529985</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.287860</td>\n",
       "      <td>1.287285</td>\n",
       "      <td>1.232101</td>\n",
       "      <td>1.173206</td>\n",
       "      <td>1.212150</td>\n",
       "      <td>1.203949</td>\n",
       "      <td>1.218569</td>\n",
       "      <td>1.392768</td>\n",
       "      <td>1.229372</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.066779</td>\n",
       "      <td>1.054476</td>\n",
       "      <td>1.090065</td>\n",
       "      <td>1.106729</td>\n",
       "      <td>1.018415</td>\n",
       "      <td>1.048563</td>\n",
       "      <td>1.055761</td>\n",
       "      <td>0.872858</td>\n",
       "      <td>1.053669</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.212923</td>\n",
       "      <td>1.329790</td>\n",
       "      <td>1.380889</td>\n",
       "      <td>1.407620</td>\n",
       "      <td>1.317958</td>\n",
       "      <td>1.232171</td>\n",
       "      <td>1.227022</td>\n",
       "      <td>1.067227</td>\n",
       "      <td>1.403863</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.312554</td>\n",
       "      <td>1.071757</td>\n",
       "      <td>1.061597</td>\n",
       "      <td>0.951873</td>\n",
       "      <td>1.278025</td>\n",
       "      <td>1.154286</td>\n",
       "      <td>1.212957</td>\n",
       "      <td>1.561437</td>\n",
       "      <td>1.054831</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   a_0  b_0  a_1  b_1  a_2  b_2  a_3  b_3  a_4  b_4  ...      C_31      C_32  \\\n",
       "0    0    0    0    1    0    0    0    0    0   47  ...  1.377229  1.454818   \n",
       "1    0    0    0    0    0    0    0    0    0    0  ...  1.287860  1.287285   \n",
       "2    0    0    0    0    0    0    0    0    0    0  ...  1.066779  1.054476   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...  1.212923  1.329790   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...  1.312554  1.071757   \n",
       "\n",
       "       C_33      C_34      C_35      C_36      C_37      C_38      C_39  Class  \n",
       "0  1.507436  1.475130  1.321142  1.332594  1.402960  1.464580  1.529985      4  \n",
       "1  1.232101  1.173206  1.212150  1.203949  1.218569  1.392768  1.229372      5  \n",
       "2  1.090065  1.106729  1.018415  1.048563  1.055761  0.872858  1.053669     28  \n",
       "3  1.380889  1.407620  1.317958  1.232171  1.227022  1.067227  1.403863      8  \n",
       "4  1.061597  0.951873  1.278025  1.154286  1.212957  1.561437  1.054831     27  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=data.drop(['Unnamed: 0'], axis=1)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a9969e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.66024730983685 %\n"
     ]
    }
   ],
   "source": [
    "k = 82\n",
    "feature = [\"a_0\", \"b_0\"]\n",
    "for i in range(1, k - 1, 2):\n",
    "    feature.append(\"a_{}\".format(int((i + 1) / 2)))\n",
    "    feature.append(\"b_{}\".format(int((i + 1) / 2)))\n",
    "for i in range(40):\n",
    "    feature.append(\"C_{}\".format(i))\n",
    "\n",
    "X = result[feature]  # Features\n",
    "y = result['Class']  # Labels\n",
    "X_train = X.iloc[list(train_idx)+list(valid_idx)]\n",
    "X_test = X.iloc[test_idx]\n",
    "y_train = y.iloc[list(train_idx)+list(valid_idx)]\n",
    "y_test = y.iloc[test_idx]\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "bst = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1)\n",
    "bst.fit(X_train, y_train)\n",
    "y_pred = bst.predict(X_test)\n",
    "# Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c56356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for d in NIndex_19_20:\n",
    "    N_class_train[d]=y_pred[i]\n",
    "    i=i+1\n",
    "#print(N_class_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e96eb0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 169342 (99%)"
     ]
    }
   ],
   "source": [
    "n=169343\n",
    "\n",
    "def CountX(lst, x):\n",
    "    return (lst.count(x))\n",
    "\n",
    "Node_class = list(range(40))\n",
    "F_vec = []\n",
    "for i in range(n):\n",
    "    print(\"\\rProcessing file {} ({}%)\".format(i, 100 * i //n), end='', flush=True)\n",
    "    node_F = []\n",
    "    list_out = []\n",
    "    list_In = []\n",
    "    # S_nbd_out=[]\n",
    "    # S_nbd_in=[]\n",
    "    indx = np.where(EdgeL == i)\n",
    "    indxIn = np.where(EdgeR == i)\n",
    "    for j in indx[0]:\n",
    "        list_out.append(N_class_train[EdgeR[j]])\n",
    "    #indx.clear()\n",
    "    for k in indxIn[0]:\n",
    "        list_In.append(N_class_train[EdgeL[k]])\n",
    "    #indxIn.clear()\n",
    "\n",
    "    for d in Node_class:\n",
    "        node_F.append(CountX(list_out, d))\n",
    "        node_F.append(CountX(list_In, d))\n",
    "    F_vec.append(node_F)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ba272089",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =np.array(F_vec)\n",
    "k=80\n",
    "data2=pd.DataFrame({\"I_0\":x[:,0]})\n",
    "data2.insert(loc=1, column=\"O_0\", value=x[:,1])\n",
    "for i in range(1,k-1,2):\n",
    "    data2.insert(loc=i+1, column=\"I_{}\".format(int((i+1)/2)), value=x[:,i+1])\n",
    "    data2.insert(loc=i+2, column=\"O_{}\".format(int((i+1)/2)), value=x[:,i+2])\n",
    "result2 = pd.concat([data2,result], axis=1)\n",
    "\n",
    "compression_opts = dict(method='zip',archive_name='Feature_nbd_tran_OGB_Arxiv.csv')\n",
    "result2.to_csv('Feature_nbd_tran_OGB_Arxiv.zip', index=True,compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e7783917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.50587412299653 %\n"
     ]
    }
   ],
   "source": [
    "k = 80\n",
    "feature = [\"I_0\", \"O_0\"]\n",
    "for i in range(1, k - 1, 2):\n",
    "    feature.append(\"I_{}\".format(int((i + 1) / 2)))\n",
    "    feature.append(\"O_{}\".format(int((i + 1) / 2)))\n",
    "for i in range(40):\n",
    "    feature.append(\"C_{}\".format(i))\n",
    "\n",
    "X = result2[feature]  # Features\n",
    "y = result2['Class']  # Labels\n",
    "X_train = X.iloc[list(train_idx)+list(valid_idx)]\n",
    "X_test = X.iloc[test_idx]\n",
    "y_train = y.iloc[list(train_idx)+list(valid_idx)]\n",
    "y_test = y.iloc[test_idx]\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "bst = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1)\n",
    "bst.fit(X_train, y_train)\n",
    "y_pred = bst.predict(X_test)\n",
    "# Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe91b488",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m     feature\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mint\u001b[39m((i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#for i in range(40):\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#    feature.append(\"C_{}\".format(i))\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mresult2\u001b[49m[feature]  \u001b[38;5;66;03m# Features\u001b[39;00m\n\u001b[1;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m result2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Labels\u001b[39;00m\n\u001b[1;32m     12\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;28mlist\u001b[39m(train_idx)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlist\u001b[39m(valid_idx)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result2' is not defined"
     ]
    }
   ],
   "source": [
    "#Spatil Only\n",
    "k = 80\n",
    "feature = [\"I_0\", \"O_0\"]\n",
    "for i in range(1, k - 1, 2):\n",
    "    feature.append(\"I_{}\".format(int((i + 1) / 2)))\n",
    "    feature.append(\"O_{}\".format(int((i + 1) / 2)))\n",
    "#for i in range(40):\n",
    "#    feature.append(\"C_{}\".format(i))\n",
    "\n",
    "X = result2[feature]  # Features\n",
    "y = result2['Class']  # Labels\n",
    "X_train = X.iloc[list(train_idx)+list(valid_idx)]\n",
    "X_test = X.iloc[test_idx]\n",
    "y_train = y.iloc[list(train_idx)+list(valid_idx)]\n",
    "y_test = y.iloc[test_idx]\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "bst = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1)\n",
    "bst.fit(X_train, y_train)\n",
    "y_pred = bst.predict(X_test)\n",
    "# Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ac0eb54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 80\n",
    "feature = [\"I_0\", \"O_0\"]\n",
    "for i in range(1, k - 1, 2):\n",
    "    feature.append(\"I_{}\".format(int((i + 1) / 2)))\n",
    "    feature.append(\"O_{}\".format(int((i + 1) / 2)))\n",
    "for i in range(40):\n",
    "    feature.append(\"C_{}\".format(i))\n",
    "\n",
    "X = result2[feature]  # Features\n",
    "y = result2['Class']  # Labels\n",
    "X_train = X.iloc[list(train_idx)+list(valid_idx)]\n",
    "X_test = X.iloc[test_idx]\n",
    "y_train = y.iloc[list(train_idx)+list(valid_idx)]\n",
    "y_test = y.iloc[test_idx]\n",
    "\n",
    "# Create train and test features as a numpy array.\n",
    "X_train = X_train[feature].to_numpy()\n",
    "X_test = X_test[feature].to_numpy()\n",
    "# Create train and test targets as a numpy array.\n",
    "#y_train = y_train['Class']\n",
    "#y_test = y_test['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "35e8154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "earlystop1 = EarlyStopping(patience=7)\n",
    "earlystop2 = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               min_lr = 3e-7, \n",
    "                               patience = 4,\n",
    "                               factor=0.3,\n",
    "                               verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82af4966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1eea21c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/100\n",
      "944/944 [==============================] - 35s 36ms/step - loss: 0.3881 - auc: 0.8478 - binary_accuracy: 0.5403 - val_loss: -2.3215 - val_auc: 0.9756 - val_binary_accuracy: 0.5956\n",
      "Epoch 2/100\n",
      "944/944 [==============================] - 35s 38ms/step - loss: -4.5187 - auc: 0.9782 - binary_accuracy: 0.5933 - val_loss: -13.9762 - val_auc: 0.9700 - val_binary_accuracy: 0.5957\n",
      "Epoch 3/100\n",
      "944/944 [==============================] - 38s 40ms/step - loss: -20.0838 - auc: 0.9698 - binary_accuracy: 0.5880 - val_loss: -39.7258 - val_auc: 0.9693 - val_binary_accuracy: 0.5957\n",
      "Epoch 4/100\n",
      "944/944 [==============================] - 34s 37ms/step - loss: -50.6896 - auc: 0.9644 - binary_accuracy: 0.5788 - val_loss: -81.1627 - val_auc: 0.9573 - val_binary_accuracy: 0.5957\n",
      "Epoch 5/100\n",
      "944/944 [==============================] - 38s 40ms/step - loss: -98.1446 - auc: 0.9581 - binary_accuracy: 0.5741 - val_loss: -139.8308 - val_auc: 0.9563 - val_binary_accuracy: 0.5957\n",
      "Epoch 6/100\n",
      "944/944 [==============================] - 36s 38ms/step - loss: -163.4882 - auc: 0.9517 - binary_accuracy: 0.5711 - val_loss: -217.2729 - val_auc: 0.9552 - val_binary_accuracy: 0.5957\n",
      "Epoch 7/100\n",
      "944/944 [==============================] - 36s 38ms/step - loss: -248.9198 - auc: 0.9475 - binary_accuracy: 0.5704 - val_loss: -314.9547 - val_auc: 0.9520 - val_binary_accuracy: 0.5957\n",
      "Epoch 8/100\n",
      "944/944 [==============================] - 38s 40ms/step - loss: -356.8915 - auc: 0.9435 - binary_accuracy: 0.5696 - val_loss: -434.5146 - val_auc: 0.9520 - val_binary_accuracy: 0.5957\n",
      "Epoch 9/100\n",
      "944/944 [==============================] - 35s 37ms/step - loss: -485.9700 - auc: 0.9415 - binary_accuracy: 0.5705 - val_loss: -577.6094 - val_auc: 0.9459 - val_binary_accuracy: 0.5957\n",
      "Epoch 10/100\n",
      "944/944 [==============================] - 37s 39ms/step - loss: -641.8004 - auc: 0.9387 - binary_accuracy: 0.5694 - val_loss: -745.9980 - val_auc: 0.9460 - val_binary_accuracy: 0.5957\n",
      "Epoch 11/100\n",
      "944/944 [==============================] - 37s 40ms/step - loss: -823.8903 - auc: 0.9371 - binary_accuracy: 0.5697 - val_loss: -940.9379 - val_auc: 0.9459 - val_binary_accuracy: 0.5957\n",
      "Epoch 12/100\n",
      "944/944 [==============================] - 37s 39ms/step - loss: -1035.7899 - auc: 0.9350 - binary_accuracy: 0.5686 - val_loss: -1164.5142 - val_auc: 0.9460 - val_binary_accuracy: 0.5957\n",
      "Epoch 13/100\n",
      "944/944 [==============================] - 36s 38ms/step - loss: -1271.0911 - auc: 0.9344 - binary_accuracy: 0.5696 - val_loss: -1418.5417 - val_auc: 0.9460 - val_binary_accuracy: 0.5957\n",
      "Epoch 14/100\n",
      "944/944 [==============================] - 36s 38ms/step - loss: -1548.7595 - auc: 0.9333 - binary_accuracy: 0.5692 - val_loss: -1704.1168 - val_auc: 0.9461 - val_binary_accuracy: 0.5957\n",
      "Epoch 15/100\n",
      "944/944 [==============================] - 35s 37ms/step - loss: -1847.5238 - auc: 0.9328 - binary_accuracy: 0.5698 - val_loss: -2023.2329 - val_auc: 0.9460 - val_binary_accuracy: 0.5957\n",
      "Epoch 16/100\n",
      "944/944 [==============================] - 36s 38ms/step - loss: -2194.6477 - auc: 0.9316 - binary_accuracy: 0.5691 - val_loss: -2377.0625 - val_auc: 0.9461 - val_binary_accuracy: 0.5957\n",
      "Epoch 17/100\n",
      "944/944 [==============================] - 38s 40ms/step - loss: -2560.0097 - auc: 0.9310 - binary_accuracy: 0.5691 - val_loss: -2767.8440 - val_auc: 0.9461 - val_binary_accuracy: 0.5957\n",
      "Epoch 18/100\n",
      "944/944 [==============================] - 37s 40ms/step - loss: -2987.0603 - auc: 0.9307 - binary_accuracy: 0.5693 - val_loss: -3196.5125 - val_auc: 0.9461 - val_binary_accuracy: 0.5957\n",
      "Epoch 19/100\n",
      "944/944 [==============================] - 38s 41ms/step - loss: -3437.3448 - auc: 0.9304 - binary_accuracy: 0.5695 - val_loss: -3665.3984 - val_auc: 0.9461 - val_binary_accuracy: 0.5957\n",
      "Epoch 20/100\n",
      "944/944 [==============================] - 39s 41ms/step - loss: -3942.2697 - auc: 0.9295 - binary_accuracy: 0.5687 - val_loss: -4175.5449 - val_auc: 0.9440 - val_binary_accuracy: 0.5957\n",
      "Epoch 21/100\n",
      "944/944 [==============================] - 37s 39ms/step - loss: -4477.0894 - auc: 0.9292 - binary_accuracy: 0.5690 - val_loss: -4728.6973 - val_auc: 0.9440 - val_binary_accuracy: 0.5957\n",
      "Epoch 22/100\n",
      "944/944 [==============================] - 39s 41ms/step - loss: -5068.6284 - auc: 0.9289 - binary_accuracy: 0.5689 - val_loss: -5326.2646 - val_auc: 0.9461 - val_binary_accuracy: 0.5957\n",
      "Epoch 23/100\n",
      "944/944 [==============================] - 37s 39ms/step - loss: -5696.0075 - auc: 0.9292 - binary_accuracy: 0.5697 - val_loss: -5970.2422 - val_auc: 0.9461 - val_binary_accuracy: 0.5957\n",
      "Epoch 24/100\n",
      "944/944 [==============================] - 37s 40ms/step - loss: -6399.4557 - auc: 0.9288 - binary_accuracy: 0.5693 - val_loss: -6661.4790 - val_auc: 0.9461 - val_binary_accuracy: 0.5957\n",
      "Epoch 25/100\n",
      "944/944 [==============================] - 37s 40ms/step - loss: -7152.8631 - auc: 0.9286 - binary_accuracy: 0.5693 - val_loss: -7402.6753 - val_auc: 0.9461 - val_binary_accuracy: 0.5957\n",
      "Epoch 26/100\n",
      "944/944 [==============================] - 35s 38ms/step - loss: -7935.5998 - auc: 0.9285 - binary_accuracy: 0.5693 - val_loss: -8193.8369 - val_auc: 0.9437 - val_binary_accuracy: 0.5957\n",
      "Epoch 27/100\n",
      "944/944 [==============================] - 35s 37ms/step - loss: -8742.8401 - auc: 0.9280 - binary_accuracy: 0.5689 - val_loss: -9038.5566 - val_auc: 0.9461 - val_binary_accuracy: 0.5957\n",
      "Epoch 28/100\n",
      "944/944 [==============================] - 37s 39ms/step - loss: -9680.4078 - auc: 0.9278 - binary_accuracy: 0.5688 - val_loss: -9936.4502 - val_auc: 0.9440 - val_binary_accuracy: 0.5957\n",
      "Epoch 29/100\n",
      "944/944 [==============================] - 35s 37ms/step - loss: -10599.6049 - auc: 0.9278 - binary_accuracy: 0.5690 - val_loss: -10890.8467 - val_auc: 0.9440 - val_binary_accuracy: 0.5957\n",
      "Epoch 30/100\n",
      "944/944 [==============================] - 36s 38ms/step - loss: -11622.8051 - auc: 0.9277 - binary_accuracy: 0.5688 - val_loss: -11901.5176 - val_auc: 0.9437 - val_binary_accuracy: 0.5957\n",
      "Epoch 31/100\n",
      "944/944 [==============================] - 35s 38ms/step - loss: -12692.1712 - auc: 0.9278 - binary_accuracy: 0.5691 - val_loss: -12972.0059 - val_auc: 0.9440 - val_binary_accuracy: 0.5957\n",
      "Epoch 32/100\n",
      "944/944 [==============================] - 36s 38ms/step - loss: -13817.8420 - auc: 0.9280 - binary_accuracy: 0.5694 - val_loss: -14101.8535 - val_auc: 0.9461 - val_binary_accuracy: 0.5957\n",
      "Epoch 33/100\n",
      "944/944 [==============================] - 37s 39ms/step - loss: -14963.4136 - auc: 0.9283 - binary_accuracy: 0.5697 - val_loss: -15294.0225 - val_auc: 0.9376 - val_binary_accuracy: 0.5875\n",
      "Epoch 34/100\n",
      "944/944 [==============================] - 38s 40ms/step - loss: -16217.0084 - auc: 0.9274 - binary_accuracy: 0.5685 - val_loss: -16549.9531 - val_auc: 0.9461 - val_binary_accuracy: 0.5957\n",
      "Epoch 35/100\n",
      "944/944 [==============================] - 36s 38ms/step - loss: -17679.0823 - auc: 0.9280 - binary_accuracy: 0.5692 - val_loss: -17869.5703 - val_auc: 0.9440 - val_binary_accuracy: 0.5957\n",
      "Epoch 36/100\n",
      "944/944 [==============================] - 34s 36ms/step - loss: -19074.3895 - auc: 0.9281 - binary_accuracy: 0.5691 - val_loss: -19255.2637 - val_auc: 0.9451 - val_binary_accuracy: 0.5957\n",
      "Epoch 37/100\n",
      "944/944 [==============================] - 36s 38ms/step - loss: -20387.1353 - auc: 0.9288 - binary_accuracy: 0.5700 - val_loss: -20710.9473 - val_auc: 0.9473 - val_binary_accuracy: 0.5957\n",
      "Epoch 38/100\n",
      "944/944 [==============================] - 35s 37ms/step - loss: -21961.4262 - auc: 0.9292 - binary_accuracy: 0.5706 - val_loss: -22235.9590 - val_auc: 0.9451 - val_binary_accuracy: 0.5957\n",
      "Epoch 39/100\n",
      "944/944 [==============================] - 36s 38ms/step - loss: -23539.4474 - auc: 0.9290 - binary_accuracy: 0.5701 - val_loss: -23831.7969 - val_auc: 0.9449 - val_binary_accuracy: 0.5957\n",
      "Epoch 40/100\n",
      "944/944 [==============================] - 37s 39ms/step - loss: -25254.3233 - auc: 0.9292 - binary_accuracy: 0.5697 - val_loss: -25499.0859 - val_auc: 0.9463 - val_binary_accuracy: 0.5875\n",
      "Epoch 41/100\n",
      "944/944 [==============================] - 30s 32ms/step - loss: -27123.9650 - auc: 0.9300 - binary_accuracy: 0.5700 - val_loss: -27240.4082 - val_auc: 0.9466 - val_binary_accuracy: 0.5957\n",
      "Epoch 42/100\n",
      "944/944 [==============================] - 31s 33ms/step - loss: -28952.5776 - auc: 0.9309 - binary_accuracy: 0.5711 - val_loss: -29057.7363 - val_auc: 0.9497 - val_binary_accuracy: 0.5957\n",
      "Epoch 43/100\n",
      "944/944 [==============================] - 33s 35ms/step - loss: -30711.1855 - auc: 0.9316 - binary_accuracy: 0.5724 - val_loss: -30954.9922 - val_auc: 0.9496 - val_binary_accuracy: 0.5899\n",
      "Epoch 44/100\n",
      "944/944 [==============================] - 33s 35ms/step - loss: -32758.1533 - auc: 0.9318 - binary_accuracy: 0.5728 - val_loss: -32928.7578 - val_auc: 0.9474 - val_binary_accuracy: 0.5957\n",
      "Epoch 45/100\n",
      "944/944 [==============================] - 33s 35ms/step - loss: -34886.7485 - auc: 0.9319 - binary_accuracy: 0.5722 - val_loss: -34983.8711 - val_auc: 0.9475 - val_binary_accuracy: 0.5957\n",
      "Epoch 46/100\n",
      "944/944 [==============================] - 33s 35ms/step - loss: -36900.7223 - auc: 0.9329 - binary_accuracy: 0.5737 - val_loss: -37120.3828 - val_auc: 0.9474 - val_binary_accuracy: 0.5957\n",
      "Epoch 47/100\n",
      "944/944 [==============================] - 33s 35ms/step - loss: -39305.9150 - auc: 0.9332 - binary_accuracy: 0.5733 - val_loss: -39339.0703 - val_auc: 0.9480 - val_binary_accuracy: 0.5957\n",
      "Epoch 48/100\n",
      "944/944 [==============================] - 35s 37ms/step - loss: -41620.4911 - auc: 0.9340 - binary_accuracy: 0.5741 - val_loss: -41643.8398 - val_auc: 0.9484 - val_binary_accuracy: 0.5957\n",
      "Epoch 49/100\n",
      "944/944 [==============================] - 34s 36ms/step - loss: -44088.4295 - auc: 0.9346 - binary_accuracy: 0.5750 - val_loss: -44034.6328 - val_auc: 0.9489 - val_binary_accuracy: 0.5957\n",
      "Epoch 50/100\n",
      "944/944 [==============================] - 36s 38ms/step - loss: -46445.5940 - auc: 0.9360 - binary_accuracy: 0.5765 - val_loss: -46514.0781 - val_auc: 0.9489 - val_binary_accuracy: 0.5957\n",
      "Epoch 51/100\n",
      "944/944 [==============================] - 35s 37ms/step - loss: -49121.1054 - auc: 0.9359 - binary_accuracy: 0.5770 - val_loss: -49084.6289 - val_auc: 0.9515 - val_binary_accuracy: 0.5896\n",
      "Epoch 52/100\n",
      "944/944 [==============================] - 32s 34ms/step - loss: -51889.5961 - auc: 0.9361 - binary_accuracy: 0.5770 - val_loss: -51739.9141 - val_auc: 0.9488 - val_binary_accuracy: 0.5957\n",
      "Epoch 53/100\n",
      "944/944 [==============================] - 32s 33ms/step - loss: -54795.6864 - auc: 0.9364 - binary_accuracy: 0.5774 - val_loss: -54492.0625 - val_auc: 0.9562 - val_binary_accuracy: 0.5899\n",
      "Epoch 54/100\n",
      "944/944 [==============================] - 35s 37ms/step - loss: -57597.6365 - auc: 0.9369 - binary_accuracy: 0.5778 - val_loss: -57339.1055 - val_auc: 0.9564 - val_binary_accuracy: 0.5957\n",
      "Epoch 55/100\n",
      "944/944 [==============================] - 36s 38ms/step - loss: -60844.0346 - auc: 0.9366 - binary_accuracy: 0.5773 - val_loss: -60281.9141 - val_auc: 0.9554 - val_binary_accuracy: 0.5957\n",
      "Epoch 56/100\n",
      "944/944 [==============================] - 33s 35ms/step - loss: -63500.9467 - auc: 0.9378 - binary_accuracy: 0.5789 - val_loss: -63324.1367 - val_auc: 0.9562 - val_binary_accuracy: 0.5957\n",
      "Epoch 57/100\n",
      "944/944 [==============================] - 30s 32ms/step - loss: -66692.4112 - auc: 0.9383 - binary_accuracy: 0.5795 - val_loss: -66461.7969 - val_auc: 0.9539 - val_binary_accuracy: 0.5957\n",
      "Epoch 58/100\n",
      "944/944 [==============================] - 31s 33ms/step - loss: -70095.8119 - auc: 0.9382 - binary_accuracy: 0.5795 - val_loss: -69700.0391 - val_auc: 0.9556 - val_binary_accuracy: 0.5899\n",
      "Epoch 59/100\n",
      "944/944 [==============================] - 32s 34ms/step - loss: -73809.3187 - auc: 0.9386 - binary_accuracy: 0.5801 - val_loss: -73034.4219 - val_auc: 0.9560 - val_binary_accuracy: 0.5883\n",
      "Epoch 60/100\n",
      "944/944 [==============================] - 33s 35ms/step - loss: -77124.3950 - auc: 0.9392 - binary_accuracy: 0.5808 - val_loss: -76477.0625 - val_auc: 0.9556 - val_binary_accuracy: 0.5817\n",
      "Epoch 61/100\n",
      "944/944 [==============================] - 33s 35ms/step - loss: -80594.7156 - auc: 0.9392 - binary_accuracy: 0.5800 - val_loss: -80023.4453 - val_auc: 0.9561 - val_binary_accuracy: 0.5899\n",
      "Epoch 62/100\n",
      "944/944 [==============================] - 34s 36ms/step - loss: -84586.6657 - auc: 0.9405 - binary_accuracy: 0.5803 - val_loss: -83676.9844 - val_auc: 0.9576 - val_binary_accuracy: 0.5899\n",
      "Epoch 63/100\n",
      "944/944 [==============================] - 36s 38ms/step - loss: -88315.2011 - auc: 0.9414 - binary_accuracy: 0.5801 - val_loss: -87438.4922 - val_auc: 0.9550 - val_binary_accuracy: 0.5883\n",
      "Epoch 64/100\n",
      "944/944 [==============================] - 36s 38ms/step - loss: -92516.8294 - auc: 0.9416 - binary_accuracy: 0.5805 - val_loss: -91309.2578 - val_auc: 0.9568 - val_binary_accuracy: 0.5957\n",
      "Epoch 65/100\n",
      "944/944 [==============================] - 35s 37ms/step - loss: -96432.4362 - auc: 0.9415 - binary_accuracy: 0.5801 - val_loss: -95289.7188 - val_auc: 0.9547 - val_binary_accuracy: 0.5899\n",
      "Epoch 66/100\n",
      "944/944 [==============================] - 36s 38ms/step - loss: -100422.5566 - auc: 0.9424 - binary_accuracy: 0.5812 - val_loss: -99384.8203 - val_auc: 0.9508 - val_binary_accuracy: 0.5899\n",
      "Epoch 67/100\n",
      "944/944 [==============================] - 36s 38ms/step - loss: -104676.9051 - auc: 0.9430 - binary_accuracy: 0.5822 - val_loss: -103594.5703 - val_auc: 0.9553 - val_binary_accuracy: 0.5957\n",
      "Epoch 68/100\n",
      "944/944 [==============================] - 38s 40ms/step - loss: -108799.2074 - auc: 0.9429 - binary_accuracy: 0.5818 - val_loss: -107918.1797 - val_auc: 0.9543 - val_binary_accuracy: 0.5899\n",
      "Epoch 69/100\n",
      "944/944 [==============================] - 37s 39ms/step - loss: -113680.4156 - auc: 0.9439 - binary_accuracy: 0.5824 - val_loss: -112354.8906 - val_auc: 0.9512 - val_binary_accuracy: 0.5744\n",
      "Epoch 70/100\n",
      "944/944 [==============================] - 38s 41ms/step - loss: -118331.9639 - auc: 0.9446 - binary_accuracy: 0.5824 - val_loss: -116916.0703 - val_auc: 0.9542 - val_binary_accuracy: 0.5875\n",
      "Epoch 71/100\n",
      "944/944 [==============================] - 37s 39ms/step - loss: -122981.0988 - auc: 0.9454 - binary_accuracy: 0.5834 - val_loss: -121592.7891 - val_auc: 0.9550 - val_binary_accuracy: 0.5817\n",
      "Epoch 72/100\n",
      "944/944 [==============================] - 37s 39ms/step - loss: -128164.3862 - auc: 0.9452 - binary_accuracy: 0.5832 - val_loss: -126392.3359 - val_auc: 0.9537 - val_binary_accuracy: 0.5883\n",
      "Epoch 73/100\n",
      "944/944 [==============================] - 36s 38ms/step - loss: -132852.2162 - auc: 0.9457 - binary_accuracy: 0.5841 - val_loss: -131312.6094 - val_auc: 0.9500 - val_binary_accuracy: 0.5802\n",
      "Epoch 74/100\n",
      "944/944 [==============================] - 35s 37ms/step - loss: -138611.3535 - auc: 0.9457 - binary_accuracy: 0.5835 - val_loss: -136359.1406 - val_auc: 0.9549 - val_binary_accuracy: 0.5957\n",
      "Epoch 75/100\n",
      "944/944 [==============================] - 35s 37ms/step - loss: -142973.7903 - auc: 0.9466 - binary_accuracy: 0.5845 - val_loss: -141532.7969 - val_auc: 0.9525 - val_binary_accuracy: 0.5899\n",
      "Epoch 76/100\n",
      "944/944 [==============================] - 35s 37ms/step - loss: -148726.1777 - auc: 0.9468 - binary_accuracy: 0.5837 - val_loss: -146832.4531 - val_auc: 0.9558 - val_binary_accuracy: 0.5957\n",
      "Epoch 77/100\n",
      "944/944 [==============================] - 34s 36ms/step - loss: -154719.8408 - auc: 0.9471 - binary_accuracy: 0.5844 - val_loss: -152260.3750 - val_auc: 0.9538 - val_binary_accuracy: 0.5957\n",
      "Epoch 78/100\n",
      "944/944 [==============================] - 33s 35ms/step - loss: -159967.9062 - auc: 0.9471 - binary_accuracy: 0.5840 - val_loss: -157819.9219 - val_auc: 0.9537 - val_binary_accuracy: 0.5817\n",
      "Epoch 79/100\n",
      "944/944 [==============================] - 33s 35ms/step - loss: -165678.6136 - auc: 0.9477 - binary_accuracy: 0.5847 - val_loss: -163514.1562 - val_auc: 0.9544 - val_binary_accuracy: 0.5957\n",
      "Epoch 80/100\n",
      "944/944 [==============================] - 33s 35ms/step - loss: -172393.3119 - auc: 0.9474 - binary_accuracy: 0.5838 - val_loss: -169335.7812 - val_auc: 0.9555 - val_binary_accuracy: 0.5834\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944/944 [==============================] - 28s 30ms/step - loss: -178366.0762 - auc: 0.9486 - binary_accuracy: 0.5849 - val_loss: -175293.2344 - val_auc: 0.9541 - val_binary_accuracy: 0.5753\n",
      "Epoch 82/100\n",
      "944/944 [==============================] - 30s 31ms/step - loss: -184704.4953 - auc: 0.9491 - binary_accuracy: 0.5843 - val_loss: -181389.8281 - val_auc: 0.9563 - val_binary_accuracy: 0.5899\n",
      "Epoch 83/100\n",
      "944/944 [==============================] - 31s 33ms/step - loss: -190702.3679 - auc: 0.9509 - binary_accuracy: 0.5846 - val_loss: -187627.2031 - val_auc: 0.9545 - val_binary_accuracy: 0.5875\n",
      "Epoch 84/100\n",
      "944/944 [==============================] - 32s 34ms/step - loss: -197567.2658 - auc: 0.9511 - binary_accuracy: 0.5843 - val_loss: -194001.6562 - val_auc: 0.9587 - val_binary_accuracy: 0.5957\n",
      "Epoch 85/100\n",
      "944/944 [==============================] - 29s 30ms/step - loss: -204412.1649 - auc: 0.9516 - binary_accuracy: 0.5848 - val_loss: -200513.9531 - val_auc: 0.9573 - val_binary_accuracy: 0.5957\n",
      "Epoch 86/100\n",
      "944/944 [==============================] - 29s 31ms/step - loss: -210115.6229 - auc: 0.9506 - binary_accuracy: 0.5846 - val_loss: -207179.5312 - val_auc: 0.9481 - val_binary_accuracy: 0.5875\n",
      "Epoch 87/100\n",
      "944/944 [==============================] - 28s 30ms/step - loss: -218995.3080 - auc: 0.9514 - binary_accuracy: 0.5842 - val_loss: -213968.8750 - val_auc: 0.9518 - val_binary_accuracy: 0.5814\n",
      "Epoch 88/100\n",
      "944/944 [==============================] - 30s 32ms/step - loss: -224849.0933 - auc: 0.9513 - binary_accuracy: 0.5844 - val_loss: -220919.4375 - val_auc: 0.9469 - val_binary_accuracy: 0.5748\n",
      "Epoch 89/100\n",
      "944/944 [==============================] - 29s 31ms/step - loss: -232703.6322 - auc: 0.9517 - binary_accuracy: 0.5846 - val_loss: -228013.6562 - val_auc: 0.9547 - val_binary_accuracy: 0.5899\n",
      "Epoch 90/100\n",
      "944/944 [==============================] - 31s 33ms/step - loss: -239455.1899 - auc: 0.9516 - binary_accuracy: 0.5843 - val_loss: -235253.3750 - val_auc: 0.9568 - val_binary_accuracy: 0.5899\n",
      "Epoch 91/100\n",
      "944/944 [==============================] - 29s 31ms/step - loss: -246878.9497 - auc: 0.9519 - binary_accuracy: 0.5848 - val_loss: -242649.8594 - val_auc: 0.9512 - val_binary_accuracy: 0.5750\n",
      "Epoch 92/100\n",
      "944/944 [==============================] - 30s 32ms/step - loss: -254861.3138 - auc: 0.9519 - binary_accuracy: 0.5848 - val_loss: -250192.0312 - val_auc: 0.9561 - val_binary_accuracy: 0.5902\n",
      "Epoch 93/100\n",
      "944/944 [==============================] - 31s 32ms/step - loss: -262833.6609 - auc: 0.9517 - binary_accuracy: 0.5845 - val_loss: -257888.9375 - val_auc: 0.9580 - val_binary_accuracy: 0.5957\n",
      "Epoch 94/100\n",
      "944/944 [==============================] - 29s 31ms/step - loss: -271429.1597 - auc: 0.9518 - binary_accuracy: 0.5846 - val_loss: -265743.7188 - val_auc: 0.9483 - val_binary_accuracy: 0.5875\n",
      "Epoch 95/100\n",
      "944/944 [==============================] - 31s 33ms/step - loss: -278911.9038 - auc: 0.9518 - binary_accuracy: 0.5841 - val_loss: -273753.6875 - val_auc: 0.9446 - val_binary_accuracy: 0.5584\n",
      "Epoch 96/100\n",
      "944/944 [==============================] - 31s 33ms/step - loss: -287602.5054 - auc: 0.9516 - binary_accuracy: 0.5841 - val_loss: -281923.0938 - val_auc: 0.9538 - val_binary_accuracy: 0.5818\n",
      "Epoch 97/100\n",
      "944/944 [==============================] - 30s 31ms/step - loss: -295940.6027 - auc: 0.9512 - binary_accuracy: 0.5843 - val_loss: -290250.4688 - val_auc: 0.9556 - val_binary_accuracy: 0.5899\n",
      "Epoch 98/100\n",
      "944/944 [==============================] - 32s 34ms/step - loss: -305148.2963 - auc: 0.9522 - binary_accuracy: 0.5845 - val_loss: -298730.9062 - val_auc: 0.9570 - val_binary_accuracy: 0.5899\n",
      "Epoch 99/100\n",
      "944/944 [==============================] - 31s 33ms/step - loss: -313874.4658 - auc: 0.9524 - binary_accuracy: 0.5844 - val_loss: -307379.1875 - val_auc: 0.9563 - val_binary_accuracy: 0.5641\n",
      "Epoch 100/100\n",
      "944/944 [==============================] - 32s 33ms/step - loss: -322170.9836 - auc: 0.9523 - binary_accuracy: 0.5840 - val_loss: -316194.5312 - val_auc: 0.9483 - val_binary_accuracy: 0.5875\n",
      "Score for fold 1: loss of -2.3214590549468994; auc of 97.55738973617554%\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "checkpoint_filepath='/tmp/checkpoint'\n",
    "# for train, test in kfold.split(X_train, y_train):\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(len(X_train.iloc[0]),)),\n",
    "    tf.keras.layers.Dense(512),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(256),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(len(y.columns), activation='sigmoid')\n",
    "])\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(2e-5), loss=loss_fn, \n",
    "              metrics=[tf.keras.metrics.AUC(name='auc'), 'binary_accuracy'])\n",
    "print('------------------------------------------------------------------------')\n",
    "print(f'Training for fold {fold_no} ...')\n",
    "history = model.fit(np.array(X_train), np.array(y_train),\n",
    "                    batch_size = 128,\n",
    "                    epochs=100,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=4,\n",
    "                    validation_data=(np.array(X_test), np.array(y_test)),\n",
    "                    callbacks=[\n",
    "                                tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                                save_best_only=True,\n",
    "                                                                save_weights_only=True,\n",
    "                                                                monitor='val_auc',\n",
    "                                                                mode='max')])\n",
    "model.load_weights(checkpoint_filepath)\n",
    "scores = model.evaluate(np.array(X_test), np.array(y_test), verbose=0)\n",
    "print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "acc_per_fold.append(scores[1] * 100)\n",
    "loss_per_fold.append(scores[0])\n",
    "fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df7e3530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          4\n",
       "1          5\n",
       "2         28\n",
       "3          8\n",
       "4         27\n",
       "          ..\n",
       "169155    16\n",
       "169176     4\n",
       "169185    30\n",
       "169261    16\n",
       "169296    28\n",
       "Name: Class, Length: 120740, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "25399d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 2.7871 - sparse_categorical_accuracy: 0.4189 - val_loss: 1.4713 - val_sparse_categorical_accuracy: 0.6815\n",
      "Epoch 2/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 1.6131 - sparse_categorical_accuracy: 0.6597 - val_loss: 1.3594 - val_sparse_categorical_accuracy: 0.6988\n",
      "Epoch 3/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 1.4505 - sparse_categorical_accuracy: 0.6934 - val_loss: 1.3412 - val_sparse_categorical_accuracy: 0.6913\n",
      "Epoch 4/100\n",
      "944/944 [==============================] - 13s 13ms/step - loss: 1.3948 - sparse_categorical_accuracy: 0.7040 - val_loss: 1.2730 - val_sparse_categorical_accuracy: 0.7096\n",
      "Epoch 5/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 1.3385 - sparse_categorical_accuracy: 0.7105 - val_loss: 1.2673 - val_sparse_categorical_accuracy: 0.7024\n",
      "Epoch 6/100\n",
      "944/944 [==============================] - 13s 13ms/step - loss: 1.3166 - sparse_categorical_accuracy: 0.7106 - val_loss: 1.2438 - val_sparse_categorical_accuracy: 0.7092\n",
      "Epoch 7/100\n",
      "944/944 [==============================] - 13s 13ms/step - loss: 1.3088 - sparse_categorical_accuracy: 0.7138 - val_loss: 1.2446 - val_sparse_categorical_accuracy: 0.7076\n",
      "Epoch 8/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 1.2683 - sparse_categorical_accuracy: 0.7157 - val_loss: 1.2387 - val_sparse_categorical_accuracy: 0.7050\n",
      "Epoch 9/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 1.2526 - sparse_categorical_accuracy: 0.7159 - val_loss: 1.2126 - val_sparse_categorical_accuracy: 0.7077\n",
      "Epoch 10/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 1.2520 - sparse_categorical_accuracy: 0.7145 - val_loss: 1.2147 - val_sparse_categorical_accuracy: 0.7038\n",
      "Epoch 11/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 1.2312 - sparse_categorical_accuracy: 0.7185 - val_loss: 1.2140 - val_sparse_categorical_accuracy: 0.7012\n",
      "Epoch 12/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 1.2243 - sparse_categorical_accuracy: 0.7179 - val_loss: 1.2108 - val_sparse_categorical_accuracy: 0.7024\n",
      "Epoch 13/100\n",
      "944/944 [==============================] - 13s 13ms/step - loss: 1.2041 - sparse_categorical_accuracy: 0.7182 - val_loss: 1.1865 - val_sparse_categorical_accuracy: 0.7093\n",
      "Epoch 14/100\n",
      "944/944 [==============================] - 12s 12ms/step - loss: 1.2088 - sparse_categorical_accuracy: 0.7191 - val_loss: 1.1844 - val_sparse_categorical_accuracy: 0.7086\n",
      "Epoch 15/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 1.1866 - sparse_categorical_accuracy: 0.7193 - val_loss: 1.1778 - val_sparse_categorical_accuracy: 0.7082\n",
      "Epoch 16/100\n",
      "944/944 [==============================] - 13s 13ms/step - loss: 1.1950 - sparse_categorical_accuracy: 0.7202 - val_loss: 1.1796 - val_sparse_categorical_accuracy: 0.7053\n",
      "Epoch 17/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 1.1887 - sparse_categorical_accuracy: 0.7207 - val_loss: 1.1714 - val_sparse_categorical_accuracy: 0.7068\n",
      "Epoch 18/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 1.1869 - sparse_categorical_accuracy: 0.7195 - val_loss: 1.1666 - val_sparse_categorical_accuracy: 0.7096\n",
      "Epoch 19/100\n",
      "944/944 [==============================] - 13s 13ms/step - loss: 1.1761 - sparse_categorical_accuracy: 0.7203 - val_loss: 1.1689 - val_sparse_categorical_accuracy: 0.7087\n",
      "Epoch 20/100\n",
      "944/944 [==============================] - 13s 13ms/step - loss: 1.1840 - sparse_categorical_accuracy: 0.7185 - val_loss: 1.1643 - val_sparse_categorical_accuracy: 0.7089\n",
      "Epoch 21/100\n",
      "944/944 [==============================] - 13s 13ms/step - loss: 1.1843 - sparse_categorical_accuracy: 0.7183 - val_loss: 1.1802 - val_sparse_categorical_accuracy: 0.7015\n",
      "Epoch 22/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 1.1729 - sparse_categorical_accuracy: 0.7202 - val_loss: 1.1630 - val_sparse_categorical_accuracy: 0.7053\n",
      "Epoch 23/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 1.1663 - sparse_categorical_accuracy: 0.7217 - val_loss: 1.1456 - val_sparse_categorical_accuracy: 0.7131\n",
      "Epoch 24/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 1.1580 - sparse_categorical_accuracy: 0.7215 - val_loss: 1.1485 - val_sparse_categorical_accuracy: 0.7099\n",
      "Epoch 25/100\n",
      "944/944 [==============================] - 14s 15ms/step - loss: 1.1638 - sparse_categorical_accuracy: 0.7198 - val_loss: 1.1473 - val_sparse_categorical_accuracy: 0.7100\n",
      "Epoch 26/100\n",
      "944/944 [==============================] - 14s 15ms/step - loss: 1.1546 - sparse_categorical_accuracy: 0.7204 - val_loss: 1.1528 - val_sparse_categorical_accuracy: 0.7099\n",
      "Epoch 27/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 1.1673 - sparse_categorical_accuracy: 0.7181 - val_loss: 1.1423 - val_sparse_categorical_accuracy: 0.7101\n",
      "Epoch 28/100\n",
      "944/944 [==============================] - 14s 14ms/step - loss: 1.1466 - sparse_categorical_accuracy: 0.7237 - val_loss: 1.1463 - val_sparse_categorical_accuracy: 0.7078\n",
      "Epoch 29/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 1.1554 - sparse_categorical_accuracy: 0.7201 - val_loss: 1.1469 - val_sparse_categorical_accuracy: 0.7100\n",
      "Epoch 30/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 1.1448 - sparse_categorical_accuracy: 0.7207 - val_loss: 1.1409 - val_sparse_categorical_accuracy: 0.7067\n",
      "Epoch 31/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 1.1378 - sparse_categorical_accuracy: 0.7204 - val_loss: 1.1506 - val_sparse_categorical_accuracy: 0.7073\n",
      "Epoch 32/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 1.1480 - sparse_categorical_accuracy: 0.7195 - val_loss: 1.1311 - val_sparse_categorical_accuracy: 0.7110\n",
      "Epoch 33/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 1.1347 - sparse_categorical_accuracy: 0.7226 - val_loss: 1.1338 - val_sparse_categorical_accuracy: 0.7085\n",
      "Epoch 34/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 1.1326 - sparse_categorical_accuracy: 0.7220 - val_loss: 1.1253 - val_sparse_categorical_accuracy: 0.7108\n",
      "Epoch 35/100\n",
      "944/944 [==============================] - 12s 12ms/step - loss: 1.1510 - sparse_categorical_accuracy: 0.7198 - val_loss: 1.1263 - val_sparse_categorical_accuracy: 0.7121\n",
      "Epoch 36/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 1.1350 - sparse_categorical_accuracy: 0.7230 - val_loss: 1.1266 - val_sparse_categorical_accuracy: 0.7107\n",
      "Epoch 37/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 1.1349 - sparse_categorical_accuracy: 0.7213 - val_loss: 1.1255 - val_sparse_categorical_accuracy: 0.7116\n",
      "Epoch 38/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 1.1260 - sparse_categorical_accuracy: 0.7246 - val_loss: 1.1185 - val_sparse_categorical_accuracy: 0.7140\n",
      "Epoch 39/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 1.1342 - sparse_categorical_accuracy: 0.7217 - val_loss: 1.1223 - val_sparse_categorical_accuracy: 0.7108\n",
      "Epoch 40/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 1.1223 - sparse_categorical_accuracy: 0.7219 - val_loss: 1.1225 - val_sparse_categorical_accuracy: 0.7113\n",
      "Epoch 41/100\n",
      "944/944 [==============================] - 13s 13ms/step - loss: 1.1182 - sparse_categorical_accuracy: 0.7210 - val_loss: 1.1215 - val_sparse_categorical_accuracy: 0.7117\n",
      "Epoch 42/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 1.1280 - sparse_categorical_accuracy: 0.7216 - val_loss: 1.1114 - val_sparse_categorical_accuracy: 0.7140\n",
      "Epoch 43/100\n",
      "944/944 [==============================] - 12s 12ms/step - loss: 1.1109 - sparse_categorical_accuracy: 0.7253 - val_loss: 1.1131 - val_sparse_categorical_accuracy: 0.7123\n",
      "Epoch 44/100\n",
      "944/944 [==============================] - 12s 12ms/step - loss: 1.1191 - sparse_categorical_accuracy: 0.7220 - val_loss: 1.1160 - val_sparse_categorical_accuracy: 0.7127\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944/944 [==============================] - 11s 11ms/step - loss: 1.1209 - sparse_categorical_accuracy: 0.7227 - val_loss: 1.1036 - val_sparse_categorical_accuracy: 0.7131\n",
      "Epoch 46/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.1253 - sparse_categorical_accuracy: 0.7227 - val_loss: 1.1156 - val_sparse_categorical_accuracy: 0.7127\n",
      "Epoch 47/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.1217 - sparse_categorical_accuracy: 0.7234 - val_loss: 1.1162 - val_sparse_categorical_accuracy: 0.7093\n",
      "Epoch 48/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.1052 - sparse_categorical_accuracy: 0.7239 - val_loss: 1.1061 - val_sparse_categorical_accuracy: 0.7127\n",
      "Epoch 49/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.1061 - sparse_categorical_accuracy: 0.7239 - val_loss: 1.1007 - val_sparse_categorical_accuracy: 0.7141\n",
      "Epoch 50/100\n",
      "944/944 [==============================] - 11s 12ms/step - loss: 1.1034 - sparse_categorical_accuracy: 0.7229 - val_loss: 1.1111 - val_sparse_categorical_accuracy: 0.7119\n",
      "Epoch 51/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.1163 - sparse_categorical_accuracy: 0.7210 - val_loss: 1.1146 - val_sparse_categorical_accuracy: 0.7112\n",
      "Epoch 52/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.1035 - sparse_categorical_accuracy: 0.7234 - val_loss: 1.1120 - val_sparse_categorical_accuracy: 0.7126\n",
      "Epoch 53/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.1049 - sparse_categorical_accuracy: 0.7231 - val_loss: 1.1141 - val_sparse_categorical_accuracy: 0.7113\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 2.100000056088902e-05.\n",
      "Epoch 54/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.1056 - sparse_categorical_accuracy: 0.7248 - val_loss: 1.1027 - val_sparse_categorical_accuracy: 0.7127\n",
      "Epoch 55/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.0929 - sparse_categorical_accuracy: 0.7252 - val_loss: 1.1028 - val_sparse_categorical_accuracy: 0.7133\n",
      "Epoch 56/100\n",
      "944/944 [==============================] - 11s 11ms/step - loss: 1.0988 - sparse_categorical_accuracy: 0.7258 - val_loss: 1.1016 - val_sparse_categorical_accuracy: 0.7124\n",
      "Score for fold 1: loss of 1.1006580591201782; sparse_categorical_accuracy of 71.40711545944214%\n"
     ]
    }
   ],
   "source": [
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "checkpoint_filepath='/tmp/checkpoint'\n",
    "# for train, test in kfold.split(X_train, y_train):\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(120,)),\n",
    "    tf.keras.layers.Dense(512),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(256),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(120, activation='sigmoid')\n",
    "])\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(7e-5), loss=loss_fn, \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "print('------------------------------------------------------------------------')\n",
    "print(f'Training for fold {fold_no} ...')\n",
    "history = model.fit(np.array(X_train), np.array(y_train),\n",
    "                    batch_size = 128,\n",
    "                    epochs=100,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=4,\n",
    "                    validation_data=(np.array(X_test), np.array(y_test)),\n",
    "                    callbacks=[earlystop1, earlystop2,\n",
    "                                tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                                save_best_only=True,\n",
    "                                                                save_weights_only=True,\n",
    "                                                                monitor='val_sparse_categorical_accuracy',\n",
    "                                                                mode='max')])\n",
    "model.load_weights(checkpoint_filepath)\n",
    "scores = model.evaluate(np.array(X_test), np.array(y_test), verbose=0)\n",
    "print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "acc_per_fold.append(scores[1] * 100)\n",
    "loss_per_fold.append(scores[0])\n",
    "fold_no += 1\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb666f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n"
     ]
    }
   ],
   "source": [
    "print(len(y.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "23d49382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/100\n",
      "944/944 [==============================] - 12s 12ms/step - loss: 5.1583 - sparse_categorical_accuracy: 0.0769 - val_loss: 3.0934 - val_sparse_categorical_accuracy: 0.3920\n",
      "Epoch 2/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 3.5581 - sparse_categorical_accuracy: 0.3160 - val_loss: 2.7269 - val_sparse_categorical_accuracy: 0.4569\n",
      "Epoch 3/100\n",
      "944/944 [==============================] - 12s 12ms/step - loss: 3.2543 - sparse_categorical_accuracy: 0.3480 - val_loss: 2.5417 - val_sparse_categorical_accuracy: 0.4847\n",
      "Epoch 4/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 3.0919 - sparse_categorical_accuracy: 0.3702 - val_loss: 2.4194 - val_sparse_categorical_accuracy: 0.5086\n",
      "Epoch 5/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 2.9245 - sparse_categorical_accuracy: 0.3870 - val_loss: 2.3321 - val_sparse_categorical_accuracy: 0.5209\n",
      "Epoch 6/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 2.8379 - sparse_categorical_accuracy: 0.3991 - val_loss: 2.2679 - val_sparse_categorical_accuracy: 0.5279\n",
      "Epoch 7/100\n",
      "944/944 [==============================] - 11s 12ms/step - loss: 2.7361 - sparse_categorical_accuracy: 0.4082 - val_loss: 2.2177 - val_sparse_categorical_accuracy: 0.5339\n",
      "Epoch 8/100\n",
      "944/944 [==============================] - 12s 12ms/step - loss: 2.6909 - sparse_categorical_accuracy: 0.4216 - val_loss: 2.1726 - val_sparse_categorical_accuracy: 0.5415\n",
      "Epoch 9/100\n",
      "944/944 [==============================] - 11s 12ms/step - loss: 2.6228 - sparse_categorical_accuracy: 0.4281 - val_loss: 2.1395 - val_sparse_categorical_accuracy: 0.5471\n",
      "Epoch 10/100\n",
      "944/944 [==============================] - 12s 12ms/step - loss: 2.5760 - sparse_categorical_accuracy: 0.4365 - val_loss: 2.1096 - val_sparse_categorical_accuracy: 0.5521\n",
      "Epoch 11/100\n",
      "944/944 [==============================] - 11s 12ms/step - loss: 2.5264 - sparse_categorical_accuracy: 0.4453 - val_loss: 2.0825 - val_sparse_categorical_accuracy: 0.5582\n",
      "Epoch 12/100\n",
      "944/944 [==============================] - 12s 12ms/step - loss: 2.4863 - sparse_categorical_accuracy: 0.4539 - val_loss: 2.0594 - val_sparse_categorical_accuracy: 0.5626\n",
      "Epoch 13/100\n",
      "944/944 [==============================] - 12s 12ms/step - loss: 2.4485 - sparse_categorical_accuracy: 0.4578 - val_loss: 2.0381 - val_sparse_categorical_accuracy: 0.5674\n",
      "Epoch 14/100\n",
      "944/944 [==============================] - 13s 13ms/step - loss: 2.4133 - sparse_categorical_accuracy: 0.4618 - val_loss: 2.0174 - val_sparse_categorical_accuracy: 0.5723\n",
      "Epoch 15/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 2.3868 - sparse_categorical_accuracy: 0.4732 - val_loss: 2.0023 - val_sparse_categorical_accuracy: 0.5765\n",
      "Epoch 16/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 2.4039 - sparse_categorical_accuracy: 0.4706 - val_loss: 1.9846 - val_sparse_categorical_accuracy: 0.5796\n",
      "Epoch 17/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 2.3392 - sparse_categorical_accuracy: 0.4824 - val_loss: 1.9687 - val_sparse_categorical_accuracy: 0.5840\n",
      "Epoch 18/100\n",
      "944/944 [==============================] - 12s 12ms/step - loss: 2.3139 - sparse_categorical_accuracy: 0.4867 - val_loss: 1.9561 - val_sparse_categorical_accuracy: 0.5870\n",
      "Epoch 19/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 2.2897 - sparse_categorical_accuracy: 0.4930 - val_loss: 1.9415 - val_sparse_categorical_accuracy: 0.5908\n",
      "Epoch 20/100\n",
      "944/944 [==============================] - 12s 12ms/step - loss: 2.2769 - sparse_categorical_accuracy: 0.4959 - val_loss: 1.9277 - val_sparse_categorical_accuracy: 0.5937\n",
      "Epoch 21/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 2.2495 - sparse_categorical_accuracy: 0.5007 - val_loss: 1.9156 - val_sparse_categorical_accuracy: 0.5962\n",
      "Epoch 22/100\n",
      "944/944 [==============================] - 11s 12ms/step - loss: 2.2538 - sparse_categorical_accuracy: 0.5039 - val_loss: 1.9052 - val_sparse_categorical_accuracy: 0.5978\n",
      "Epoch 23/100\n",
      "944/944 [==============================] - 11s 12ms/step - loss: 2.2256 - sparse_categorical_accuracy: 0.5106 - val_loss: 1.8936 - val_sparse_categorical_accuracy: 0.6009\n",
      "Epoch 24/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 2.2016 - sparse_categorical_accuracy: 0.5131 - val_loss: 1.8824 - val_sparse_categorical_accuracy: 0.6035\n",
      "Epoch 25/100\n",
      "944/944 [==============================] - 11s 12ms/step - loss: 2.1892 - sparse_categorical_accuracy: 0.5168 - val_loss: 1.8724 - val_sparse_categorical_accuracy: 0.6054\n",
      "Epoch 26/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 2.1822 - sparse_categorical_accuracy: 0.5184 - val_loss: 1.8634 - val_sparse_categorical_accuracy: 0.6079\n",
      "Epoch 27/100\n",
      "944/944 [==============================] - 12s 12ms/step - loss: 2.1762 - sparse_categorical_accuracy: 0.5210 - val_loss: 1.8552 - val_sparse_categorical_accuracy: 0.6094\n",
      "Epoch 28/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 2.1590 - sparse_categorical_accuracy: 0.5269 - val_loss: 1.8458 - val_sparse_categorical_accuracy: 0.6109\n",
      "Epoch 29/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 2.1448 - sparse_categorical_accuracy: 0.5283 - val_loss: 1.8387 - val_sparse_categorical_accuracy: 0.6127\n",
      "Epoch 30/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 2.1271 - sparse_categorical_accuracy: 0.5304 - val_loss: 1.8298 - val_sparse_categorical_accuracy: 0.6144\n",
      "Epoch 31/100\n",
      "944/944 [==============================] - 11s 12ms/step - loss: 2.1266 - sparse_categorical_accuracy: 0.5342 - val_loss: 1.8228 - val_sparse_categorical_accuracy: 0.6169\n",
      "Epoch 32/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 2.1133 - sparse_categorical_accuracy: 0.5378 - val_loss: 1.8132 - val_sparse_categorical_accuracy: 0.6183\n",
      "Epoch 33/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 2.1065 - sparse_categorical_accuracy: 0.5380 - val_loss: 1.8065 - val_sparse_categorical_accuracy: 0.6198\n",
      "Epoch 34/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 2.1052 - sparse_categorical_accuracy: 0.5405 - val_loss: 1.8003 - val_sparse_categorical_accuracy: 0.6208\n",
      "Epoch 35/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 2.0898 - sparse_categorical_accuracy: 0.5474 - val_loss: 1.7931 - val_sparse_categorical_accuracy: 0.6218\n",
      "Epoch 36/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 2.0774 - sparse_categorical_accuracy: 0.5484 - val_loss: 1.7860 - val_sparse_categorical_accuracy: 0.6241\n",
      "Epoch 37/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 2.0631 - sparse_categorical_accuracy: 0.5500 - val_loss: 1.7795 - val_sparse_categorical_accuracy: 0.6255\n",
      "Epoch 38/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 2.0430 - sparse_categorical_accuracy: 0.5516 - val_loss: 1.7731 - val_sparse_categorical_accuracy: 0.6272\n",
      "Epoch 39/100\n",
      "944/944 [==============================] - 13s 14ms/step - loss: 2.0436 - sparse_categorical_accuracy: 0.5539 - val_loss: 1.7677 - val_sparse_categorical_accuracy: 0.6285\n",
      "Epoch 40/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 2.0291 - sparse_categorical_accuracy: 0.5597 - val_loss: 1.7629 - val_sparse_categorical_accuracy: 0.6288\n",
      "Epoch 41/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 2.0323 - sparse_categorical_accuracy: 0.5570 - val_loss: 1.7577 - val_sparse_categorical_accuracy: 0.6301\n",
      "Epoch 42/100\n",
      "944/944 [==============================] - 13s 13ms/step - loss: 2.0100 - sparse_categorical_accuracy: 0.5620 - val_loss: 1.7499 - val_sparse_categorical_accuracy: 0.6318\n",
      "Epoch 43/100\n",
      "944/944 [==============================] - 11s 12ms/step - loss: 2.0102 - sparse_categorical_accuracy: 0.5631 - val_loss: 1.7462 - val_sparse_categorical_accuracy: 0.6322\n",
      "Epoch 44/100\n",
      "944/944 [==============================] - 12s 13ms/step - loss: 2.0011 - sparse_categorical_accuracy: 0.5647 - val_loss: 1.7399 - val_sparse_categorical_accuracy: 0.6340\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944/944 [==============================] - 10s 11ms/step - loss: 2.0098 - sparse_categorical_accuracy: 0.5646 - val_loss: 1.7353 - val_sparse_categorical_accuracy: 0.6347\n",
      "Epoch 46/100\n",
      "944/944 [==============================] - 9s 10ms/step - loss: 1.9935 - sparse_categorical_accuracy: 0.5669 - val_loss: 1.7297 - val_sparse_categorical_accuracy: 0.6359\n",
      "Epoch 47/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.9974 - sparse_categorical_accuracy: 0.5700 - val_loss: 1.7254 - val_sparse_categorical_accuracy: 0.6367\n",
      "Epoch 48/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.9921 - sparse_categorical_accuracy: 0.5722 - val_loss: 1.7206 - val_sparse_categorical_accuracy: 0.6380\n",
      "Epoch 49/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.9744 - sparse_categorical_accuracy: 0.5721 - val_loss: 1.7145 - val_sparse_categorical_accuracy: 0.6394\n",
      "Epoch 50/100\n",
      "944/944 [==============================] - 9s 10ms/step - loss: 1.9740 - sparse_categorical_accuracy: 0.5781 - val_loss: 1.7093 - val_sparse_categorical_accuracy: 0.6404\n",
      "Epoch 51/100\n",
      "944/944 [==============================] - 9s 10ms/step - loss: 1.9684 - sparse_categorical_accuracy: 0.5772 - val_loss: 1.7046 - val_sparse_categorical_accuracy: 0.6405\n",
      "Epoch 52/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.9579 - sparse_categorical_accuracy: 0.5775 - val_loss: 1.7024 - val_sparse_categorical_accuracy: 0.6402\n",
      "Epoch 53/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.9499 - sparse_categorical_accuracy: 0.5782 - val_loss: 1.6989 - val_sparse_categorical_accuracy: 0.6409\n",
      "Epoch 54/100\n",
      "944/944 [==============================] - 9s 10ms/step - loss: 1.9365 - sparse_categorical_accuracy: 0.5813 - val_loss: 1.6944 - val_sparse_categorical_accuracy: 0.6425\n",
      "Epoch 55/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.9427 - sparse_categorical_accuracy: 0.5827 - val_loss: 1.6897 - val_sparse_categorical_accuracy: 0.6442\n",
      "Epoch 56/100\n",
      "944/944 [==============================] - 11s 11ms/step - loss: 1.9332 - sparse_categorical_accuracy: 0.5828 - val_loss: 1.6857 - val_sparse_categorical_accuracy: 0.6450\n",
      "Epoch 57/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.9103 - sparse_categorical_accuracy: 0.5864 - val_loss: 1.6817 - val_sparse_categorical_accuracy: 0.6456\n",
      "Epoch 58/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.9271 - sparse_categorical_accuracy: 0.5868 - val_loss: 1.6788 - val_sparse_categorical_accuracy: 0.6467\n",
      "Epoch 59/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.9026 - sparse_categorical_accuracy: 0.5907 - val_loss: 1.6722 - val_sparse_categorical_accuracy: 0.6478\n",
      "Epoch 60/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.9140 - sparse_categorical_accuracy: 0.5900 - val_loss: 1.6689 - val_sparse_categorical_accuracy: 0.6485\n",
      "Epoch 61/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.8994 - sparse_categorical_accuracy: 0.5907 - val_loss: 1.6658 - val_sparse_categorical_accuracy: 0.6494\n",
      "Epoch 62/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.9011 - sparse_categorical_accuracy: 0.5922 - val_loss: 1.6626 - val_sparse_categorical_accuracy: 0.6498\n",
      "Epoch 63/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.8978 - sparse_categorical_accuracy: 0.5962 - val_loss: 1.6592 - val_sparse_categorical_accuracy: 0.6502\n",
      "Epoch 64/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.8940 - sparse_categorical_accuracy: 0.5935 - val_loss: 1.6567 - val_sparse_categorical_accuracy: 0.6500\n",
      "Epoch 65/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.8786 - sparse_categorical_accuracy: 0.5980 - val_loss: 1.6527 - val_sparse_categorical_accuracy: 0.6509\n",
      "Epoch 66/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.8704 - sparse_categorical_accuracy: 0.6002 - val_loss: 1.6504 - val_sparse_categorical_accuracy: 0.6514\n",
      "Epoch 67/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.8758 - sparse_categorical_accuracy: 0.6014 - val_loss: 1.6466 - val_sparse_categorical_accuracy: 0.6521\n",
      "Epoch 68/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.8752 - sparse_categorical_accuracy: 0.5978 - val_loss: 1.6429 - val_sparse_categorical_accuracy: 0.6533\n",
      "Epoch 69/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.8628 - sparse_categorical_accuracy: 0.6021 - val_loss: 1.6394 - val_sparse_categorical_accuracy: 0.6537\n",
      "Epoch 70/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.8687 - sparse_categorical_accuracy: 0.6020 - val_loss: 1.6360 - val_sparse_categorical_accuracy: 0.6541\n",
      "Epoch 71/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.8503 - sparse_categorical_accuracy: 0.6055 - val_loss: 1.6335 - val_sparse_categorical_accuracy: 0.6543\n",
      "Epoch 72/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.8559 - sparse_categorical_accuracy: 0.6047 - val_loss: 1.6313 - val_sparse_categorical_accuracy: 0.6548\n",
      "Epoch 73/100\n",
      "944/944 [==============================] - 9s 10ms/step - loss: 1.8363 - sparse_categorical_accuracy: 0.6066 - val_loss: 1.6274 - val_sparse_categorical_accuracy: 0.6557\n",
      "Epoch 74/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.8477 - sparse_categorical_accuracy: 0.6053 - val_loss: 1.6243 - val_sparse_categorical_accuracy: 0.6562\n",
      "Epoch 75/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.8321 - sparse_categorical_accuracy: 0.6089 - val_loss: 1.6210 - val_sparse_categorical_accuracy: 0.6567\n",
      "Epoch 76/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.8344 - sparse_categorical_accuracy: 0.6127 - val_loss: 1.6190 - val_sparse_categorical_accuracy: 0.6572\n",
      "Epoch 77/100\n",
      "944/944 [==============================] - 11s 11ms/step - loss: 1.8260 - sparse_categorical_accuracy: 0.6133 - val_loss: 1.6160 - val_sparse_categorical_accuracy: 0.6573\n",
      "Epoch 78/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.8262 - sparse_categorical_accuracy: 0.6101 - val_loss: 1.6131 - val_sparse_categorical_accuracy: 0.6578\n",
      "Epoch 79/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.8333 - sparse_categorical_accuracy: 0.6122 - val_loss: 1.6100 - val_sparse_categorical_accuracy: 0.6581\n",
      "Epoch 80/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.8107 - sparse_categorical_accuracy: 0.6126 - val_loss: 1.6073 - val_sparse_categorical_accuracy: 0.6584\n",
      "Epoch 81/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.8066 - sparse_categorical_accuracy: 0.6137 - val_loss: 1.6054 - val_sparse_categorical_accuracy: 0.6591\n",
      "Epoch 82/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.8176 - sparse_categorical_accuracy: 0.6174 - val_loss: 1.6044 - val_sparse_categorical_accuracy: 0.6588\n",
      "Epoch 83/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.8009 - sparse_categorical_accuracy: 0.6143 - val_loss: 1.5998 - val_sparse_categorical_accuracy: 0.6601\n",
      "Epoch 84/100\n",
      "944/944 [==============================] - 11s 11ms/step - loss: 1.8062 - sparse_categorical_accuracy: 0.6160 - val_loss: 1.5992 - val_sparse_categorical_accuracy: 0.6603\n",
      "Epoch 85/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.7934 - sparse_categorical_accuracy: 0.6187 - val_loss: 1.5944 - val_sparse_categorical_accuracy: 0.6611\n",
      "Epoch 86/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.7899 - sparse_categorical_accuracy: 0.6199 - val_loss: 1.5932 - val_sparse_categorical_accuracy: 0.6611\n",
      "Epoch 87/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.8028 - sparse_categorical_accuracy: 0.6186 - val_loss: 1.5906 - val_sparse_categorical_accuracy: 0.6615\n",
      "Epoch 88/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.7835 - sparse_categorical_accuracy: 0.6193 - val_loss: 1.5884 - val_sparse_categorical_accuracy: 0.6619\n",
      "Epoch 89/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.7941 - sparse_categorical_accuracy: 0.6228 - val_loss: 1.5849 - val_sparse_categorical_accuracy: 0.6626\n",
      "Epoch 90/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.7838 - sparse_categorical_accuracy: 0.6241 - val_loss: 1.5826 - val_sparse_categorical_accuracy: 0.6629\n",
      "Epoch 91/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.7870 - sparse_categorical_accuracy: 0.6222 - val_loss: 1.5810 - val_sparse_categorical_accuracy: 0.6631\n",
      "Epoch 92/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.7771 - sparse_categorical_accuracy: 0.6238 - val_loss: 1.5785 - val_sparse_categorical_accuracy: 0.6635\n",
      "Epoch 93/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.7683 - sparse_categorical_accuracy: 0.6253 - val_loss: 1.5748 - val_sparse_categorical_accuracy: 0.6640\n",
      "Epoch 94/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.7491 - sparse_categorical_accuracy: 0.6266 - val_loss: 1.5721 - val_sparse_categorical_accuracy: 0.6642\n",
      "Epoch 95/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.7704 - sparse_categorical_accuracy: 0.6266 - val_loss: 1.5702 - val_sparse_categorical_accuracy: 0.6644\n",
      "Epoch 96/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.7602 - sparse_categorical_accuracy: 0.6281 - val_loss: 1.5681 - val_sparse_categorical_accuracy: 0.6646\n",
      "Epoch 97/100\n",
      "944/944 [==============================] - 9s 10ms/step - loss: 1.7751 - sparse_categorical_accuracy: 0.6262 - val_loss: 1.5665 - val_sparse_categorical_accuracy: 0.6646\n",
      "Epoch 98/100\n",
      "944/944 [==============================] - 10s 11ms/step - loss: 1.7407 - sparse_categorical_accuracy: 0.6295 - val_loss: 1.5643 - val_sparse_categorical_accuracy: 0.6648\n",
      "Epoch 99/100\n",
      "944/944 [==============================] - 9s 10ms/step - loss: 1.7568 - sparse_categorical_accuracy: 0.6296 - val_loss: 1.5614 - val_sparse_categorical_accuracy: 0.6651\n",
      "Epoch 100/100\n",
      "944/944 [==============================] - 10s 10ms/step - loss: 1.7541 - sparse_categorical_accuracy: 0.6287 - val_loss: 1.5589 - val_sparse_categorical_accuracy: 0.6655\n",
      "Score for fold 1: loss of 1.5588579177856445; sparse_categorical_accuracy of 66.5535032749176%\n"
     ]
    }
   ],
   "source": [
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "checkpoint_filepath='/tmp/checkpoint'\n",
    "# for train, test in kfold.split(X_train, y_train):\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(120,)),\n",
    "    tf.keras.layers.Dense(512),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(256),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(120, activation='sigmoid')\n",
    "])\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(7e-5), loss=loss_fn, \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "print('------------------------------------------------------------------------')\n",
    "print(f'Training for fold {fold_no} ...')\n",
    "history = model.fit(np.array(X_train), np.array(y_train),\n",
    "                    batch_size = 128,\n",
    "                    epochs=100,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=4,\n",
    "                    validation_data=(np.array(X_test), np.array(y_test)),\n",
    "                    callbacks=[earlystop1, earlystop2,\n",
    "                                tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                                save_best_only=True,\n",
    "                                                                save_weights_only=True,\n",
    "                                                                monitor='val_sparse_categorical_accuracy',\n",
    "                                                                mode='max')])\n",
    "model.load_weights(checkpoint_filepath)\n",
    "scores = model.evaluate(np.array(X_test), np.array(y_test), verbose=0)\n",
    "print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "acc_per_fold.append(scores[1] * 100)\n",
    "loss_per_fold.append(scores[0])\n",
    "fold_no += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6532c5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
