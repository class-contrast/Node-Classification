{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZ1_CCkjZ5BZ"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import os\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6Hbkb-zSHWa",
        "outputId": "5fe4d9d5-b603-4439-a46c-8c54381d4708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ogb\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (4.65.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.26.15)\n",
            "Collecting outdated>=0.2.0 (from ogb)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.27.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n",
            "Building wheels for collected packages: torch_geometric, littleutils\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910459 sha256=6159a820133c9a243e3a21ef7bc992c6a8b3dfe8e3d8b269bb7e2049432c4eea\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7029 sha256=bdcbf700a1ab65d57ffe877b9b06e232ad3c0c698ddc716804d6b774110074c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built torch_geometric littleutils\n",
            "Installing collected packages: littleutils, outdated, torch_geometric, ogb\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.6 outdated-0.2.2 torch_geometric-2.3.1\n"
          ]
        }
      ],
      "source": [
        "%pip install ogb torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8jmDqzL0iOo"
      },
      "outputs": [],
      "source": [
        "import ogb\n",
        "from ogb.nodeproppred import NodePropPredDataset \n",
        "from torch_geometric.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swmrwtChzcuy"
      },
      "source": [
        "#OGBN Mag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tASd3M0JSCNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5defec10-2be1-433e-cf10-7b332db28d9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/mag.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 0.40 GB: 100%|██████████| 413/413 [00:30<00:00, 13.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /Users/joshem/PhD Research/Data/mag.zip\n",
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 7810.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#H:\\\\PhD Research\\Data\\PROTEINS\\PROTEINS_node_attributes.txt\n",
        "# Download and process data at './dataset/ogbg_molhiv/'\n",
        "dataset = NodePropPredDataset(name = \"ogbn-mag\", root = '/Users/joshem/PhD Research/Data/')\n",
        "split_idx = dataset.get_idx_split()\n",
        "train_idx, valid_idx, test_idx = split_idx[\"train\"]['paper'], split_idx[\"valid\"]['paper'], split_idx[\"test\"]['paper']\n",
        "graph = dataset[0] # pyg graph object\n",
        "\n",
        "Node_Class = graph[1]['paper'][:,0]\n",
        "Node_Year=graph[0]['node_year']['paper']\n",
        "E=graph[0]['edge_index_dict'][('paper', 'cites', 'paper')]\n",
        "n = graph[0]['num_nodes_dict']['paper']\n",
        "\n",
        "F_vec_url = 'https://utdallas.box.com/shared/static/19yvbjlxzkwhjft5k9r9sfu23pkvm4aa.zip'\n",
        "F_vec_file = '/content/Feature_nbd_mag.csv'\n",
        "Node_Fec = list(graph[0]['node_feat_dict']['paper'])\n",
        "Node_Year_list=list(Node_Year[:,0])\n",
        "num_cls = max(Node_Class) + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGh7KdfTzkOB"
      },
      "source": [
        "#OGBN Arxiv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5A0hTGGwzwmu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58ea3786-9e6c-4f41-88d2-784cbffb1fc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 0.08 GB: 100%|██████████| 81/81 [00:08<00:00,  9.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /Users/joshem/PhD Research/Data/arxiv.zip\n",
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 10565.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "dataset = NodePropPredDataset(name = \"ogbn-arxiv\", root = '/Users/joshem/PhD Research/Data/')\n",
        "split_idx = dataset.get_idx_split()\n",
        "train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
        "graph = dataset[0] # pyg graph object\n",
        "\n",
        "Node_Class = graph[1][:,0]\n",
        "Node_Year=graph[0]['node_year']\n",
        "E=graph[0]['edge_index']\n",
        "n = graph[0]['num_nodes']\n",
        "\n",
        "F_vec_url = 'https://utdallas.box.com/shared/static/4tsidulh34mrqa1fiemejvk7xckp9not.zip'\n",
        "F_vec_file = '/content/Feature_OGB_Arxiv.csv'\n",
        "Node_Fec = list(graph[0]['node_feat'])\n",
        "Node_Year_list=list(Node_Year[:,0])\n",
        "num_cls = max(Node_Class)+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0xomy2Sc_gF"
      },
      "source": [
        "# OGBN Proteins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt0QAcjcdCis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5c7ede2-01fb-4fda-be33-a01abf6fdfcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/proteins.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 0.21 GB: 100%|██████████| 216/216 [00:18<00:00, 11.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting H:\\PhD Research\\Python code\\OGB/proteins.zip\n",
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n"
          ]
        }
      ],
      "source": [
        "dataset = NodePropPredDataset(name = \"ogbn-proteins\", root = 'H:\\\\PhD Research\\Python code\\OGB')\n",
        "split_idx = dataset.get_idx_split()\n",
        "train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
        "graph = dataset[0] # pyg graph object\n",
        "\n",
        "Node_Class = graph[1]\n",
        "E = graph[0]['edge_index']\n",
        "n = graph[0]['num_nodes']\n",
        "num_cls = Node_Class.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8J1vbV_oIFq",
        "outputId": "473e918d-674d-4c25-98b1-22e90415dc7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "736389"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6p38uWXgA-c"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('https://utdallas.box.com/shared/static/ukzv4nd8jjg4y8zqb4y66ekmhw8fmfvj.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "FgXjtQDTgCZ0",
        "outputId": "5acc804c-3e63-4cab-ba41-20108f34e684"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       1      2      3      4      5      6      7      8      9     10  ...  \\\n",
              "0  311.0  308.0  235.0  281.0  275.0  128.0  272.0  113.0  256.0  187.0  ...   \n",
              "1    4.0    4.0    4.0    4.0    4.0    3.0    3.0    3.0    3.0    3.0  ...   \n",
              "2  105.0   89.0   70.0   62.0   66.0   34.0   49.0   31.0   44.0   39.0  ...   \n",
              "3  426.0  412.0  307.0  372.0  350.0  210.0  333.0  191.0  322.0  240.0  ...   \n",
              "4  360.0  290.0  258.0  229.0  241.0  139.0  166.0  133.0  161.0  178.0  ...   \n",
              "\n",
              "     999    1000   1001   1002   1003   1004   1005   1006   1007  1008  \n",
              "0  5.979   0.008  0.003  0.003  0.462  0.983  0.003  2.432  0.000   0.0  \n",
              "1  0.000   0.000  0.000  0.000  0.968  0.000  0.000  0.000  0.000   0.0  \n",
              "2  1.133   1.122  0.000  0.581  5.428  0.465  0.000  0.584  0.000   0.0  \n",
              "3  8.860  10.153  0.000  1.170  1.523  3.057  0.000  2.335  0.000   0.0  \n",
              "4  5.963   3.508  0.000  1.496  0.680  4.017  0.000  0.714  0.152   0.0  \n",
              "\n",
              "[5 rows x 1008 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82305492-949b-48a4-a5c6-0240245ead23\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>999</th>\n",
              "      <th>1000</th>\n",
              "      <th>1001</th>\n",
              "      <th>1002</th>\n",
              "      <th>1003</th>\n",
              "      <th>1004</th>\n",
              "      <th>1005</th>\n",
              "      <th>1006</th>\n",
              "      <th>1007</th>\n",
              "      <th>1008</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>311.0</td>\n",
              "      <td>308.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>281.0</td>\n",
              "      <td>275.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>272.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>256.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.979</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.462</td>\n",
              "      <td>0.983</td>\n",
              "      <td>0.003</td>\n",
              "      <td>2.432</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.968</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>105.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.133</td>\n",
              "      <td>1.122</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.581</td>\n",
              "      <td>5.428</td>\n",
              "      <td>0.465</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.584</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>426.0</td>\n",
              "      <td>412.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>372.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8.860</td>\n",
              "      <td>10.153</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.170</td>\n",
              "      <td>1.523</td>\n",
              "      <td>3.057</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2.335</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>360.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>258.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>241.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>166.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.963</td>\n",
              "      <td>3.508</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.496</td>\n",
              "      <td>0.680</td>\n",
              "      <td>4.017</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.714</td>\n",
              "      <td>0.152</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1008 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82305492-949b-48a4-a5c6-0240245ead23')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82305492-949b-48a4-a5c6-0240245ead23 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82305492-949b-48a4-a5c6-0240245ead23');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAjnowAC01Gv",
        "outputId": "643a8f1f-93c7-4996-9107-9c1026548908"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'edge_index_dict': {('author',\n",
              "    'affiliated_with',\n",
              "    'institution'): array([[      0,       1,       2, ..., 1134645, 1134647, 1134648],\n",
              "          [    845,     996,    3197, ...,    5189,    4668,    4668]]),\n",
              "   ('author',\n",
              "    'writes',\n",
              "    'paper'): array([[      0,       0,       0, ..., 1134647, 1134648, 1134648],\n",
              "          [  19703,  289285,  311768, ...,  657395,  671118,  719594]]),\n",
              "   ('paper',\n",
              "    'cites',\n",
              "    'paper'): array([[     0,      0,      0, ..., 736388, 736388, 736388],\n",
              "          [    88,  27449, 121051, ..., 421711, 427339, 439864]]),\n",
              "   ('paper',\n",
              "    'has_topic',\n",
              "    'field_of_study'): array([[     0,      0,      0, ..., 736388, 736388, 736388],\n",
              "          [   145,   2215,   3205, ...,  21458,  22283,  31934]])},\n",
              "  'edge_feat_dict': None,\n",
              "  'node_feat_dict': {'paper': array([[-0.095379,  0.040758, -0.210948, ...,  0.061569, -0.027663,\n",
              "           -0.133832],\n",
              "          [-0.151047, -0.107315, -0.221964, ...,  0.345754, -0.027737,\n",
              "           -0.218527],\n",
              "          [-0.114799, -0.175982, -0.260556, ...,  0.173058, -0.156445,\n",
              "           -0.277954],\n",
              "          ...,\n",
              "          [ 0.022815, -0.0865  ,  0.098138, ..., -0.054667, -0.207721,\n",
              "           -0.230458],\n",
              "          [-0.289148, -0.202898, -0.152454, ...,  0.104207,  0.204123,\n",
              "           -0.352805],\n",
              "          [-0.088966, -0.034788, -0.264226, ...,  0.260077, -0.087453,\n",
              "           -0.517127]], dtype=float32)},\n",
              "  'num_nodes_dict': {'author': 1134649,\n",
              "   'field_of_study': 59965,\n",
              "   'institution': 8740,\n",
              "   'paper': 736389},\n",
              "  'node_year': {'paper': array([[2015],\n",
              "          [2012],\n",
              "          [2012],\n",
              "          ...,\n",
              "          [2016],\n",
              "          [2017],\n",
              "          [2014]])},\n",
              "  'edge_reltype': {('author',\n",
              "    'affiliated_with',\n",
              "    'institution'): array([[0],\n",
              "          [0],\n",
              "          [0],\n",
              "          ...,\n",
              "          [0],\n",
              "          [0],\n",
              "          [0]]),\n",
              "   ('author',\n",
              "    'writes',\n",
              "    'paper'): array([[3],\n",
              "          [3],\n",
              "          [3],\n",
              "          ...,\n",
              "          [3],\n",
              "          [3],\n",
              "          [3]]),\n",
              "   ('paper',\n",
              "    'cites',\n",
              "    'paper'): array([[1],\n",
              "          [1],\n",
              "          [1],\n",
              "          ...,\n",
              "          [1],\n",
              "          [1],\n",
              "          [1]]),\n",
              "   ('paper',\n",
              "    'has_topic',\n",
              "    'field_of_study'): array([[2],\n",
              "          [2],\n",
              "          [2],\n",
              "          ...,\n",
              "          [2],\n",
              "          [2],\n",
              "          [2]])}},\n",
              " {'paper': array([[246],\n",
              "         [131],\n",
              "         [189],\n",
              "         ...,\n",
              "         [266],\n",
              "         [289],\n",
              "         [  1]])})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGd6K_7qIwxc"
      },
      "source": [
        "# Creating Neighborhood Feature Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2UTao5-PKZ0",
        "outputId": "3c9a61ee-33ee-42d1-ae90-d6cec6114e06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[     0      0      0 ... 736388 736388 736388]\n",
            "[    88  27449 121051 ... 421711 427339 439864]\n"
          ]
        }
      ],
      "source": [
        "EdgeL=E[0]\n",
        "EdgeR=E[1]\n",
        "print(EdgeL)\n",
        "print(EdgeR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAYhC_zJPN2n",
        "outputId": "9f6d7696-42ce-4a3a-9c44-3020ca6a8b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[246 131 189 ... 266 289   1]\n"
          ]
        }
      ],
      "source": [
        "N_class_train= Node_Class.copy()\n",
        "for d in test_idx:\n",
        "    N_class_train[d]=500\n",
        "print(N_class_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nWQwwcBsZRY",
        "outputId": "156da39a-445f-4a5f-fcde-178c93e06eab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "EdgeL[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyUg19QdsGGl",
        "outputId": "7f74ff2d-029e-41be-afe7-cc7a668c5ea8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([    397, 1670849]),)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.where(EdgeR==0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZT824P3s-oP",
        "outputId": "117328f2-1564-4f69-fbdb-28afec382437"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "348"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(Node_Class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "iW2Q_PCyb8S0",
        "outputId": "e3ba3523-0648-486c-b10a-c07c1cf76837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing file 14785 (0%)"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-bad72bde84c7>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mF_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cls\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEdgeL\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\rProcessing file {} ({}%)\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEdgeL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEdgeL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEdgeR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mF_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNode_Class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#@title For Mag and Arxiv\n",
        "import time\n",
        "start_time = time.time()\n",
        "F_vec = np.zeros((n, num_cls*2))\n",
        "for i in range(len(EdgeL)):\n",
        "  print(\"\\rProcessing file {} ({}%)\".format(i, 100*i//len(EdgeL)), end='', flush=True)\n",
        "  left, right = EdgeL[i], EdgeR[i]\n",
        "  F_vec[left][Node_Class[right]*2] += 1\n",
        "  F_vec[right][Node_Class[left]*2+1] += 1\n",
        "end_time = time.time()\n",
        "print(f'--- {(end_time-start_time)/3600} hours ---')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpPLHDMh7OdW",
        "outputId": "43261dc3-2deb-4e77-9933-433fd15f7bd3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7145660"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph[0]['edge_index_dict'][('author', 'writes', 'paper')].shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Smr5evCq8b_Z"
      },
      "outputs": [],
      "source": [
        "author_edges = graph[0]['edge_index_dict'][('author', 'writes', 'paper')]\n",
        "A_Edge, P_Edge = author_edges\n",
        "num_authors = graph[0]['num_nodes_dict']['author']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P906iPkQOYRE",
        "outputId": "4254ff4a-841a-4924-c195-a29db6e44794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWOm2fjfliu2",
        "outputId": "ddea70f1-7a15-4d00-d518-97d28cc8ad45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "79122504"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(graph[0]['edge_feat'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqQQCYGdl_n0",
        "outputId": "d0c78520-5510-4e9d-c9b3-3749c387f5df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.501, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph[0]['edge_feat'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "KoaW9zrNeVTS",
        "outputId": "22cd8ee2-bfd7-40b0-d4a1-526a556c0ad4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing file 412966 (0%)"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-630a3b304a76>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mF_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEdgeL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\rProcessing file {} ({}%)\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEdgeL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEdgeL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEdgeR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mF_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mNode_Class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#@title For Proteins\n",
        "import time\n",
        "start_time = time.time()\n",
        "E_feats = graph[0]['edge_feat']\n",
        "F_vec = [[0 for _ in range(num_cls*9)] for _ in range(n)]\n",
        "for i in range(0, len(EdgeL), 2):\n",
        "  print(\"\\rProcessing file {} ({}%)\".format(i, 100*i//len(EdgeL)), end='', flush=True)\n",
        "  e_feat = np.insert(E_feats[i], 0, 1)\n",
        "  left, right = EdgeL[i], EdgeR[i]\n",
        "  vec1 = np.concatenate([Node_Class[right] * e_f for e_f in e_feat])\n",
        "  vec2 = np.concatenate([Node_Class[left] * e_f for e_f in e_feat])\n",
        "  F_vec[left] += vec1\n",
        "  F_vec[right] += vec2\n",
        "\n",
        "end_time = time.time()\n",
        "print(f'--- {(end_time-start_time)/3600} hours ---')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9c1wfEtPFmc",
        "outputId": "9ed6bf0d-73d9-4ff5-d99a-fac211cbd8be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rProcessing file 0 (0%)(array([0, 1, 2, 3, 4]),)\n",
            "(array([    397, 1670849]),)\n",
            "[246, 309, 146, 309, 324]\n",
            "[246, 146]\n",
            "(array([292, 293, 492, 493, 618, 648]),)\n",
            "--- 1.8209682570563423e-05 hours ---\n"
          ]
        }
      ],
      "source": [
        "def CountX(lst,x):\n",
        "    return(lst.count(x))\n",
        "\n",
        "start_time = time.time()\n",
        "F_vec=[]\n",
        "for i in range(n):\n",
        "    print(\"\\rProcessing file {} ({}%)\".format(i, 100*i//n), end='', flush=True)\n",
        "    node_F=[]\n",
        "    list_out=[]\n",
        "    list_In=[]\n",
        "    #S_nbd_out=[]\n",
        "    #S_nbd_in=[]\n",
        "    indx=np.where(EdgeL==i)\n",
        "    indxIn=np.where(EdgeR==i)\n",
        "    #print(indx)\n",
        "    for j in indx[0]:\n",
        "        list_out.append(N_class_train[EdgeR[j]])\n",
        "   # indx[0].clear()\n",
        "    for k in indxIn[0]:\n",
        "        list_In.append(N_class_train[EdgeL[k]])\n",
        "   # indxIn[0].clear()\n",
        "\n",
        "    # print(indx)\n",
        "    # print(indxIn)\n",
        "    # print(list_out)\n",
        "    # print(list_In)\n",
        "                \n",
        "                \n",
        "    for d in range(max(Node_Class)+1):\n",
        "        node_F.append(CountX(list_out,d))\n",
        "        node_F.append(CountX(list_In,d))\n",
        "    F_vec.append(node_F)\n",
        "print(np.where(np.array(F_vec[0])!=0))\n",
        "data = pd.DataFrame(F_vec)\n",
        "# data.insert(loc=int(num_cls*2), column='Class', value=Node_Class)\n",
        "end_time = time.time()\n",
        "print(f'--- {(end_time-start_time)/3600} hours ---')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGQH3bCuIlge"
      },
      "source": [
        "# Retrieving Saved Neighborhood Feature Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHsJhdrhD_1O"
      },
      "outputs": [],
      "source": [
        "import requests, zipfile, io\n",
        "r = requests.get(F_vec_url, stream=True)\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall('/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muYHE7IDDPjx"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(F_vec_file, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "XICOneMaTqxb",
        "outputId": "fc69fdd6-5ea4-4052-e90f-5e72ec51296e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  9  ...  689  690  691  692  693  694  695  696  \\\n",
              "0  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
              "1  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
              "2  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
              "3  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
              "4  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
              "\n",
              "   697  Class  \n",
              "0    0    246  \n",
              "1    0    131  \n",
              "2    0    189  \n",
              "3    0    131  \n",
              "4    0     95  \n",
              "\n",
              "[5 rows x 699 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b860c37a-7e06-45f7-8915-4249974adf55\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>689</th>\n",
              "      <th>690</th>\n",
              "      <th>691</th>\n",
              "      <th>692</th>\n",
              "      <th>693</th>\n",
              "      <th>694</th>\n",
              "      <th>695</th>\n",
              "      <th>696</th>\n",
              "      <th>697</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 699 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b860c37a-7e06-45f7-8915-4249974adf55')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b860c37a-7e06-45f7-8915-4249974adf55 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b860c37a-7e06-45f7-8915-4249974adf55');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysqzOKI78huE",
        "outputId": "87a5e112-21ca-46ea-b1c3-928eff482a13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing file 4037518 (56%)"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "author_vecs = np.zeros((num_authors, num_cls))\n",
        "for i in range(len(A_Edge)):\n",
        "  print(\"\\rProcessing file {} ({}%)\".format(i, 100*i//len(A_Edge)), end='', flush=True)\n",
        "  auth, paper = A_Edge[i], P_Edge[i]\n",
        "  if N_class_train[paper] == 500:\n",
        "    continue\n",
        "  author_vecs[auth][Node_Class[paper]] += 1\n",
        "# for i in range(len(author_vecs)):\n",
        "#   author_vecs[i] /= np.linalg.norm(author_vecs, ord=1)\n",
        "compression_opts = dict(method='zip',\n",
        "                        archive_name='Author_vecs.csv')  \n",
        "author_df = pd.DataFrame(author_vecs)\n",
        "author_df.to_csv('/content/drive/MyDrive/Author_vecs.zip', compression=compression_opts)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f'--- {(end_time-start_time)/3600} hours ---')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4yCEx0rOXhe"
      },
      "outputs": [],
      "source": [
        "#@title Reading Author vecs\n",
        "z = zipfile.ZipFile('/content/drive/MyDrive/Author_vecs.zip')\n",
        "z.extractall('/content')\n",
        "author_df = pd.read_csv('/content/Author_vecs.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xP23QmlfPg_v"
      },
      "outputs": [],
      "source": [
        "author_vecs = author_df.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSAyNUfJPk_T",
        "outputId": "e37e66d9-d2b4-4ff4-90b6-89351593218f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1134649, 349)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "author_vecs.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = zipfile.ZipFile('/content/drive/MyDrive/Topic_vecs.zip')\n",
        "z.extractall('/content')\n",
        "topic_df = pd.read_csv('/content/Topic_vecs.csv', index_col=0)"
      ],
      "metadata": {
        "id": "ZAWt4ok1Tf5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_vecs = topic_df.to_numpy()"
      ],
      "metadata": {
        "id": "sJNRFgYKT43H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtwFSk8eKFlJ"
      },
      "outputs": [],
      "source": [
        "data['Class'] = Node_Class"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = zipfile.ZipFile('/content/drive/MyDrive/Paper_topic_vecs_max.zip')\n",
        "z.extractall('/content')\n",
        "paper_topic_df = pd.read_csv('/content/Paper_topic_vecs_max.csv', index_col=0)"
      ],
      "metadata": {
        "id": "DgxEMU69GzUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = zipfile.ZipFile('/content/drive/MyDrive/Paper_auth_vecs_max.zip')\n",
        "z.extractall('/content')\n",
        "paper_auth_df = pd.read_csv('/content/Paper_auth_vecs_max.csv', index_col=0)"
      ],
      "metadata": {
        "id": "vxpjm8BLITpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(paper_topic_df['0'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgwAeqXLNDu7",
        "outputId": "d867ae0a-fe27-4393-9873-953244bbcf60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2131.0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Qcq7Je1F10_"
      },
      "source": [
        "#Creating Node Description Feature Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzk5l-85BAqt"
      },
      "outputs": [],
      "source": [
        "feature_names = [\"w_{}\".format(ii) for ii in range(len(Node_Fec[0]))]\n",
        "Node_Fec = pd.DataFrame(Node_Fec,columns=feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiKcKi-DBOTZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "87dc8347-8e9f-4b37-c019-8fb286b22660"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        w_0       w_1       w_2       w_3       w_4       w_5       w_6  \\\n",
              "0 -0.057943 -0.052530 -0.072603 -0.026555  0.130435 -0.241386 -0.449242   \n",
              "1 -0.124500 -0.070665 -0.325202  0.007779 -0.001559  0.074189 -0.191013   \n",
              "2 -0.080242 -0.023328 -0.183787 -0.180707  0.075765 -0.125818 -0.394573   \n",
              "3 -0.145044  0.054915 -0.126666  0.039971 -0.055909 -0.101278 -0.339202   \n",
              "4 -0.071154  0.070766 -0.281432 -0.161892 -0.165246 -0.029116 -0.338593   \n",
              "\n",
              "        w_7       w_8       w_9  ...     w_118     w_119     w_120     w_121  \\\n",
              "0 -0.018443 -0.087218  0.112320  ...  0.211490 -0.226118 -0.185603  0.053230   \n",
              "1  0.049689  0.026369  0.099364  ...  0.106316  0.052926 -0.258378  0.021567   \n",
              "2 -0.219078 -0.108931  0.056966  ...  0.019453 -0.070291 -0.177562 -0.214012   \n",
              "3 -0.115801 -0.080058 -0.001633  ... -0.065752  0.042735  0.066338 -0.226921   \n",
              "4 -0.138727  0.100015  0.132794  ... -0.056130  0.047475 -0.263795  0.026462   \n",
              "\n",
              "      w_122     w_123     w_124     w_125     w_126     w_127  \n",
              "0  0.332873  0.104175  0.007408  0.173364 -0.172796 -0.140059  \n",
              "1  0.281503 -0.173423  0.202082  0.068524 -0.372111 -0.301036  \n",
              "2  0.182186 -0.121589 -0.073642  0.109919  0.117589 -0.139883  \n",
              "3  0.188418 -0.017295  0.063449  0.017816  0.085364 -0.081804  \n",
              "4  0.376349 -0.253772  0.084472  0.098033 -0.075347 -0.111687  \n",
              "\n",
              "[5 rows x 128 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1bca87c4-397a-4b72-ab41-68bdddf19a26\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>w_0</th>\n",
              "      <th>w_1</th>\n",
              "      <th>w_2</th>\n",
              "      <th>w_3</th>\n",
              "      <th>w_4</th>\n",
              "      <th>w_5</th>\n",
              "      <th>w_6</th>\n",
              "      <th>w_7</th>\n",
              "      <th>w_8</th>\n",
              "      <th>w_9</th>\n",
              "      <th>...</th>\n",
              "      <th>w_118</th>\n",
              "      <th>w_119</th>\n",
              "      <th>w_120</th>\n",
              "      <th>w_121</th>\n",
              "      <th>w_122</th>\n",
              "      <th>w_123</th>\n",
              "      <th>w_124</th>\n",
              "      <th>w_125</th>\n",
              "      <th>w_126</th>\n",
              "      <th>w_127</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.057943</td>\n",
              "      <td>-0.052530</td>\n",
              "      <td>-0.072603</td>\n",
              "      <td>-0.026555</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>-0.241386</td>\n",
              "      <td>-0.449242</td>\n",
              "      <td>-0.018443</td>\n",
              "      <td>-0.087218</td>\n",
              "      <td>0.112320</td>\n",
              "      <td>...</td>\n",
              "      <td>0.211490</td>\n",
              "      <td>-0.226118</td>\n",
              "      <td>-0.185603</td>\n",
              "      <td>0.053230</td>\n",
              "      <td>0.332873</td>\n",
              "      <td>0.104175</td>\n",
              "      <td>0.007408</td>\n",
              "      <td>0.173364</td>\n",
              "      <td>-0.172796</td>\n",
              "      <td>-0.140059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.124500</td>\n",
              "      <td>-0.070665</td>\n",
              "      <td>-0.325202</td>\n",
              "      <td>0.007779</td>\n",
              "      <td>-0.001559</td>\n",
              "      <td>0.074189</td>\n",
              "      <td>-0.191013</td>\n",
              "      <td>0.049689</td>\n",
              "      <td>0.026369</td>\n",
              "      <td>0.099364</td>\n",
              "      <td>...</td>\n",
              "      <td>0.106316</td>\n",
              "      <td>0.052926</td>\n",
              "      <td>-0.258378</td>\n",
              "      <td>0.021567</td>\n",
              "      <td>0.281503</td>\n",
              "      <td>-0.173423</td>\n",
              "      <td>0.202082</td>\n",
              "      <td>0.068524</td>\n",
              "      <td>-0.372111</td>\n",
              "      <td>-0.301036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.080242</td>\n",
              "      <td>-0.023328</td>\n",
              "      <td>-0.183787</td>\n",
              "      <td>-0.180707</td>\n",
              "      <td>0.075765</td>\n",
              "      <td>-0.125818</td>\n",
              "      <td>-0.394573</td>\n",
              "      <td>-0.219078</td>\n",
              "      <td>-0.108931</td>\n",
              "      <td>0.056966</td>\n",
              "      <td>...</td>\n",
              "      <td>0.019453</td>\n",
              "      <td>-0.070291</td>\n",
              "      <td>-0.177562</td>\n",
              "      <td>-0.214012</td>\n",
              "      <td>0.182186</td>\n",
              "      <td>-0.121589</td>\n",
              "      <td>-0.073642</td>\n",
              "      <td>0.109919</td>\n",
              "      <td>0.117589</td>\n",
              "      <td>-0.139883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.145044</td>\n",
              "      <td>0.054915</td>\n",
              "      <td>-0.126666</td>\n",
              "      <td>0.039971</td>\n",
              "      <td>-0.055909</td>\n",
              "      <td>-0.101278</td>\n",
              "      <td>-0.339202</td>\n",
              "      <td>-0.115801</td>\n",
              "      <td>-0.080058</td>\n",
              "      <td>-0.001633</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.065752</td>\n",
              "      <td>0.042735</td>\n",
              "      <td>0.066338</td>\n",
              "      <td>-0.226921</td>\n",
              "      <td>0.188418</td>\n",
              "      <td>-0.017295</td>\n",
              "      <td>0.063449</td>\n",
              "      <td>0.017816</td>\n",
              "      <td>0.085364</td>\n",
              "      <td>-0.081804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.071154</td>\n",
              "      <td>0.070766</td>\n",
              "      <td>-0.281432</td>\n",
              "      <td>-0.161892</td>\n",
              "      <td>-0.165246</td>\n",
              "      <td>-0.029116</td>\n",
              "      <td>-0.338593</td>\n",
              "      <td>-0.138727</td>\n",
              "      <td>0.100015</td>\n",
              "      <td>0.132794</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.056130</td>\n",
              "      <td>0.047475</td>\n",
              "      <td>-0.263795</td>\n",
              "      <td>0.026462</td>\n",
              "      <td>0.376349</td>\n",
              "      <td>-0.253772</td>\n",
              "      <td>0.084472</td>\n",
              "      <td>0.098033</td>\n",
              "      <td>-0.075347</td>\n",
              "      <td>-0.111687</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 128 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bca87c4-397a-4b72-ab41-68bdddf19a26')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1bca87c4-397a-4b72-ab41-68bdddf19a26 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1bca87c4-397a-4b72-ab41-68bdddf19a26');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "Node_Fec.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrWhL3xfBY9R",
        "outputId": "9c8c6390-6ba3-4a90-ce41-af62a6a98a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(169343, 50)\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaling = StandardScaler()\n",
        "\n",
        "Scaled_data = Node_Fec\n",
        "\n",
        "scaling.fit(Scaled_data)\n",
        "Scaled_data = scaling.transform(Scaled_data)\n",
        "\n",
        "m = 50\n",
        "principal = PCA(n_components=m)\n",
        "principal.fit(Scaled_data)\n",
        "x = principal.transform(Scaled_data)\n",
        "\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQgblr6jCOYf"
      },
      "outputs": [],
      "source": [
        "Scaled_data = pd.DataFrame(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqRQcBuYF0fq"
      },
      "outputs": [],
      "source": [
        "# Replace Node_Fec with Scaled_data if you want to use PCA\n",
        "Data = pd.concat([data, Node_Fec], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHB9tLf_Tu7g"
      },
      "outputs": [],
      "source": [
        "Data = pd.concat([data, Scaled_data], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_feat_df = pd.read_csv('https://utdallas.box.com/shared/static/hju4cvgquks1a2wijtbp9obiijldl0c3.csv', index_col=0)"
      ],
      "metadata": {
        "id": "yZA-SzLUlxrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_feat_df = edge_feat_df.iloc[:, :16]"
      ],
      "metadata": {
        "id": "1c4Uj1ErmEJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_feat_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "bSqeXMCLmLyu",
        "outputId": "1ccaddd4-27aa-4298-9f5a-4af2ed0c7477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          1  2  3  4   5  6   7  8       9     10     11     12       13  \\\n",
              "0       471  2  4  6  10  6  11  1  20.511  1.292  0.511  0.511   47.750   \n",
              "1         7  0  0  0   0  0   0  0   0.007  0.007  0.007  0.007    0.007   \n",
              "2       184  0  0  0   0  0   0  0   0.184  0.184  0.772  0.184   20.474   \n",
              "3       731  1  1  1   1  1   1  0   3.737  0.737  1.541  0.737   75.981   \n",
              "4       591  0  0  0   0  0   0  0   0.591  0.591  0.591  0.591  100.085   \n",
              "...     ... .. .. ..  .. ..  .. ..     ...    ...    ...    ...      ...   \n",
              "132529    0  0  6  1   1  3   4  0   7.015  0.015  0.015  0.224    0.015   \n",
              "132530    0  0  6  1   1  3   4  0   7.015  0.015  0.015  0.228    0.015   \n",
              "132531    0  0  6  1   1  3   4  0   7.015  0.015  0.015  0.227    0.015   \n",
              "132532    0  0  6  1   1  3   4  0   7.015  0.015  0.015  0.222    0.015   \n",
              "132533    0  0  0  0   0  0   0  0     NaN    NaN    NaN    NaN      NaN   \n",
              "\n",
              "            14          15      16  \n",
              "0       39.328    0.511000  47.564  \n",
              "1        0.007    0.007000   5.286  \n",
              "2        5.423    0.184000  29.872  \n",
              "3       95.882  160.577004  91.906  \n",
              "4        1.376    0.591000  43.605  \n",
              "...        ...         ...     ...  \n",
              "132529   0.015    0.015000   0.015  \n",
              "132530   0.015    0.015000   0.015  \n",
              "132531   0.015    0.015000   0.015  \n",
              "132532   0.015    0.015000   0.015  \n",
              "132533     NaN         NaN     NaN  \n",
              "\n",
              "[132534 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-910f8bdc-3aa1-4b9c-962c-2ec396aec3e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>471</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>20.511</td>\n",
              "      <td>1.292</td>\n",
              "      <td>0.511</td>\n",
              "      <td>0.511</td>\n",
              "      <td>47.750</td>\n",
              "      <td>39.328</td>\n",
              "      <td>0.511000</td>\n",
              "      <td>47.564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.007000</td>\n",
              "      <td>5.286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.772</td>\n",
              "      <td>0.184</td>\n",
              "      <td>20.474</td>\n",
              "      <td>5.423</td>\n",
              "      <td>0.184000</td>\n",
              "      <td>29.872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>731</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3.737</td>\n",
              "      <td>0.737</td>\n",
              "      <td>1.541</td>\n",
              "      <td>0.737</td>\n",
              "      <td>75.981</td>\n",
              "      <td>95.882</td>\n",
              "      <td>160.577004</td>\n",
              "      <td>91.906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>591</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.591</td>\n",
              "      <td>100.085</td>\n",
              "      <td>1.376</td>\n",
              "      <td>0.591000</td>\n",
              "      <td>43.605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132529</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>7.015</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.224</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132530</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>7.015</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.228</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132531</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>7.015</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.227</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132532</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>7.015</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.222</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132533</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>132534 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-910f8bdc-3aa1-4b9c-962c-2ec396aec3e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-910f8bdc-3aa1-4b9c-962c-2ec396aec3e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-910f8bdc-3aa1-4b9c-962c-2ec396aec3e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Node_Class_df = pd.DataFrame(Node_Class)"
      ],
      "metadata": {
        "id": "G_CADfVch4ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IsCDbjojXO7"
      },
      "outputs": [],
      "source": [
        "Data = pd.concat([data, Node_Class_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "ADXySAJwCr8d",
        "outputId": "3b8812a9-99dc-47fa-c176-c72cbc5dcfbb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       1      2      3      4      5      6      7      8      9     10  ...  \\\n",
              "0  311.0  308.0  235.0  281.0  275.0  128.0  272.0  113.0  256.0  187.0  ...   \n",
              "1    4.0    4.0    4.0    4.0    4.0    3.0    3.0    3.0    3.0    3.0  ...   \n",
              "2  105.0   89.0   70.0   62.0   66.0   34.0   49.0   31.0   44.0   39.0  ...   \n",
              "3  426.0  412.0  307.0  372.0  350.0  210.0  333.0  191.0  322.0  240.0  ...   \n",
              "4  360.0  290.0  258.0  229.0  241.0  139.0  166.0  133.0  161.0  178.0  ...   \n",
              "\n",
              "   102  103  104  105  106  107  108  109  110  111  \n",
              "0    0    0    0    0    0    0    0    0    0    0  \n",
              "1    0    0    0    0    0    0    0    0    0    0  \n",
              "2    0    0    0    0    0    0    0    0    0    0  \n",
              "3    0    0    0    0    0    0    0    0    0    0  \n",
              "4    0    1    0    0    1    0    0    0    0    0  \n",
              "\n",
              "[5 rows x 1120 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65542c75-dc85-410b-8f50-2864d96aa396\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>102</th>\n",
              "      <th>103</th>\n",
              "      <th>104</th>\n",
              "      <th>105</th>\n",
              "      <th>106</th>\n",
              "      <th>107</th>\n",
              "      <th>108</th>\n",
              "      <th>109</th>\n",
              "      <th>110</th>\n",
              "      <th>111</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>311.0</td>\n",
              "      <td>308.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>281.0</td>\n",
              "      <td>275.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>272.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>256.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>105.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>426.0</td>\n",
              "      <td>412.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>372.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>360.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>258.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>241.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>166.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1120 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65542c75-dc85-410b-8f50-2864d96aa396')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65542c75-dc85-410b-8f50-2864d96aa396 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65542c75-dc85-410b-8f50-2864d96aa396');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "Data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OEamQZ_-rcC",
        "outputId": "4a174f60-34ad-43c2-d011-ad805e24daf3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7145660"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(P_Edge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jza8n9X_984D"
      },
      "outputs": [],
      "source": [
        "P_T_Edges = graph[0]['edge_index_dict'][('paper', 'has_topic', 'field_of_study')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5vdN2s4AOKY"
      },
      "outputs": [],
      "source": [
        "num_fields = graph[0]['num_nodes_dict']['field_of_study']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cri6xnD2_rn-"
      },
      "outputs": [],
      "source": [
        "P_Edges, T_Edges = P_T_Edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2XrVQaE-0kq",
        "outputId": "73fc0fd7-8cc6-48b1-8d52-f358355e3894"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing file 7505077 (99%)--- 2.806017263929049 hours ---\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "topic_vecs = np.zeros((num_fields, num_cls))\n",
        "for i in range(len(P_Edges)):\n",
        "  print(\"\\rProcessing file {} ({}%)\".format(i, 100*i//len(P_Edges)), end='', flush=True)\n",
        "  topic, paper = T_Edges[i], P_Edges[i]\n",
        "  if N_class_train[paper] == 500:\n",
        "    continue\n",
        "  topic_vecs[topic][Node_Class[paper]] += 1\n",
        "# for i in range(len(author_vecs)):\n",
        "#   author_vecs[i] /= np.linalg.norm(author_vecs, ord=1)\n",
        "compression_opts = dict(method='zip',\n",
        "                        archive_name='Topic_vecs.csv')  \n",
        "topic_df = pd.DataFrame(topic_vecs)\n",
        "topic_df.to_csv('/content/drive/MyDrive/Topic_vecs.zip', compression=compression_opts)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f'--- {(end_time-start_time)/3600} hours ---')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2EMgK0_EQOy",
        "outputId": "2c698bab-f071-41d2-c97c-f2b4d3132a93"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing file 892491 (11%)"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 7505027 (99%)--- 2.785127653744486 hours ---\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "paper_topic_vecs = np.zeros((n, num_cls))\n",
        "\n",
        "# topic_sums = [sum(topic_vecs[topic]) for topic in range(len(topic_vecs))]\n",
        "# paper_topic_sums = [0 for _ in range(n)]\n",
        "for i in range(len(P_Edges)):\n",
        "  print(\"\\rProcessing file {} ({}%)\".format(i, 100*i//len(P_Edges)), end='', flush=True)\n",
        "  paper, topic = P_Edges[i], T_Edges[i]\n",
        "  paper_topic_vecs[paper] += topic_vecs[topic]\n",
        "print()\n",
        "# for i in range(n):\n",
        "#   print(\"\\rProcessing file {} ({}%)\".format(i, 100*i//n), end='', flush=True)\n",
        "#   paper_auth_vecs[i] /= paper_counts[i]\n",
        "\n",
        "paper_topic_df = pd.DataFrame(paper_topic_vecs)\n",
        "compression_opts = dict(method='zip',\n",
        "                        archive_name='Paper_topic_vecs_max.csv')\n",
        "paper_topic_df.to_csv('/content/drive/MyDrive/Paper_topic_vecs_max.zip', compression=compression_opts)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f'--- {(end_time-start_time)/3600} hours ---')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Zuy1Arc_1Br",
        "outputId": "b0a6216e-3e7f-4590-b0fd-07d1a62e9e83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing file 7145656 (99%)--- 2.711470737722185 hours ---\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "paper_auth_vecs = np.zeros((n, num_cls))\n",
        "paper_counts = Counter(P_Edge)\n",
        "\n",
        "auth_sums = [sum(author_vecs[author]) for author in range(len(author_vecs))]\n",
        "paper_auth_sums = [0 for _ in range(n)]\n",
        "for i in range(len(P_Edge)):\n",
        "  print(\"\\rProcessing file {} ({}%)\".format(i, 100*i//len(P_Edge)), end='', flush=True)\n",
        "  paper, author = P_Edge[i], A_Edge[i]\n",
        "  if auth_sums[author] > paper_auth_sums[paper]:\n",
        "    paper_auth_vecs[paper] = author_vecs[author]\n",
        "    paper_auth_sums[paper] = auth_sums[author]\n",
        "print()\n",
        "# for i in range(n):\n",
        "#   print(\"\\rProcessing file {} ({}%)\".format(i, 100*i//n), end='', flush=True)\n",
        "#   paper_auth_vecs[i] /= paper_counts[i]\n",
        "\n",
        "paper_auth_df = pd.DataFrame(paper_auth_vecs)\n",
        "compression_opts = dict(method='zip',\n",
        "                        archive_name='Paper_auth_vecs_max.csv')\n",
        "paper_auth_df.to_csv('/content/drive/MyDrive/Paper_auth_vecs_max.zip', compression=compression_opts)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f'--- {(end_time-start_time)/3600} hours ---')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLjuNnvq2hNg"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "z = zipfile.ZipFile('/content/Mag_F_vecs.zip')\n",
        "z.extractall('/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIYMeqVxDrtU"
      },
      "outputs": [],
      "source": [
        "Data = pd.read_csv('/content/Mag_F_vecs.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "9fcEqB4213Kz",
        "outputId": "b8959ea7-978e-4e9c-c025-b7d28c9f6154"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c057809b-7250-41b7-a3df-8abedfa89a33\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>339</th>\n",
              "      <th>340</th>\n",
              "      <th>341</th>\n",
              "      <th>342</th>\n",
              "      <th>343</th>\n",
              "      <th>344</th>\n",
              "      <th>345</th>\n",
              "      <th>346</th>\n",
              "      <th>347</th>\n",
              "      <th>348</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.682927</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017422</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017422</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003484</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006969</td>\n",
              "      <td>0.006969</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736384</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736385</th>\n",
              "      <td>0.000734</td>\n",
              "      <td>0.105727</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000734</td>\n",
              "      <td>0.002937</td>\n",
              "      <td>0.011747</td>\n",
              "      <td>0.000734</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008076</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002203</td>\n",
              "      <td>0.000734</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015419</td>\n",
              "      <td>0.031571</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736386</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736387</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736388</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>736389 rows × 349 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c057809b-7250-41b7-a3df-8abedfa89a33')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c057809b-7250-41b7-a3df-8abedfa89a33 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c057809b-7250-41b7-a3df-8abedfa89a33');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             0          1    2         3         4         5         6    \\\n",
              "0       0.000000   0.682927  0.0  0.017422  0.000000  0.000000  0.017422   \n",
              "1       0.000000   0.000000  0.0  0.000000  0.000000  0.000000  0.000000   \n",
              "2       0.000000   0.000000  0.0  0.000000  0.000000  0.000000  0.000000   \n",
              "3       0.000000   0.000000  0.0  0.000000  0.000000  0.000000  0.000000   \n",
              "4       0.000000   0.000000  0.0  0.000000  0.000000  0.000000  0.000000   \n",
              "...          ...        ...  ...       ...       ...       ...       ...   \n",
              "736384  0.000000   0.000000  0.0  0.000000  0.000000  0.000000  0.000000   \n",
              "736385  0.000734   0.105727  0.0  0.000000  0.000734  0.002937  0.011747   \n",
              "736386  0.000000   0.000000  0.0  0.000000  0.000000  0.000000  0.000000   \n",
              "736387  0.000000   0.000000  0.0  0.000000  0.000000  0.500000  0.000000   \n",
              "736388  0.000000  17.000000  0.0  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "             7    8         9    ...  339  340  341       342       343  344  \\\n",
              "0       0.000000  0.0  0.000000  ...  0.0  0.0  0.0  0.000000  0.003484  0.0   \n",
              "1       0.000000  0.0  0.000000  ...  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
              "2       0.000000  0.0  0.000000  ...  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
              "3       0.000000  0.0  0.000000  ...  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
              "4       0.000000  0.0  0.000000  ...  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
              "...          ...  ...       ...  ...  ...  ...  ...       ...       ...  ...   \n",
              "736384  0.000000  0.0  0.000000  ...  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
              "736385  0.000734  0.0  0.008076  ...  0.0  0.0  0.0  0.002203  0.000734  0.0   \n",
              "736386  0.000000  0.0  0.000000  ...  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
              "736387  0.000000  0.0  1.250000  ...  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
              "736388  0.000000  0.0  0.000000  ...  0.0  0.0  0.0  0.000000  0.250000  0.0   \n",
              "\n",
              "        345       346       347  348  \n",
              "0       0.0  0.006969  0.006969  0.0  \n",
              "1       0.0  0.000000  0.000000  0.0  \n",
              "2       0.0  0.000000  0.000000  0.0  \n",
              "3       0.0  0.000000  0.000000  0.0  \n",
              "4       0.0  0.000000  0.000000  0.0  \n",
              "...     ...       ...       ...  ...  \n",
              "736384  0.0  0.000000  0.000000  0.0  \n",
              "736385  0.0  0.015419  0.031571  0.0  \n",
              "736386  0.0  0.000000  0.000000  0.0  \n",
              "736387  0.0  0.000000  0.000000  0.0  \n",
              "736388  0.0  0.000000  0.000000  0.0  \n",
              "\n",
              "[736389 rows x 349 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "paper_auth_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-MaVVFT-W-Z",
        "outputId": "e3fa7096-88cc-47bd-8f21-61b684e63bca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'edge_index_dict': {('author',\n",
              "   'affiliated_with',\n",
              "   'institution'): array([[      0,       1,       2, ..., 1134645, 1134647, 1134648],\n",
              "         [    845,     996,    3197, ...,    5189,    4668,    4668]]),\n",
              "  ('author',\n",
              "   'writes',\n",
              "   'paper'): array([[      0,       0,       0, ..., 1134647, 1134648, 1134648],\n",
              "         [  19703,  289285,  311768, ...,  657395,  671118,  719594]]),\n",
              "  ('paper',\n",
              "   'cites',\n",
              "   'paper'): array([[     0,      0,      0, ..., 736388, 736388, 736388],\n",
              "         [    88,  27449, 121051, ..., 421711, 427339, 439864]]),\n",
              "  ('paper',\n",
              "   'has_topic',\n",
              "   'field_of_study'): array([[     0,      0,      0, ..., 736388, 736388, 736388],\n",
              "         [   145,   2215,   3205, ...,  21458,  22283,  31934]])},\n",
              " 'edge_feat_dict': None,\n",
              " 'node_feat_dict': {'paper': array([[-0.095379,  0.040758, -0.210948, ...,  0.061569, -0.027663,\n",
              "          -0.133832],\n",
              "         [-0.151047, -0.107315, -0.221964, ...,  0.345754, -0.027737,\n",
              "          -0.218527],\n",
              "         [-0.114799, -0.175982, -0.260556, ...,  0.173058, -0.156445,\n",
              "          -0.277954],\n",
              "         ...,\n",
              "         [ 0.022815, -0.0865  ,  0.098138, ..., -0.054667, -0.207721,\n",
              "          -0.230458],\n",
              "         [-0.289148, -0.202898, -0.152454, ...,  0.104207,  0.204123,\n",
              "          -0.352805],\n",
              "         [-0.088966, -0.034788, -0.264226, ...,  0.260077, -0.087453,\n",
              "          -0.517127]], dtype=float32)},\n",
              " 'num_nodes_dict': {'author': 1134649,\n",
              "  'field_of_study': 59965,\n",
              "  'institution': 8740,\n",
              "  'paper': 736389},\n",
              " 'node_year': {'paper': array([[2015],\n",
              "         [2012],\n",
              "         [2012],\n",
              "         ...,\n",
              "         [2016],\n",
              "         [2017],\n",
              "         [2014]])},\n",
              " 'edge_reltype': {('author',\n",
              "   'affiliated_with',\n",
              "   'institution'): array([[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]]),\n",
              "  ('author',\n",
              "   'writes',\n",
              "   'paper'): array([[3],\n",
              "         [3],\n",
              "         [3],\n",
              "         ...,\n",
              "         [3],\n",
              "         [3],\n",
              "         [3]]),\n",
              "  ('paper',\n",
              "   'cites',\n",
              "   'paper'): array([[1],\n",
              "         [1],\n",
              "         [1],\n",
              "         ...,\n",
              "         [1],\n",
              "         [1],\n",
              "         [1]]),\n",
              "  ('paper',\n",
              "   'has_topic',\n",
              "   'field_of_study'): array([[2],\n",
              "         [2],\n",
              "         [2],\n",
              "         ...,\n",
              "         [2],\n",
              "         [2],\n",
              "         [2]])}}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5xRsp8o3RpU"
      },
      "outputs": [],
      "source": [
        "Data = pd.concat([data, Node_Fec, paper_auth_df, paper_topic_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paper_auth_df"
      ],
      "metadata": {
        "id": "0jCnL26iYGse",
        "outputId": "a1d629d5-1cf4-4d4a-b0a2-761ef01c951b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0     1    2    3    4    5    6    7    8    9  ...  339  340  341  \\\n",
              "0       0.0  51.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "1       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "2       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "3       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "4       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "...     ...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "736384  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "736385  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "736386  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "736387  0.0   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  4.0  ...  0.0  0.0  0.0   \n",
              "736388  0.0  15.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "\n",
              "        342  343  344  345  346  347  348  \n",
              "0       0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
              "1       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "2       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "3       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "4       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "...     ...  ...  ...  ...  ...  ...  ...  \n",
              "736384  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "736385  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "736386  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "736387  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "736388  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
              "\n",
              "[736389 rows x 349 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e880452-b39c-474d-af8e-5dd0183ad463\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>339</th>\n",
              "      <th>340</th>\n",
              "      <th>341</th>\n",
              "      <th>342</th>\n",
              "      <th>343</th>\n",
              "      <th>344</th>\n",
              "      <th>345</th>\n",
              "      <th>346</th>\n",
              "      <th>347</th>\n",
              "      <th>348</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736384</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736385</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736386</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736387</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736388</th>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>736389 rows × 349 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e880452-b39c-474d-af8e-5dd0183ad463')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e880452-b39c-474d-af8e-5dd0183ad463 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e880452-b39c-474d-af8e-5dd0183ad463');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "hKqCIRGUWPPU",
        "outputId": "be3d507e-af34-4ead-fab8-ddd929aa4b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0  1  2  3  4  5  6  7  8  9  ...    339    340    341    342    343  \\\n",
              "0       0  0  0  0  0  0  0  0  0  0  ...  219.0  315.0  137.0  263.0  308.0   \n",
              "1       0  0  0  0  0  0  0  0  0  0  ...  205.0  317.0  139.0  268.0  194.0   \n",
              "2       0  0  0  0  0  0  0  0  0  0  ...  240.0  311.0  137.0  261.0  194.0   \n",
              "3       0  0  0  0  0  0  0  0  0  0  ...  208.0  320.0  139.0  268.0  197.0   \n",
              "4       0  0  0  0  0  0  0  0  0  0  ...  244.0  322.0  146.0  288.0  195.0   \n",
              "...    .. .. .. .. .. .. .. .. .. ..  ...    ...    ...    ...    ...    ...   \n",
              "736384  0  0  0  0  0  0  0  0  0  0  ...  207.0  332.0  139.0  280.0  191.0   \n",
              "736385  0  0  1  0  0  0  0  0  0  0  ...  238.0  309.0  137.0  257.0  195.0   \n",
              "736386  0  0  0  0  0  0  0  0  0  0  ...  211.0  594.0  144.0  359.0  194.0   \n",
              "736387  0  0  0  0  0  0  0  0  0  0  ...  204.0  317.0  177.0  335.0  191.0   \n",
              "736388  0  0  0  0  0  0  0  0  0  0  ...  233.0  316.0  138.0  280.0  353.0   \n",
              "\n",
              "          344    345    346     347    348  \n",
              "0       284.0  209.0  240.0   522.0  301.0  \n",
              "1       261.0  211.0  213.0   438.0  301.0  \n",
              "2       249.0  214.0  299.0   836.0  306.0  \n",
              "3       302.0  212.0  213.0   455.0  304.0  \n",
              "4       251.0  215.0  297.0  1031.0  312.0  \n",
              "...       ...    ...    ...     ...    ...  \n",
              "736384  240.0  248.0  213.0   439.0  327.0  \n",
              "736385  237.0  210.0  302.0   910.0  297.0  \n",
              "736386  290.0  291.0  219.0   442.0  371.0  \n",
              "736387  240.0  221.0  214.0   430.0  307.0  \n",
              "736388  410.0  231.0  290.0   490.0  323.0  \n",
              "\n",
              "[736389 rows x 1525 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b80e02cc-253f-4522-8a46-72286210b1fb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>339</th>\n",
              "      <th>340</th>\n",
              "      <th>341</th>\n",
              "      <th>342</th>\n",
              "      <th>343</th>\n",
              "      <th>344</th>\n",
              "      <th>345</th>\n",
              "      <th>346</th>\n",
              "      <th>347</th>\n",
              "      <th>348</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>219.0</td>\n",
              "      <td>315.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>263.0</td>\n",
              "      <td>308.0</td>\n",
              "      <td>284.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>522.0</td>\n",
              "      <td>301.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>205.0</td>\n",
              "      <td>317.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>268.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>261.0</td>\n",
              "      <td>211.0</td>\n",
              "      <td>213.0</td>\n",
              "      <td>438.0</td>\n",
              "      <td>301.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>240.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>261.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>249.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>299.0</td>\n",
              "      <td>836.0</td>\n",
              "      <td>306.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>208.0</td>\n",
              "      <td>320.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>268.0</td>\n",
              "      <td>197.0</td>\n",
              "      <td>302.0</td>\n",
              "      <td>212.0</td>\n",
              "      <td>213.0</td>\n",
              "      <td>455.0</td>\n",
              "      <td>304.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>244.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>251.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>297.0</td>\n",
              "      <td>1031.0</td>\n",
              "      <td>312.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736384</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>207.0</td>\n",
              "      <td>332.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>248.0</td>\n",
              "      <td>213.0</td>\n",
              "      <td>439.0</td>\n",
              "      <td>327.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736385</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>238.0</td>\n",
              "      <td>309.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>257.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>302.0</td>\n",
              "      <td>910.0</td>\n",
              "      <td>297.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736386</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>211.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>359.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>291.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>442.0</td>\n",
              "      <td>371.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736387</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>204.0</td>\n",
              "      <td>317.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>335.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>430.0</td>\n",
              "      <td>307.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736388</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>233.0</td>\n",
              "      <td>316.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>353.0</td>\n",
              "      <td>410.0</td>\n",
              "      <td>231.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>490.0</td>\n",
              "      <td>323.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>736389 rows × 1525 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b80e02cc-253f-4522-8a46-72286210b1fb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b80e02cc-253f-4522-8a46-72286210b1fb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b80e02cc-253f-4522-8a46-72286210b1fb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del data, Node_Fec, paper_auth_df, paper_topic_df"
      ],
      "metadata": {
        "id": "ZvUm7FnfLa2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBHMLwEP3tbh"
      },
      "outputs": [],
      "source": [
        "compression_opts = dict(method='zip',\n",
        "                        archive_name='Mag_F_vecs.csv')\n",
        "Data.to_csv('/content/drive/MyDrive/Mag_F_vecs.zip', compression=compression_opts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE5_sko43gNs"
      },
      "outputs": [],
      "source": [
        "Data = Data.drop(Data.columns[0], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p2YW6RQDYub",
        "outputId": "6ec87afc-2da7-4c56-bb33-d401c81c4218"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({19703: 5,\n",
              "         289285: 4,\n",
              "         311768: 5,\n",
              "         402711: 3,\n",
              "         181505: 3,\n",
              "         297095: 3,\n",
              "         336569: 3,\n",
              "         14217: 6,\n",
              "         14630: 6,\n",
              "         15376: 3,\n",
              "         15420: 5,\n",
              "         20656: 9,\n",
              "         27715: 3,\n",
              "         37354: 3,\n",
              "         62987: 3,\n",
              "         78157: 4,\n",
              "         86646: 13,\n",
              "         91551: 9,\n",
              "         103412: 8,\n",
              "         129861: 5,\n",
              "         148900: 7,\n",
              "         178805: 4,\n",
              "         190892: 5,\n",
              "         194646: 5,\n",
              "         261498: 2,\n",
              "         301784: 3,\n",
              "         357433: 9,\n",
              "         432992: 5,\n",
              "         455787: 7,\n",
              "         489838: 5,\n",
              "         519995: 16,\n",
              "         540904: 8,\n",
              "         599199: 3,\n",
              "         600495: 9,\n",
              "         614248: 6,\n",
              "         617244: 3,\n",
              "         647287: 4,\n",
              "         689138: 5,\n",
              "         705788: 7,\n",
              "         722195: 6,\n",
              "         729975: 3,\n",
              "         230166: 2,\n",
              "         392216: 2,\n",
              "         504678: 2,\n",
              "         625373: 6,\n",
              "         240904: 2,\n",
              "         393817: 3,\n",
              "         499283: 4,\n",
              "         538604: 4,\n",
              "         621886: 5,\n",
              "         709654: 4,\n",
              "         215835: 3,\n",
              "         539403: 2,\n",
              "         676656: 3,\n",
              "         204588: 4,\n",
              "         411983: 5,\n",
              "         421839: 6,\n",
              "         562041: 36,\n",
              "         124161: 4,\n",
              "         100885: 5,\n",
              "         459821: 2,\n",
              "         230926: 18,\n",
              "         319407: 2,\n",
              "         340191: 6,\n",
              "         510844: 4,\n",
              "         660773: 5,\n",
              "         184138: 6,\n",
              "         234385: 5,\n",
              "         266087: 2,\n",
              "         293181: 7,\n",
              "         298381: 4,\n",
              "         345795: 2,\n",
              "         415880: 4,\n",
              "         96891: 9,\n",
              "         563647: 8,\n",
              "         612825: 8,\n",
              "         164709: 3,\n",
              "         199932: 20,\n",
              "         345106: 5,\n",
              "         360756: 3,\n",
              "         375811: 6,\n",
              "         399694: 3,\n",
              "         416314: 2,\n",
              "         498455: 6,\n",
              "         144085: 4,\n",
              "         276223: 4,\n",
              "         379223: 4,\n",
              "         445195: 3,\n",
              "         486707: 7,\n",
              "         712943: 27,\n",
              "         117844: 11,\n",
              "         548927: 11,\n",
              "         191125: 5,\n",
              "         558754: 4,\n",
              "         20953: 6,\n",
              "         22529: 3,\n",
              "         39440: 13,\n",
              "         51956: 4,\n",
              "         139105: 5,\n",
              "         152755: 2,\n",
              "         168516: 4,\n",
              "         181324: 2,\n",
              "         182647: 1,\n",
              "         249241: 8,\n",
              "         258138: 2,\n",
              "         273965: 2,\n",
              "         329083: 2,\n",
              "         378424: 12,\n",
              "         395792: 5,\n",
              "         406655: 4,\n",
              "         419425: 3,\n",
              "         439249: 5,\n",
              "         440334: 3,\n",
              "         465483: 12,\n",
              "         474671: 3,\n",
              "         478309: 7,\n",
              "         492493: 2,\n",
              "         548709: 1,\n",
              "         579734: 2,\n",
              "         596144: 1,\n",
              "         602348: 16,\n",
              "         620867: 3,\n",
              "         650218: 6,\n",
              "         651868: 7,\n",
              "         656504: 3,\n",
              "         669880: 3,\n",
              "         671343: 3,\n",
              "         673775: 3,\n",
              "         682317: 3,\n",
              "         698094: 3,\n",
              "         698753: 12,\n",
              "         722073: 4,\n",
              "         255821: 2,\n",
              "         52342: 2,\n",
              "         145637: 2,\n",
              "         306422: 2,\n",
              "         312683: 2,\n",
              "         323023: 2,\n",
              "         439528: 2,\n",
              "         444520: 5,\n",
              "         461013: 2,\n",
              "         42282: 2,\n",
              "         82798: 9,\n",
              "         110913: 8,\n",
              "         111225: 4,\n",
              "         116248: 7,\n",
              "         123275: 4,\n",
              "         226435: 9,\n",
              "         301479: 3,\n",
              "         314634: 6,\n",
              "         368946: 5,\n",
              "         488528: 3,\n",
              "         534325: 4,\n",
              "         559937: 7,\n",
              "         583509: 6,\n",
              "         597691: 4,\n",
              "         615559: 10,\n",
              "         628422: 4,\n",
              "         637934: 7,\n",
              "         641932: 8,\n",
              "         676733: 8,\n",
              "         678407: 6,\n",
              "         697925: 2,\n",
              "         735990: 3,\n",
              "         267348: 3,\n",
              "         271853: 5,\n",
              "         282399: 6,\n",
              "         389077: 6,\n",
              "         528770: 5,\n",
              "         163442: 7,\n",
              "         215184: 4,\n",
              "         243149: 4,\n",
              "         250892: 7,\n",
              "         259012: 7,\n",
              "         400394: 3,\n",
              "         481554: 4,\n",
              "         501127: 5,\n",
              "         548837: 8,\n",
              "         647163: 5,\n",
              "         671382: 5,\n",
              "         678524: 8,\n",
              "         710504: 7,\n",
              "         184511: 3,\n",
              "         55441: 3,\n",
              "         426999: 5,\n",
              "         217375: 7,\n",
              "         142586: 10,\n",
              "         360139: 10,\n",
              "         366332: 8,\n",
              "         431327: 7,\n",
              "         99419: 1,\n",
              "         324706: 1,\n",
              "         352373: 1,\n",
              "         144977: 9,\n",
              "         9374: 20,\n",
              "         48846: 6,\n",
              "         75864: 7,\n",
              "         218815: 5,\n",
              "         229888: 6,\n",
              "         260331: 10,\n",
              "         276384: 5,\n",
              "         448479: 4,\n",
              "         37609: 2,\n",
              "         55790: 2,\n",
              "         114576: 3,\n",
              "         114785: 2,\n",
              "         134573: 2,\n",
              "         136685: 3,\n",
              "         142536: 2,\n",
              "         215162: 3,\n",
              "         218543: 2,\n",
              "         234128: 1,\n",
              "         235045: 2,\n",
              "         238299: 2,\n",
              "         357988: 3,\n",
              "         382160: 2,\n",
              "         417916: 2,\n",
              "         430146: 2,\n",
              "         498277: 2,\n",
              "         521102: 3,\n",
              "         534993: 2,\n",
              "         591569: 5,\n",
              "         624889: 6,\n",
              "         651210: 2,\n",
              "         731035: 3,\n",
              "         542233: 19,\n",
              "         18677: 4,\n",
              "         35030: 3,\n",
              "         182985: 1,\n",
              "         273174: 5,\n",
              "         395170: 4,\n",
              "         619336: 3,\n",
              "         674294: 2,\n",
              "         22742: 19,\n",
              "         278206: 5,\n",
              "         3562: 3,\n",
              "         3908: 3,\n",
              "         119877: 3,\n",
              "         123890: 3,\n",
              "         157512: 3,\n",
              "         171535: 3,\n",
              "         188209: 3,\n",
              "         195102: 3,\n",
              "         293763: 3,\n",
              "         297846: 3,\n",
              "         345074: 2,\n",
              "         465721: 3,\n",
              "         472685: 4,\n",
              "         531965: 3,\n",
              "         560697: 3,\n",
              "         564660: 3,\n",
              "         567412: 4,\n",
              "         577859: 4,\n",
              "         579762: 2,\n",
              "         585284: 4,\n",
              "         604954: 4,\n",
              "         629738: 2,\n",
              "         633805: 3,\n",
              "         669309: 2,\n",
              "         698029: 3,\n",
              "         703099: 3,\n",
              "         71723: 1,\n",
              "         78931: 4,\n",
              "         428680: 3,\n",
              "         460878: 1,\n",
              "         587789: 1,\n",
              "         322783: 2,\n",
              "         129433: 10,\n",
              "         154903: 11,\n",
              "         195990: 13,\n",
              "         243787: 12,\n",
              "         272022: 12,\n",
              "         290602: 11,\n",
              "         359681: 10,\n",
              "         521568: 19,\n",
              "         524169: 11,\n",
              "         525087: 16,\n",
              "         528494: 14,\n",
              "         531010: 17,\n",
              "         558731: 19,\n",
              "         572472: 6,\n",
              "         590305: 18,\n",
              "         659223: 15,\n",
              "         712462: 12,\n",
              "         375662: 6,\n",
              "         3570: 3,\n",
              "         7337: 3,\n",
              "         57909: 1,\n",
              "         90834: 2,\n",
              "         129473: 2,\n",
              "         145625: 2,\n",
              "         154940: 3,\n",
              "         176165: 2,\n",
              "         181194: 2,\n",
              "         206187: 2,\n",
              "         266580: 1,\n",
              "         278777: 3,\n",
              "         303968: 3,\n",
              "         319992: 2,\n",
              "         329446: 3,\n",
              "         336742: 3,\n",
              "         352167: 2,\n",
              "         372159: 3,\n",
              "         394068: 2,\n",
              "         398739: 2,\n",
              "         440552: 2,\n",
              "         441818: 4,\n",
              "         448717: 2,\n",
              "         475391: 3,\n",
              "         477409: 4,\n",
              "         482035: 7,\n",
              "         494805: 10,\n",
              "         520519: 6,\n",
              "         560162: 6,\n",
              "         562835: 3,\n",
              "         597833: 6,\n",
              "         611617: 2,\n",
              "         619028: 3,\n",
              "         626638: 3,\n",
              "         628791: 3,\n",
              "         646039: 3,\n",
              "         720480: 3,\n",
              "         261245: 15,\n",
              "         523925: 16,\n",
              "         319868: 3,\n",
              "         431849: 3,\n",
              "         60109: 7,\n",
              "         464851: 15,\n",
              "         478577: 6,\n",
              "         118263: 8,\n",
              "         158842: 8,\n",
              "         160493: 9,\n",
              "         174600: 5,\n",
              "         235130: 12,\n",
              "         413413: 14,\n",
              "         477412: 4,\n",
              "         509635: 4,\n",
              "         597707: 11,\n",
              "         630186: 10,\n",
              "         732950: 6,\n",
              "         143984: 3,\n",
              "         208030: 3,\n",
              "         7734: 4,\n",
              "         23022: 3,\n",
              "         76404: 3,\n",
              "         465651: 2,\n",
              "         587457: 6,\n",
              "         654006: 5,\n",
              "         174606: 5,\n",
              "         543036: 9,\n",
              "         644246: 6,\n",
              "         662779: 3,\n",
              "         24931: 18,\n",
              "         63178: 4,\n",
              "         114020: 3,\n",
              "         175338: 3,\n",
              "         176608: 4,\n",
              "         253268: 3,\n",
              "         312723: 4,\n",
              "         315373: 6,\n",
              "         345336: 4,\n",
              "         353032: 7,\n",
              "         354055: 5,\n",
              "         371434: 3,\n",
              "         384273: 11,\n",
              "         431546: 7,\n",
              "         508770: 4,\n",
              "         522807: 10,\n",
              "         524028: 4,\n",
              "         530142: 4,\n",
              "         594091: 2,\n",
              "         595360: 10,\n",
              "         610836: 4,\n",
              "         615085: 4,\n",
              "         617037: 8,\n",
              "         631857: 8,\n",
              "         639800: 15,\n",
              "         669560: 39,\n",
              "         712240: 4,\n",
              "         734930: 5,\n",
              "         385960: 8,\n",
              "         235441: 4,\n",
              "         175423: 9,\n",
              "         255846: 3,\n",
              "         280525: 6,\n",
              "         464224: 5,\n",
              "         733975: 5,\n",
              "         57701: 2,\n",
              "         75028: 5,\n",
              "         200207: 4,\n",
              "         240105: 4,\n",
              "         514563: 8,\n",
              "         559393: 10,\n",
              "         642824: 12,\n",
              "         76241: 4,\n",
              "         202466: 2,\n",
              "         385832: 1,\n",
              "         484147: 2,\n",
              "         512922: 2,\n",
              "         17514: 7,\n",
              "         37080: 4,\n",
              "         178461: 6,\n",
              "         346167: 6,\n",
              "         265198: 4,\n",
              "         277266: 4,\n",
              "         326913: 4,\n",
              "         671925: 5,\n",
              "         459206: 7,\n",
              "         27138: 7,\n",
              "         37090: 3,\n",
              "         45216: 4,\n",
              "         46688: 4,\n",
              "         101090: 6,\n",
              "         102303: 7,\n",
              "         346009: 4,\n",
              "         366579: 5,\n",
              "         399280: 7,\n",
              "         406614: 7,\n",
              "         418135: 4,\n",
              "         560990: 5,\n",
              "         734433: 5,\n",
              "         61739: 6,\n",
              "         246456: 2,\n",
              "         335760: 2,\n",
              "         7761: 3,\n",
              "         397599: 5,\n",
              "         399359: 3,\n",
              "         419617: 13,\n",
              "         450478: 2,\n",
              "         548764: 4,\n",
              "         553133: 3,\n",
              "         558738: 8,\n",
              "         679763: 10,\n",
              "         17333: 6,\n",
              "         38870: 3,\n",
              "         74986: 2,\n",
              "         123519: 3,\n",
              "         127804: 3,\n",
              "         281339: 3,\n",
              "         318833: 4,\n",
              "         337406: 2,\n",
              "         394920: 4,\n",
              "         511042: 5,\n",
              "         643407: 5,\n",
              "         652011: 5,\n",
              "         654426: 3,\n",
              "         689133: 4,\n",
              "         730736: 5,\n",
              "         338865: 10,\n",
              "         516272: 11,\n",
              "         500951: 7,\n",
              "         654853: 3,\n",
              "         11096: 4,\n",
              "         103662: 6,\n",
              "         445569: 7,\n",
              "         707702: 5,\n",
              "         39013: 6,\n",
              "         390109: 4,\n",
              "         723059: 13,\n",
              "         604290: 4,\n",
              "         632325: 6,\n",
              "         714632: 1,\n",
              "         715576: 1,\n",
              "         734038: 2,\n",
              "         7923: 10,\n",
              "         13663: 11,\n",
              "         109956: 9,\n",
              "         141660: 5,\n",
              "         160241: 10,\n",
              "         229831: 5,\n",
              "         242257: 5,\n",
              "         291446: 7,\n",
              "         310689: 11,\n",
              "         413694: 10,\n",
              "         495785: 7,\n",
              "         501848: 9,\n",
              "         598476: 4,\n",
              "         654596: 6,\n",
              "         716088: 8,\n",
              "         15305: 4,\n",
              "         218507: 5,\n",
              "         302992: 1,\n",
              "         586287: 2,\n",
              "         717294: 2,\n",
              "         71692: 4,\n",
              "         125474: 2,\n",
              "         452177: 2,\n",
              "         15894: 16,\n",
              "         20385: 3,\n",
              "         33120: 8,\n",
              "         35009: 5,\n",
              "         40742: 6,\n",
              "         68438: 12,\n",
              "         183932: 14,\n",
              "         189952: 6,\n",
              "         274125: 5,\n",
              "         289332: 6,\n",
              "         301841: 6,\n",
              "         333075: 33,\n",
              "         364028: 4,\n",
              "         378803: 6,\n",
              "         397162: 13,\n",
              "         413786: 6,\n",
              "         428005: 15,\n",
              "         439383: 7,\n",
              "         446744: 12,\n",
              "         447551: 13,\n",
              "         467412: 5,\n",
              "         473168: 9,\n",
              "         484859: 11,\n",
              "         486857: 9,\n",
              "         520842: 7,\n",
              "         544354: 343,\n",
              "         573823: 11,\n",
              "         576761: 12,\n",
              "         579665: 362,\n",
              "         579974: 6,\n",
              "         580688: 3,\n",
              "         609067: 347,\n",
              "         629229: 7,\n",
              "         640524: 10,\n",
              "         656947: 7,\n",
              "         694640: 233,\n",
              "         699935: 9,\n",
              "         707992: 9,\n",
              "         729353: 22,\n",
              "         730575: 14,\n",
              "         46950: 1,\n",
              "         88242: 5,\n",
              "         106756: 3,\n",
              "         171204: 3,\n",
              "         184645: 4,\n",
              "         268270: 2,\n",
              "         495489: 4,\n",
              "         588959: 3,\n",
              "         54165: 7,\n",
              "         85420: 6,\n",
              "         126321: 9,\n",
              "         158818: 6,\n",
              "         215299: 7,\n",
              "         348194: 7,\n",
              "         404067: 7,\n",
              "         423277: 8,\n",
              "         526970: 8,\n",
              "         366012: 7,\n",
              "         583815: 13,\n",
              "         5874: 3,\n",
              "         354068: 6,\n",
              "         491920: 11,\n",
              "         677867: 11,\n",
              "         159229: 11,\n",
              "         408046: 6,\n",
              "         30108: 13,\n",
              "         262572: 6,\n",
              "         16689: 7,\n",
              "         19836: 20,\n",
              "         20194: 15,\n",
              "         21770: 17,\n",
              "         26448: 11,\n",
              "         28539: 6,\n",
              "         29118: 25,\n",
              "         32180: 14,\n",
              "         35855: 8,\n",
              "         37250: 7,\n",
              "         38199: 10,\n",
              "         38631: 26,\n",
              "         43226: 8,\n",
              "         80419: 26,\n",
              "         125161: 18,\n",
              "         155621: 7,\n",
              "         156343: 14,\n",
              "         196992: 7,\n",
              "         213110: 6,\n",
              "         216234: 14,\n",
              "         242377: 11,\n",
              "         260680: 29,\n",
              "         261439: 24,\n",
              "         288972: 6,\n",
              "         289199: 7,\n",
              "         309294: 24,\n",
              "         318159: 7,\n",
              "         332952: 5,\n",
              "         344410: 7,\n",
              "         384541: 9,\n",
              "         411002: 20,\n",
              "         416238: 5,\n",
              "         416898: 5,\n",
              "         427566: 8,\n",
              "         430809: 6,\n",
              "         433846: 31,\n",
              "         444739: 22,\n",
              "         446894: 7,\n",
              "         450750: 12,\n",
              "         470338: 26,\n",
              "         475571: 18,\n",
              "         490095: 19,\n",
              "         527014: 14,\n",
              "         535842: 35,\n",
              "         541172: 26,\n",
              "         558002: 8,\n",
              "         562432: 16,\n",
              "         580241: 19,\n",
              "         600017: 9,\n",
              "         600999: 4,\n",
              "         616155: 9,\n",
              "         620197: 8,\n",
              "         637363: 7,\n",
              "         673658: 9,\n",
              "         685116: 13,\n",
              "         700931: 15,\n",
              "         716357: 12,\n",
              "         317186: 5,\n",
              "         367676: 14,\n",
              "         169883: 2,\n",
              "         227406: 2,\n",
              "         249841: 4,\n",
              "         345749: 4,\n",
              "         559059: 3,\n",
              "         563716: 3,\n",
              "         43248: 4,\n",
              "         432410: 2,\n",
              "         476754: 2,\n",
              "         266018: 9,\n",
              "         359269: 17,\n",
              "         474969: 6,\n",
              "         492007: 3,\n",
              "         305285: 2,\n",
              "         372798: 3,\n",
              "         473526: 5,\n",
              "         482827: 6,\n",
              "         143507: 5,\n",
              "         221626: 4,\n",
              "         532662: 7,\n",
              "         300373: 3,\n",
              "         735370: 8,\n",
              "         117562: 3,\n",
              "         293485: 2,\n",
              "         366179: 3,\n",
              "         459317: 4,\n",
              "         606707: 1,\n",
              "         644840: 3,\n",
              "         646135: 2,\n",
              "         653035: 1,\n",
              "         46648: 6,\n",
              "         152488: 5,\n",
              "         186921: 2,\n",
              "         226243: 2,\n",
              "         262196: 2,\n",
              "         296132: 3,\n",
              "         373798: 3,\n",
              "         395779: 2,\n",
              "         453484: 5,\n",
              "         562795: 5,\n",
              "         569423: 5,\n",
              "         595724: 63,\n",
              "         649683: 6,\n",
              "         126609: 228,\n",
              "         641147: 120,\n",
              "         154131: 3,\n",
              "         310164: 5,\n",
              "         425587: 5,\n",
              "         504083: 5,\n",
              "         11787: 7,\n",
              "         13321: 12,\n",
              "         123808: 6,\n",
              "         222388: 3,\n",
              "         262973: 10,\n",
              "         606945: 6,\n",
              "         618823: 16,\n",
              "         696468: 7,\n",
              "         697819: 7,\n",
              "         10941: 6,\n",
              "         320975: 4,\n",
              "         457348: 3,\n",
              "         606197: 2,\n",
              "         381458: 70,\n",
              "         136310: 3,\n",
              "         316546: 4,\n",
              "         335481: 4,\n",
              "         408746: 3,\n",
              "         437574: 3,\n",
              "         511865: 3,\n",
              "         546854: 2,\n",
              "         567066: 3,\n",
              "         598769: 2,\n",
              "         653533: 2,\n",
              "         656744: 2,\n",
              "         663100: 3,\n",
              "         671641: 4,\n",
              "         697611: 3,\n",
              "         701404: 1,\n",
              "         703056: 3,\n",
              "         706715: 7,\n",
              "         717264: 4,\n",
              "         717745: 5,\n",
              "         732748: 4,\n",
              "         643565: 3,\n",
              "         668479: 4,\n",
              "         693028: 3,\n",
              "         370824: 6,\n",
              "         191618: 11,\n",
              "         213477: 7,\n",
              "         290118: 3,\n",
              "         76671: 6,\n",
              "         91576: 2,\n",
              "         464121: 7,\n",
              "         473520: 4,\n",
              "         339661: 10,\n",
              "         6578: 4,\n",
              "         153522: 3,\n",
              "         381954: 1,\n",
              "         404732: 4,\n",
              "         409059: 3,\n",
              "         409716: 2,\n",
              "         421148: 4,\n",
              "         423538: 5,\n",
              "         440100: 1,\n",
              "         443273: 2,\n",
              "         445367: 3,\n",
              "         541751: 4,\n",
              "         562507: 5,\n",
              "         655205: 3,\n",
              "         703431: 3,\n",
              "         543969: 5,\n",
              "         4427: 2,\n",
              "         59938: 2,\n",
              "         438990: 2,\n",
              "         439218: 2,\n",
              "         478865: 3,\n",
              "         495156: 3,\n",
              "         496448: 3,\n",
              "         500505: 4,\n",
              "         506989: 3,\n",
              "         570576: 3,\n",
              "         578472: 2,\n",
              "         582809: 3,\n",
              "         627909: 4,\n",
              "         658992: 3,\n",
              "         690910: 3,\n",
              "         726405: 2,\n",
              "         83473: 12,\n",
              "         202829: 4,\n",
              "         255198: 8,\n",
              "         282236: 4,\n",
              "         320907: 4,\n",
              "         336773: 9,\n",
              "         342830: 3,\n",
              "         458510: 8,\n",
              "         474108: 6,\n",
              "         477906: 6,\n",
              "         566206: 11,\n",
              "         605145: 8,\n",
              "         241641: 2,\n",
              "         243161: 3,\n",
              "         391389: 3,\n",
              "         421916: 3,\n",
              "         434570: 3,\n",
              "         254482: 4,\n",
              "         364664: 2,\n",
              "         554225: 4,\n",
              "         15523: 6,\n",
              "         16118: 5,\n",
              "         22703: 8,\n",
              "         180867: 11,\n",
              "         343721: 8,\n",
              "         352046: 9,\n",
              "         368523: 12,\n",
              "         504013: 13,\n",
              "         167428: 2,\n",
              "         370845: 2,\n",
              "         397992: 3,\n",
              "         465983: 2,\n",
              "         594143: 2,\n",
              "         632552: 6,\n",
              "         722394: 3,\n",
              "         729690: 4,\n",
              "         733103: 3,\n",
              "         59483: 37,\n",
              "         179502: 5,\n",
              "         304086: 14,\n",
              "         415278: 25,\n",
              "         536764: 26,\n",
              "         5605: 6,\n",
              "         294304: 6,\n",
              "         450859: 11,\n",
              "         133222: 16,\n",
              "         198414: 17,\n",
              "         219374: 10,\n",
              "         295253: 163,\n",
              "         383746: 165,\n",
              "         437268: 171,\n",
              "         56216: 12,\n",
              "         97485: 9,\n",
              "         240453: 8,\n",
              "         319956: 9,\n",
              "         349605: 8,\n",
              "         352504: 8,\n",
              "         423419: 15,\n",
              "         86015: 4,\n",
              "         582352: 3,\n",
              "         297235: 6,\n",
              "         365851: 4,\n",
              "         112205: 14,\n",
              "         253894: 8,\n",
              "         254357: 7,\n",
              "         339572: 5,\n",
              "         386416: 3,\n",
              "         445698: 7,\n",
              "         697229: 5,\n",
              "         354224: 11,\n",
              "         97722: 3,\n",
              "         316420: 5,\n",
              "         560235: 5,\n",
              "         144003: 4,\n",
              "         172189: 9,\n",
              "         177996: 2,\n",
              "         181275: 3,\n",
              "         184357: 5,\n",
              "         238106: 5,\n",
              "         244677: 6,\n",
              "         250598: 3,\n",
              "         269772: 3,\n",
              "         292149: 4,\n",
              "         308572: 6,\n",
              "         346169: 5,\n",
              "         359052: 2,\n",
              "         371655: 4,\n",
              "         400968: 3,\n",
              "         406583: 4,\n",
              "         412674: 4,\n",
              "         472288: 3,\n",
              "         519004: 7,\n",
              "         572565: 6,\n",
              "         578540: 6,\n",
              "         585939: 6,\n",
              "         593424: 6,\n",
              "         594960: 8,\n",
              "         611938: 50,\n",
              "         624623: 12,\n",
              "         636566: 8,\n",
              "         104294: 4,\n",
              "         369925: 5,\n",
              "         587279: 3,\n",
              "         664943: 3,\n",
              "         506577: 8,\n",
              "         436916: 6,\n",
              "         521661: 3,\n",
              "         549213: 2,\n",
              "         588343: 2,\n",
              "         642325: 2,\n",
              "         656570: 2,\n",
              "         666448: 5,\n",
              "         669049: 3,\n",
              "         675172: 2,\n",
              "         677414: 3,\n",
              "         687789: 2,\n",
              "         702431: 5,\n",
              "         730953: 3,\n",
              "         732987: 3,\n",
              "         735437: 3,\n",
              "         118415: 5,\n",
              "         399234: 6,\n",
              "         405037: 9,\n",
              "         414579: 9,\n",
              "         455439: 13,\n",
              "         483741: 9,\n",
              "         143516: 12,\n",
              "         245628: 8,\n",
              "         311735: 7,\n",
              "         411415: 11,\n",
              "         35197: 4,\n",
              "         40632: 7,\n",
              "         113551: 5,\n",
              "         204333: 6,\n",
              "         216757: 9,\n",
              "         270986: 7,\n",
              "         310089: 3,\n",
              "         333648: 5,\n",
              "         361768: 4,\n",
              "         383042: 34,\n",
              "         402799: 6,\n",
              "         427314: 5,\n",
              "         482759: 7,\n",
              "         495167: 4,\n",
              "         537987: 7,\n",
              "         581513: 4,\n",
              "         624042: 8,\n",
              "         695239: 4,\n",
              "         702967: 16,\n",
              "         707061: 3,\n",
              "         103593: 5,\n",
              "         120559: 5,\n",
              "         226760: 6,\n",
              "         232925: 7,\n",
              "         267228: 10,\n",
              "         479172: 9,\n",
              "         534938: 8,\n",
              "         590841: 12,\n",
              "         664200: 15,\n",
              "         72938: 3,\n",
              "         154696: 3,\n",
              "         169094: 3,\n",
              "         288630: 5,\n",
              "         24397: 3,\n",
              "         57078: 3,\n",
              "         57578: 3,\n",
              "         71590: 2,\n",
              "         110523: 2,\n",
              "         113108: 4,\n",
              "         148316: 2,\n",
              "         156091: 3,\n",
              "         255956: 2,\n",
              "         292067: 4,\n",
              "         297593: 2,\n",
              "         304940: 3,\n",
              "         346006: 6,\n",
              "         362281: 4,\n",
              "         392253: 3,\n",
              "         395527: 2,\n",
              "         427933: 3,\n",
              "         428777: 3,\n",
              "         481995: 3,\n",
              "         483799: 3,\n",
              "         516241: 4,\n",
              "         518586: 4,\n",
              "         553097: 2,\n",
              "         667995: 3,\n",
              "         669709: 3,\n",
              "         687171: 5,\n",
              "         688279: 6,\n",
              "         692143: 2,\n",
              "         696782: 5,\n",
              "         724342: 3,\n",
              "         33348: 4,\n",
              "         45992: 3,\n",
              "         267630: 4,\n",
              "         348439: 4,\n",
              "         91650: 5,\n",
              "         306727: 4,\n",
              "         115286: 6,\n",
              "         157278: 4,\n",
              "         346308: 2,\n",
              "         564536: 7,\n",
              "         626953: 3,\n",
              "         150211: 3,\n",
              "         370617: 31,\n",
              "         514567: 6,\n",
              "         529256: 6,\n",
              "         680088: 11,\n",
              "         717970: 3,\n",
              "         81025: 5,\n",
              "         92202: 5,\n",
              "         171221: 2,\n",
              "         207889: 3,\n",
              "         399202: 4,\n",
              "         402793: 3,\n",
              "         431705: 4,\n",
              "         469990: 4,\n",
              "         478627: 4,\n",
              "         525711: 4,\n",
              "         658906: 5,\n",
              "         715412: 8,\n",
              "         720633: 5,\n",
              "         13762: 3,\n",
              "         25527: 4,\n",
              "         27558: 5,\n",
              "         39354: 3,\n",
              "         56161: 4,\n",
              "         68343: 4,\n",
              "         112325: 4,\n",
              "         144985: 3,\n",
              "         172585: 3,\n",
              "         201290: 4,\n",
              "         204886: 6,\n",
              "         234895: 5,\n",
              "         260366: 3,\n",
              "         281184: 6,\n",
              "         303311: 2,\n",
              "         315198: 4,\n",
              "         330255: 3,\n",
              "         363916: 3,\n",
              "         374896: 3,\n",
              "         402674: 4,\n",
              "         417924: 7,\n",
              "         475957: 6,\n",
              "         518796: 3,\n",
              "         544421: 3,\n",
              "         559161: 5,\n",
              "         611924: 9,\n",
              "         612722: 4,\n",
              "         616421: 4,\n",
              "         619406: 8,\n",
              "         622587: 3,\n",
              "         624448: 12,\n",
              "         628221: 2,\n",
              "         641271: 4,\n",
              "         643490: 5,\n",
              "         663234: 4,\n",
              "         666773: 13,\n",
              "         670128: 5,\n",
              "         ...})"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "paper_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdsF_6JmIII-"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kp3AvQbjGnni"
      },
      "outputs": [],
      "source": [
        "X = Data.drop('Class', axis=1)\n",
        "y = Data['Class']\n",
        "X_train=X.iloc[list(train_idx)+list(valid_idx)]\n",
        "X_test=X.iloc[test_idx]\n",
        "y_train=y.iloc[list(train_idx)+list(valid_idx)]\n",
        "y_test=y.iloc[test_idx]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del X, y"
      ],
      "metadata": {
        "id": "16fCx9r3LzI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del topic_df, topic_vecs, paper_topic_vecs"
      ],
      "metadata": {
        "id": "zks_UMXvVkK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51rCXhJ5jvse"
      },
      "outputs": [],
      "source": [
        "X = Data.iloc[:, :-112]\n",
        "y = Data.iloc[:, -112:]\n",
        "X_train=X.iloc[list(train_idx)+list(valid_idx)]\n",
        "X_test=X.iloc[test_idx].drop(132533)\n",
        "y_train=y.iloc[list(train_idx)+list(valid_idx)]\n",
        "y_test=y.iloc[test_idx].drop(132533)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_2 = Data.iloc[:, -112:-109]\n",
        "y_train_2=y_2.iloc[list(train_idx)+list(valid_idx)]\n",
        "y_test_2=y_2.iloc[test_idx].drop(132533)"
      ],
      "metadata": {
        "id": "Bw2qS150FcWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ziKneaRLF5Vy",
        "outputId": "8f952c6f-02d7-4724-adcc-d31451c82725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0  1  2\n",
              "0       1  1  1\n",
              "1       1  1  0\n",
              "2       0  0  0\n",
              "3       0  0  0\n",
              "4       1  1  1\n",
              "...    .. .. ..\n",
              "132529  0  0  0\n",
              "132530  0  0  0\n",
              "132531  0  0  0\n",
              "132532  0  0  0\n",
              "132533  0  0  0\n",
              "\n",
              "[132534 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c306188-bc7e-4784-a67e-8a419e9629b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132529</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132530</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132531</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132532</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132533</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>132534 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c306188-bc7e-4784-a67e-8a419e9629b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c306188-bc7e-4784-a67e-8a419e9629b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c306188-bc7e-4784-a67e-8a419e9629b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "lowc7q5mjj7L",
        "outputId": "28de5c8b-cfb7-481b-8178-56a31b25d6ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0    1    2    3    4    5    6    7    8    9    ...  102  103  104  \\\n",
              "107855    1    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "107856    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "107857    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "107858    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "107859    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "132528    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "132529    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "132530    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "132531    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "132532    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "\n",
              "        105  106  107  108  109  110  111  \n",
              "107855    0    0    0    0    0    0    0  \n",
              "107856    0    0    0    0    0    0    0  \n",
              "107857    0    0    0    0    0    0    0  \n",
              "107858    0    0    0    0    0    0    0  \n",
              "107859    0    0    0    0    0    0    0  \n",
              "...     ...  ...  ...  ...  ...  ...  ...  \n",
              "132528    0    0    0    0    0    0    0  \n",
              "132529    0    0    0    0    0    0    0  \n",
              "132530    0    0    0    0    0    0    0  \n",
              "132531    0    0    0    0    0    0    0  \n",
              "132532    0    0    0    0    0    0    0  \n",
              "\n",
              "[24678 rows x 112 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddd6538f-f2b2-42bc-bb4b-7666633f46ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>102</th>\n",
              "      <th>103</th>\n",
              "      <th>104</th>\n",
              "      <th>105</th>\n",
              "      <th>106</th>\n",
              "      <th>107</th>\n",
              "      <th>108</th>\n",
              "      <th>109</th>\n",
              "      <th>110</th>\n",
              "      <th>111</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>107855</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107856</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107857</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107858</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107859</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132528</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132529</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132530</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132531</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132532</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24678 rows × 112 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddd6538f-f2b2-42bc-bb4b-7666633f46ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ddd6538f-f2b2-42bc-bb4b-7666633f46ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ddd6538f-f2b2-42bc-bb4b-7666633f46ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxBRldqyLE4F"
      },
      "outputs": [],
      "source": [
        "earlystop1 = EarlyStopping(patience=7)\n",
        "earlystop2 = ReduceLROnPlateau(monitor='val_loss',\n",
        "                               min_lr = 3e-7, \n",
        "                               patience = 4,\n",
        "                               factor=0.3,\n",
        "                               verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMm4cSK9tEkU",
        "outputId": "6d5e8f69-1c7f-4daf-933b-b860b212b695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tf-nightly\n",
            "  Downloading tf_nightly-2.14.0.dev20230513-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (528.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.6/528.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.8.0)\n",
            "Collecting keras-nightly~=2.14.0.dev (from tf-nightly)\n",
            "  Downloading keras_nightly-2.14.0.dev2023051307-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (16.0.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.16.0)\n",
            "Collecting tb-nightly~=2.14.0.a (from tf-nightly)\n",
            "  Downloading tb_nightly-2.14.0a20230513-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (2.3.0)\n",
            "Collecting tf-estimator-nightly~=2.14.0.dev (from tf-nightly)\n",
            "  Downloading tf_estimator_nightly-2.14.0.dev2023051308-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.0/441.0 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tf-nightly) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (0.7.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tb-nightly~=2.14.0.a->tf-nightly) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tb-nightly~=2.14.0.a->tf-nightly) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tb-nightly~=2.14.0.a->tf-nightly) (3.2.2)\n",
            "Installing collected packages: tf-estimator-nightly, keras-nightly, tb-nightly, tf-nightly\n",
            "Successfully installed keras-nightly-2.14.0.dev2023051307 tb-nightly-2.14.0a20230513 tf-estimator-nightly-2.14.0.dev2023051308 tf-nightly-2.14.0.dev20230513\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%pip install tf-nightly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZzEjewPkLvw",
        "outputId": "eb7d6971-3c12-42b4-ddb5-201453ac6aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/100\n",
            "843/843 [==============================] - 5s 4ms/step - loss: 8.4430 - auc: 0.5208 - binary_accuracy: 0.7017 - val_loss: 0.6481 - val_auc: 0.5342 - val_binary_accuracy: 0.8669\n",
            "Epoch 2/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 3.4946 - auc: 0.5324 - binary_accuracy: 0.7459 - val_loss: 0.4648 - val_auc: 0.5415 - val_binary_accuracy: 0.8976\n",
            "Epoch 3/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 2.5278 - auc: 0.5381 - binary_accuracy: 0.7600 - val_loss: 0.4044 - val_auc: 0.5432 - val_binary_accuracy: 0.9096\n",
            "Epoch 4/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 2.0151 - auc: 0.5423 - binary_accuracy: 0.7692 - val_loss: 0.3585 - val_auc: 0.5453 - val_binary_accuracy: 0.9172\n",
            "Epoch 5/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 1.6964 - auc: 0.5464 - binary_accuracy: 0.7776 - val_loss: 0.3446 - val_auc: 0.5518 - val_binary_accuracy: 0.9222\n",
            "Epoch 6/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 1.4623 - auc: 0.5505 - binary_accuracy: 0.7855 - val_loss: 0.3203 - val_auc: 0.5556 - val_binary_accuracy: 0.9273\n",
            "Epoch 7/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 1.2819 - auc: 0.5551 - binary_accuracy: 0.7922 - val_loss: 0.2725 - val_auc: 0.5608 - val_binary_accuracy: 0.9464\n",
            "Epoch 8/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 1.1329 - auc: 0.5601 - binary_accuracy: 0.7986 - val_loss: 0.2511 - val_auc: 0.5673 - val_binary_accuracy: 0.9547\n",
            "Epoch 9/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 1.0113 - auc: 0.5657 - binary_accuracy: 0.8040 - val_loss: 0.2948 - val_auc: 0.5682 - val_binary_accuracy: 0.9351\n",
            "Epoch 10/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.9106 - auc: 0.5709 - binary_accuracy: 0.8089 - val_loss: 0.2338 - val_auc: 0.5825 - val_binary_accuracy: 0.9586\n",
            "Epoch 11/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.8250 - auc: 0.5758 - binary_accuracy: 0.8134 - val_loss: 0.2376 - val_auc: 0.5943 - val_binary_accuracy: 0.9567\n",
            "Epoch 12/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.7548 - auc: 0.5820 - binary_accuracy: 0.8177 - val_loss: 0.2255 - val_auc: 0.5956 - val_binary_accuracy: 0.9608\n",
            "Epoch 13/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.6955 - auc: 0.5879 - binary_accuracy: 0.8216 - val_loss: 0.2159 - val_auc: 0.5949 - val_binary_accuracy: 0.9610\n",
            "Epoch 14/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.6457 - auc: 0.5942 - binary_accuracy: 0.8258 - val_loss: 0.2118 - val_auc: 0.6051 - val_binary_accuracy: 0.9645\n",
            "Epoch 15/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.6039 - auc: 0.6001 - binary_accuracy: 0.8295 - val_loss: 0.2139 - val_auc: 0.6120 - val_binary_accuracy: 0.9644\n",
            "Epoch 16/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.5685 - auc: 0.6061 - binary_accuracy: 0.8328 - val_loss: 0.2182 - val_auc: 0.6198 - val_binary_accuracy: 0.9622\n",
            "Epoch 17/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.5388 - auc: 0.6132 - binary_accuracy: 0.8364 - val_loss: 0.2169 - val_auc: 0.6240 - val_binary_accuracy: 0.9638\n",
            "Epoch 18/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.5137 - auc: 0.6199 - binary_accuracy: 0.8393 - val_loss: 0.2068 - val_auc: 0.6203 - val_binary_accuracy: 0.9673\n",
            "Epoch 19/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.4933 - auc: 0.6258 - binary_accuracy: 0.8420 - val_loss: 0.1964 - val_auc: 0.6330 - val_binary_accuracy: 0.9687\n",
            "Epoch 20/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.4754 - auc: 0.6320 - binary_accuracy: 0.8444 - val_loss: 0.2062 - val_auc: 0.6302 - val_binary_accuracy: 0.9620\n",
            "Epoch 21/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.4606 - auc: 0.6381 - binary_accuracy: 0.8468 - val_loss: 0.1891 - val_auc: 0.6366 - val_binary_accuracy: 0.9688\n",
            "Epoch 22/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.4481 - auc: 0.6438 - binary_accuracy: 0.8488 - val_loss: 0.1966 - val_auc: 0.6413 - val_binary_accuracy: 0.9694\n",
            "Epoch 23/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.4369 - auc: 0.6496 - binary_accuracy: 0.8506 - val_loss: 0.1884 - val_auc: 0.6403 - val_binary_accuracy: 0.9689\n",
            "Epoch 24/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.4273 - auc: 0.6553 - binary_accuracy: 0.8522 - val_loss: 0.1864 - val_auc: 0.6485 - val_binary_accuracy: 0.9703\n",
            "Epoch 25/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.4189 - auc: 0.6613 - binary_accuracy: 0.8539 - val_loss: 0.1973 - val_auc: 0.6488 - val_binary_accuracy: 0.9650\n",
            "Epoch 26/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.4135 - auc: 0.6644 - binary_accuracy: 0.8550 - val_loss: 0.1893 - val_auc: 0.6515 - val_binary_accuracy: 0.9701\n",
            "Epoch 27/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.4055 - auc: 0.6706 - binary_accuracy: 0.8565 - val_loss: 0.1871 - val_auc: 0.6543 - val_binary_accuracy: 0.9687\n",
            "Epoch 28/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.4002 - auc: 0.6750 - binary_accuracy: 0.8575 - val_loss: 0.1791 - val_auc: 0.6565 - val_binary_accuracy: 0.9717\n",
            "Epoch 29/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3962 - auc: 0.6789 - binary_accuracy: 0.8583 - val_loss: 0.1788 - val_auc: 0.6525 - val_binary_accuracy: 0.9700\n",
            "Epoch 30/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3912 - auc: 0.6843 - binary_accuracy: 0.8593 - val_loss: 0.2043 - val_auc: 0.6434 - val_binary_accuracy: 0.9528\n",
            "Epoch 31/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3874 - auc: 0.6875 - binary_accuracy: 0.8601 - val_loss: 0.1710 - val_auc: 0.6536 - val_binary_accuracy: 0.9709\n",
            "Epoch 32/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3846 - auc: 0.6904 - binary_accuracy: 0.8607 - val_loss: 0.1683 - val_auc: 0.6593 - val_binary_accuracy: 0.9719\n",
            "Epoch 33/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3818 - auc: 0.6936 - binary_accuracy: 0.8613 - val_loss: 0.1754 - val_auc: 0.6533 - val_binary_accuracy: 0.9704\n",
            "Epoch 34/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3791 - auc: 0.6962 - binary_accuracy: 0.8620 - val_loss: 0.1694 - val_auc: 0.6613 - val_binary_accuracy: 0.9717\n",
            "Epoch 35/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3769 - auc: 0.6991 - binary_accuracy: 0.8625 - val_loss: 0.1748 - val_auc: 0.6587 - val_binary_accuracy: 0.9707\n",
            "Epoch 36/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3742 - auc: 0.7023 - binary_accuracy: 0.8632 - val_loss: 0.1756 - val_auc: 0.6612 - val_binary_accuracy: 0.9703\n",
            "Epoch 37/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3727 - auc: 0.7052 - binary_accuracy: 0.8634 - val_loss: 0.1619 - val_auc: 0.6614 - val_binary_accuracy: 0.9724\n",
            "Epoch 38/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3711 - auc: 0.7065 - binary_accuracy: 0.8638 - val_loss: 0.1697 - val_auc: 0.6599 - val_binary_accuracy: 0.9705\n",
            "Epoch 39/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3691 - auc: 0.7096 - binary_accuracy: 0.8643 - val_loss: 0.1699 - val_auc: 0.6632 - val_binary_accuracy: 0.9717\n",
            "Epoch 40/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3677 - auc: 0.7114 - binary_accuracy: 0.8646 - val_loss: 0.1753 - val_auc: 0.6607 - val_binary_accuracy: 0.9708\n",
            "Epoch 41/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3661 - auc: 0.7140 - binary_accuracy: 0.8649 - val_loss: 0.1692 - val_auc: 0.6641 - val_binary_accuracy: 0.9709\n",
            "Epoch 42/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3653 - auc: 0.7155 - binary_accuracy: 0.8649 - val_loss: 0.1678 - val_auc: 0.6647 - val_binary_accuracy: 0.9714\n",
            "Epoch 43/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3639 - auc: 0.7173 - binary_accuracy: 0.8654 - val_loss: 0.1627 - val_auc: 0.6637 - val_binary_accuracy: 0.9722\n",
            "Epoch 44/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3624 - auc: 0.7193 - binary_accuracy: 0.8657 - val_loss: 0.1715 - val_auc: 0.6614 - val_binary_accuracy: 0.9681\n",
            "Epoch 45/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3619 - auc: 0.7204 - binary_accuracy: 0.8658 - val_loss: 0.1792 - val_auc: 0.6608 - val_binary_accuracy: 0.9641\n",
            "Epoch 46/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3611 - auc: 0.7212 - binary_accuracy: 0.8662 - val_loss: 0.1663 - val_auc: 0.6630 - val_binary_accuracy: 0.9728\n",
            "Epoch 47/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3601 - auc: 0.7224 - binary_accuracy: 0.8665 - val_loss: 0.1690 - val_auc: 0.6671 - val_binary_accuracy: 0.9716\n",
            "Epoch 48/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3599 - auc: 0.7227 - binary_accuracy: 0.8664 - val_loss: 0.1843 - val_auc: 0.6566 - val_binary_accuracy: 0.9638\n",
            "Epoch 49/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3582 - auc: 0.7256 - binary_accuracy: 0.8668 - val_loss: 0.1741 - val_auc: 0.6605 - val_binary_accuracy: 0.9690\n",
            "Epoch 50/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3582 - auc: 0.7259 - binary_accuracy: 0.8668 - val_loss: 0.1644 - val_auc: 0.6635 - val_binary_accuracy: 0.9724\n",
            "Epoch 51/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3573 - auc: 0.7271 - binary_accuracy: 0.8670 - val_loss: 0.1669 - val_auc: 0.6653 - val_binary_accuracy: 0.9714\n",
            "Epoch 52/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3566 - auc: 0.7284 - binary_accuracy: 0.8673 - val_loss: 0.1631 - val_auc: 0.6693 - val_binary_accuracy: 0.9731\n",
            "Epoch 53/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3566 - auc: 0.7283 - binary_accuracy: 0.8672 - val_loss: 0.1605 - val_auc: 0.6668 - val_binary_accuracy: 0.9728\n",
            "Epoch 54/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3562 - auc: 0.7286 - binary_accuracy: 0.8674 - val_loss: 0.1653 - val_auc: 0.6656 - val_binary_accuracy: 0.9727\n",
            "Epoch 55/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3550 - auc: 0.7308 - binary_accuracy: 0.8675 - val_loss: 0.1697 - val_auc: 0.6641 - val_binary_accuracy: 0.9706\n",
            "Epoch 56/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3547 - auc: 0.7315 - binary_accuracy: 0.8677 - val_loss: 0.1684 - val_auc: 0.6683 - val_binary_accuracy: 0.9723\n",
            "Epoch 57/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3545 - auc: 0.7319 - binary_accuracy: 0.8677 - val_loss: 0.1686 - val_auc: 0.6688 - val_binary_accuracy: 0.9715\n",
            "Epoch 58/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3537 - auc: 0.7330 - binary_accuracy: 0.8678 - val_loss: 0.1653 - val_auc: 0.6649 - val_binary_accuracy: 0.9721\n",
            "Epoch 59/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3538 - auc: 0.7331 - binary_accuracy: 0.8680 - val_loss: 0.1723 - val_auc: 0.6632 - val_binary_accuracy: 0.9700\n",
            "Epoch 60/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3526 - auc: 0.7355 - binary_accuracy: 0.8682 - val_loss: 0.1625 - val_auc: 0.6697 - val_binary_accuracy: 0.9727\n",
            "Epoch 61/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3525 - auc: 0.7357 - binary_accuracy: 0.8682 - val_loss: 0.1678 - val_auc: 0.6643 - val_binary_accuracy: 0.9722\n",
            "Epoch 62/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3525 - auc: 0.7355 - binary_accuracy: 0.8682 - val_loss: 0.1664 - val_auc: 0.6677 - val_binary_accuracy: 0.9719\n",
            "Epoch 63/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3522 - auc: 0.7357 - binary_accuracy: 0.8683 - val_loss: 0.1682 - val_auc: 0.6700 - val_binary_accuracy: 0.9719\n",
            "Epoch 64/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3514 - auc: 0.7372 - binary_accuracy: 0.8685 - val_loss: 0.1776 - val_auc: 0.6568 - val_binary_accuracy: 0.9688\n",
            "Epoch 65/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3518 - auc: 0.7365 - binary_accuracy: 0.8683 - val_loss: 0.1832 - val_auc: 0.6547 - val_binary_accuracy: 0.9633\n",
            "Epoch 66/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3516 - auc: 0.7369 - binary_accuracy: 0.8685 - val_loss: 0.1679 - val_auc: 0.6629 - val_binary_accuracy: 0.9706\n",
            "Epoch 67/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3511 - auc: 0.7380 - binary_accuracy: 0.8684 - val_loss: 0.1645 - val_auc: 0.6676 - val_binary_accuracy: 0.9723\n",
            "Epoch 68/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3506 - auc: 0.7386 - binary_accuracy: 0.8687 - val_loss: 0.1653 - val_auc: 0.6676 - val_binary_accuracy: 0.9727\n",
            "Epoch 69/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3507 - auc: 0.7387 - binary_accuracy: 0.8686 - val_loss: 0.1672 - val_auc: 0.6656 - val_binary_accuracy: 0.9717\n",
            "Epoch 70/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3504 - auc: 0.7391 - binary_accuracy: 0.8687 - val_loss: 0.1684 - val_auc: 0.6627 - val_binary_accuracy: 0.9714\n",
            "Epoch 71/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3501 - auc: 0.7400 - binary_accuracy: 0.8687 - val_loss: 0.1635 - val_auc: 0.6694 - val_binary_accuracy: 0.9726\n",
            "Epoch 72/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3498 - auc: 0.7404 - binary_accuracy: 0.8688 - val_loss: 0.1732 - val_auc: 0.6586 - val_binary_accuracy: 0.9704\n",
            "Epoch 73/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3496 - auc: 0.7408 - binary_accuracy: 0.8688 - val_loss: 0.1672 - val_auc: 0.6648 - val_binary_accuracy: 0.9720\n",
            "Epoch 74/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3490 - auc: 0.7423 - binary_accuracy: 0.8689 - val_loss: 0.1577 - val_auc: 0.6703 - val_binary_accuracy: 0.9731\n",
            "Epoch 75/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3496 - auc: 0.7412 - binary_accuracy: 0.8688 - val_loss: 0.1733 - val_auc: 0.6609 - val_binary_accuracy: 0.9690\n",
            "Epoch 76/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3495 - auc: 0.7412 - binary_accuracy: 0.8689 - val_loss: 0.1807 - val_auc: 0.6586 - val_binary_accuracy: 0.9644\n",
            "Epoch 77/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3486 - auc: 0.7425 - binary_accuracy: 0.8690 - val_loss: 0.1628 - val_auc: 0.6653 - val_binary_accuracy: 0.9726\n",
            "Epoch 78/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3479 - auc: 0.7439 - binary_accuracy: 0.8692 - val_loss: 0.1733 - val_auc: 0.6614 - val_binary_accuracy: 0.9703\n",
            "Epoch 79/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3488 - auc: 0.7427 - binary_accuracy: 0.8689 - val_loss: 0.1682 - val_auc: 0.6644 - val_binary_accuracy: 0.9719\n",
            "Epoch 80/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3485 - auc: 0.7429 - binary_accuracy: 0.8691 - val_loss: 0.1667 - val_auc: 0.6680 - val_binary_accuracy: 0.9726\n",
            "Epoch 81/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3480 - auc: 0.7438 - binary_accuracy: 0.8693 - val_loss: 0.1664 - val_auc: 0.6680 - val_binary_accuracy: 0.9723\n",
            "Epoch 82/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3483 - auc: 0.7434 - binary_accuracy: 0.8692 - val_loss: 0.1766 - val_auc: 0.6575 - val_binary_accuracy: 0.9676\n",
            "Epoch 83/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3482 - auc: 0.7438 - binary_accuracy: 0.8691 - val_loss: 0.1764 - val_auc: 0.6583 - val_binary_accuracy: 0.9665\n",
            "Epoch 84/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3480 - auc: 0.7444 - binary_accuracy: 0.8691 - val_loss: 0.1671 - val_auc: 0.6624 - val_binary_accuracy: 0.9721\n",
            "Epoch 85/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3477 - auc: 0.7444 - binary_accuracy: 0.8692 - val_loss: 0.1696 - val_auc: 0.6631 - val_binary_accuracy: 0.9715\n",
            "Epoch 86/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3474 - auc: 0.7449 - binary_accuracy: 0.8693 - val_loss: 0.1674 - val_auc: 0.6644 - val_binary_accuracy: 0.9720\n",
            "Epoch 87/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3477 - auc: 0.7448 - binary_accuracy: 0.8692 - val_loss: 0.1752 - val_auc: 0.6589 - val_binary_accuracy: 0.9647\n",
            "Epoch 88/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3477 - auc: 0.7448 - binary_accuracy: 0.8692 - val_loss: 0.1605 - val_auc: 0.6662 - val_binary_accuracy: 0.9737\n",
            "Epoch 89/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3471 - auc: 0.7458 - binary_accuracy: 0.8694 - val_loss: 0.1629 - val_auc: 0.6681 - val_binary_accuracy: 0.9733\n",
            "Epoch 90/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3477 - auc: 0.7447 - binary_accuracy: 0.8694 - val_loss: 0.1663 - val_auc: 0.6665 - val_binary_accuracy: 0.9725\n",
            "Epoch 91/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3471 - auc: 0.7455 - binary_accuracy: 0.8694 - val_loss: 0.1635 - val_auc: 0.6622 - val_binary_accuracy: 0.9735\n",
            "Epoch 92/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3466 - auc: 0.7469 - binary_accuracy: 0.8695 - val_loss: 0.1734 - val_auc: 0.6621 - val_binary_accuracy: 0.9684\n",
            "Epoch 93/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3471 - auc: 0.7459 - binary_accuracy: 0.8693 - val_loss: 0.1657 - val_auc: 0.6657 - val_binary_accuracy: 0.9729\n",
            "Epoch 94/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3468 - auc: 0.7470 - binary_accuracy: 0.8694 - val_loss: 0.1723 - val_auc: 0.6605 - val_binary_accuracy: 0.9706\n",
            "Epoch 95/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3468 - auc: 0.7463 - binary_accuracy: 0.8695 - val_loss: 0.1687 - val_auc: 0.6656 - val_binary_accuracy: 0.9716\n",
            "Epoch 96/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3466 - auc: 0.7471 - binary_accuracy: 0.8694 - val_loss: 0.1795 - val_auc: 0.6569 - val_binary_accuracy: 0.9630\n",
            "Epoch 97/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3466 - auc: 0.7471 - binary_accuracy: 0.8695 - val_loss: 0.1703 - val_auc: 0.6610 - val_binary_accuracy: 0.9709\n",
            "Epoch 98/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3462 - auc: 0.7477 - binary_accuracy: 0.8694 - val_loss: 0.1641 - val_auc: 0.6652 - val_binary_accuracy: 0.9730\n",
            "Epoch 99/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3459 - auc: 0.7482 - binary_accuracy: 0.8696 - val_loss: 0.1628 - val_auc: 0.6673 - val_binary_accuracy: 0.9726\n",
            "Epoch 100/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.3462 - auc: 0.7483 - binary_accuracy: 0.8694 - val_loss: 0.1668 - val_auc: 0.6684 - val_binary_accuracy: 0.9727\n",
            "Score for fold 1: loss of 0.15765073895454407; auc of 67.02962517738342%\n"
          ]
        }
      ],
      "source": [
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "fold_no = 1\n",
        "checkpoint_filepath='/tmp/checkpoint'\n",
        "# for train, test in kfold.split(X_train, y_train):\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(len(X_train.iloc[0]),)),\n",
        "    tf.keras.layers.Dense(512),\n",
        "    tf.keras.layers.Dropout(.2),\n",
        "    tf.keras.layers.Dense(256),\n",
        "    tf.keras.layers.Dropout(.2),\n",
        "    tf.keras.layers.Dense(len(y.columns), activation='sigmoid')\n",
        "])\n",
        "\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "model.compile(optimizer=tf.keras.optimizers.AdamW(2e-5), loss=loss_fn, \n",
        "              metrics=[tf.keras.metrics.AUC(name='auc'), 'binary_accuracy'])\n",
        "print('------------------------------------------------------------------------')\n",
        "print(f'Training for fold {fold_no} ...')\n",
        "history = model.fit(np.array(X_train), np.array(y_train),\n",
        "                    batch_size = 128,\n",
        "                    epochs=100,\n",
        "                    use_multiprocessing=True,\n",
        "                    workers=4,\n",
        "                    validation_data=(np.array(X_test), np.array(y_test)),\n",
        "                    callbacks=[\n",
        "                                tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                                                save_best_only=True,\n",
        "                                                                save_weights_only=True,\n",
        "                                                                monitor='val_auc',\n",
        "                                                                mode='max')])\n",
        "model.load_weights(checkpoint_filepath)\n",
        "scores = model.evaluate(np.array(X_test), np.array(y_test), verbose=0)\n",
        "print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "acc_per_fold.append(scores[1] * 100)\n",
        "loss_per_fold.append(scores[0])\n",
        "fold_no += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "fold_no = 1\n",
        "checkpoint_filepath='/tmp/checkpoint'\n",
        "# for train, test in kfold.split(X_train, y_train):\n",
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(len(X_train.iloc[0]),)),\n",
        "    tf.keras.layers.Dense(512),\n",
        "    tf.keras.layers.Dropout(.2),\n",
        "    tf.keras.layers.Dense(256),\n",
        "    tf.keras.layers.Dropout(.2),\n",
        "    tf.keras.layers.Dense(len(y_2.columns), activation='sigmoid')\n",
        "])\n",
        "\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "model_2.compile(optimizer=tf.keras.optimizers.Adam(2e-5), loss=loss_fn, \n",
        "              metrics=[tf.keras.metrics.AUC(name='auc')])\n",
        "print('------------------------------------------------------------------------')\n",
        "print(f'Training for fold {fold_no} ...')\n",
        "history = model_2.fit(np.array(X_train), np.array(y_train_2),\n",
        "                    batch_size = 128,\n",
        "                    epochs=100,\n",
        "                    use_multiprocessing=True,\n",
        "                    workers=4,\n",
        "                    validation_data=(np.array(X_test), np.array(y_test_2)),\n",
        "                    callbacks=[\n",
        "                                tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                                                save_best_only=True,\n",
        "                                                                save_weights_only=True,\n",
        "                                                                monitor='val_auc',\n",
        "                                                                mode='max')])\n",
        "model_2.load_weights(checkpoint_filepath)\n",
        "scores = model_2.evaluate(np.array(X_test), np.array(y_test_2), verbose=0)\n",
        "print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]*100}%')\n",
        "acc_per_fold.append(scores[1] * 100)\n",
        "loss_per_fold.append(scores[0])\n",
        "fold_no += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y69P0j0sGLRq",
        "outputId": "63931a66-d6bf-4472-9d0f-564d2f17f4eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/100\n",
            "843/843 [==============================] - 5s 4ms/step - loss: 15.7280 - auc: 0.5758 - val_loss: 4.7970 - val_auc: 0.5306\n",
            "Epoch 2/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 8.5744 - auc: 0.5887 - val_loss: 4.1395 - val_auc: 0.5340\n",
            "Epoch 3/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 6.0498 - auc: 0.5938 - val_loss: 3.9661 - val_auc: 0.5330\n",
            "Epoch 4/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 4.8432 - auc: 0.5977 - val_loss: 2.1316 - val_auc: 0.5388\n",
            "Epoch 5/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 4.0415 - auc: 0.6020 - val_loss: 2.3948 - val_auc: 0.5160\n",
            "Epoch 6/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 3.4951 - auc: 0.6033 - val_loss: 1.6346 - val_auc: 0.5311\n",
            "Epoch 7/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 3.0409 - auc: 0.6062 - val_loss: 1.7923 - val_auc: 0.5272\n",
            "Epoch 8/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 2.7206 - auc: 0.6073 - val_loss: 1.3362 - val_auc: 0.5571\n",
            "Epoch 9/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 2.4479 - auc: 0.6095 - val_loss: 1.8061 - val_auc: 0.5342\n",
            "Epoch 10/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 2.2362 - auc: 0.6115 - val_loss: 1.3766 - val_auc: 0.5323\n",
            "Epoch 11/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 2.0670 - auc: 0.6147 - val_loss: 1.0817 - val_auc: 0.5491\n",
            "Epoch 12/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 1.9123 - auc: 0.6160 - val_loss: 1.1522 - val_auc: 0.5282\n",
            "Epoch 13/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 1.8058 - auc: 0.6168 - val_loss: 0.9465 - val_auc: 0.5438\n",
            "Epoch 14/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 1.6876 - auc: 0.6185 - val_loss: 0.8833 - val_auc: 0.5515\n",
            "Epoch 15/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 1.5910 - auc: 0.6216 - val_loss: 0.7906 - val_auc: 0.5408\n",
            "Epoch 16/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 1.5037 - auc: 0.6252 - val_loss: 0.7396 - val_auc: 0.5373\n",
            "Epoch 17/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 1.4381 - auc: 0.6260 - val_loss: 0.8035 - val_auc: 0.5472\n",
            "Epoch 18/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 1.3761 - auc: 0.6268 - val_loss: 0.7891 - val_auc: 0.5598\n",
            "Epoch 19/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 1.3002 - auc: 0.6302 - val_loss: 0.7264 - val_auc: 0.5585\n",
            "Epoch 20/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 1.2532 - auc: 0.6303 - val_loss: 0.7447 - val_auc: 0.5447\n",
            "Epoch 21/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 1.1987 - auc: 0.6330 - val_loss: 0.7626 - val_auc: 0.5381\n",
            "Epoch 22/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 1.1554 - auc: 0.6329 - val_loss: 0.7570 - val_auc: 0.5335\n",
            "Epoch 23/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 1.1078 - auc: 0.6353 - val_loss: 0.7746 - val_auc: 0.5290\n",
            "Epoch 24/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 1.0622 - auc: 0.6383 - val_loss: 0.8193 - val_auc: 0.5287\n",
            "Epoch 25/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 1.0254 - auc: 0.6414 - val_loss: 0.8616 - val_auc: 0.5373\n",
            "Epoch 26/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.9929 - auc: 0.6409 - val_loss: 0.6951 - val_auc: 0.5365\n",
            "Epoch 27/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.9544 - auc: 0.6453 - val_loss: 0.6888 - val_auc: 0.5399\n",
            "Epoch 28/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.9247 - auc: 0.6469 - val_loss: 0.6634 - val_auc: 0.5406\n",
            "Epoch 29/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.8949 - auc: 0.6500 - val_loss: 0.7431 - val_auc: 0.5347\n",
            "Epoch 30/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.8675 - auc: 0.6521 - val_loss: 0.5927 - val_auc: 0.5550\n",
            "Epoch 31/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.8433 - auc: 0.6544 - val_loss: 0.6404 - val_auc: 0.5424\n",
            "Epoch 32/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.8169 - auc: 0.6583 - val_loss: 0.6428 - val_auc: 0.5497\n",
            "Epoch 33/100\n",
            "843/843 [==============================] - 3s 4ms/step - loss: 0.7966 - auc: 0.6603 - val_loss: 0.6730 - val_auc: 0.5394\n",
            "Epoch 34/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.7765 - auc: 0.6639 - val_loss: 0.6583 - val_auc: 0.5386\n",
            "Epoch 35/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.7607 - auc: 0.6654 - val_loss: 0.5954 - val_auc: 0.5535\n",
            "Epoch 36/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.7431 - auc: 0.6688 - val_loss: 0.6562 - val_auc: 0.5386\n",
            "Epoch 37/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.7257 - auc: 0.6732 - val_loss: 0.6663 - val_auc: 0.5406\n",
            "Epoch 38/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.7125 - auc: 0.6771 - val_loss: 0.6441 - val_auc: 0.5412\n",
            "Epoch 39/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.7002 - auc: 0.6802 - val_loss: 0.6263 - val_auc: 0.5478\n",
            "Epoch 40/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.6885 - auc: 0.6841 - val_loss: 0.6270 - val_auc: 0.5546\n",
            "Epoch 41/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.6778 - auc: 0.6884 - val_loss: 0.6076 - val_auc: 0.5543\n",
            "Epoch 42/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.6696 - auc: 0.6914 - val_loss: 0.6148 - val_auc: 0.5310\n",
            "Epoch 43/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.6626 - auc: 0.6939 - val_loss: 0.6378 - val_auc: 0.5378\n",
            "Epoch 44/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.6544 - auc: 0.6994 - val_loss: 0.6285 - val_auc: 0.5425\n",
            "Epoch 45/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.6493 - auc: 0.7021 - val_loss: 0.5979 - val_auc: 0.5620\n",
            "Epoch 46/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.6439 - auc: 0.7061 - val_loss: 0.5848 - val_auc: 0.5612\n",
            "Epoch 47/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.6391 - auc: 0.7089 - val_loss: 0.6385 - val_auc: 0.5376\n",
            "Epoch 48/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.6363 - auc: 0.7110 - val_loss: 0.6218 - val_auc: 0.5427\n",
            "Epoch 49/100\n",
            "843/843 [==============================] - 3s 3ms/step - loss: 0.6330 - auc: 0.7137 - val_loss: 0.6067 - val_auc: 0.5627\n",
            "Epoch 50/100\n",
            " 17/843 [..............................] - ETA: 2s - loss: 0.6213 - auc: 0.7252"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-a559c26a5568>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'------------------------------------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training for fold {fold_no} ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m history = model_2.fit(np.array(X_train), np.array(y_train_2),\n\u001b[0m\u001b[1;32m     21\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[0;32m--> 142\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m    143\u001b[0m     return concrete_function._call_flat(\n\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m         self._function_spec.make_canonicalized_monomorphic_type(\n\u001b[1;32m    357\u001b[0m             args, kwargs, captures))\n\u001b[0;32m--> 358\u001b[0;31m     concrete_function = self._function_cache.lookup(current_func_context,\n\u001b[0m\u001b[1;32m    359\u001b[0m                                                     lookup_func_type)\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconcrete_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_cache.py\u001b[0m in \u001b[0;36mlookup\u001b[0;34m(self, context, function_type)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;34m\"\"\"Looks up a concrete function based on the context and type.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m       \u001b[0mdispatch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdispatch_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_primary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdispatch_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6Kr8kKhpT66",
        "outputId": "63815432-b3ae-4365-9859-ca07f56eba70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "772/772 [==============================] - 1s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5mh6OHTph9L"
      },
      "outputs": [],
      "source": [
        "y_pred = np.round(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-0e4r5npzjb",
        "outputId": "df92e068-a5f1-49a0-b2e4-6ef2c607216e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "CIZibmYPqQMj",
        "outputId": "82a1e142-e125-444d-9ff6-ddb616f954a7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-610af2b1-33f2-4c2e-ba4b-63c729b81398\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T_1</th>\n",
              "      <th>T_2</th>\n",
              "      <th>T_3</th>\n",
              "      <th>T_4</th>\n",
              "      <th>T_5</th>\n",
              "      <th>T_6</th>\n",
              "      <th>T_7</th>\n",
              "      <th>T_8</th>\n",
              "      <th>T_9</th>\n",
              "      <th>T_10</th>\n",
              "      <th>...</th>\n",
              "      <th>T_103</th>\n",
              "      <th>T_104</th>\n",
              "      <th>T_105</th>\n",
              "      <th>T_106</th>\n",
              "      <th>T_107</th>\n",
              "      <th>T_108</th>\n",
              "      <th>T_109</th>\n",
              "      <th>T_110</th>\n",
              "      <th>T_111</th>\n",
              "      <th>T_112</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>107855</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107856</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107857</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107858</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107859</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132528</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132529</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132530</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132531</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132532</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24678 rows × 112 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-610af2b1-33f2-4c2e-ba4b-63c729b81398')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-610af2b1-33f2-4c2e-ba4b-63c729b81398 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-610af2b1-33f2-4c2e-ba4b-63c729b81398');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        T_1  T_2  T_3  T_4  T_5  T_6  T_7  T_8  T_9  T_10  ...  T_103  T_104  \\\n",
              "107855    1    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
              "107856    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
              "107857    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
              "107858    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
              "107859    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
              "...     ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...    ...    ...   \n",
              "132528    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
              "132529    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
              "132530    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
              "132531    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
              "132532    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
              "\n",
              "        T_105  T_106  T_107  T_108  T_109  T_110  T_111  T_112  \n",
              "107855      0      0      0      0      0      0      0      0  \n",
              "107856      0      0      0      0      0      0      0      0  \n",
              "107857      0      0      0      0      0      0      0      0  \n",
              "107858      0      0      0      0      0      0      0      0  \n",
              "107859      0      0      0      0      0      0      0      0  \n",
              "...       ...    ...    ...    ...    ...    ...    ...    ...  \n",
              "132528      0      0      0      0      0      0      0      0  \n",
              "132529      0      0      0      0      0      0      0      0  \n",
              "132530      0      0      0      0      0      0      0      0  \n",
              "132531      0      0      0      0      0      0      0      0  \n",
              "132532      0      0      0      0      0      0      0      0  \n",
              "\n",
              "[24678 rows x 112 columns]"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkChWBirqAKd",
        "outputId": "d9be8574-e79c-4da7-9c78-57fc8c59ed92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.49877402406155447\n",
            "0.5\n",
            "0.499982376313368\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5016193553774021\n",
            "0.5\n",
            "0.5003491638879127\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.4998967240880737\n",
            "0.5\n",
            "0.49981198295312107\n",
            "0.5\n",
            "0.4998538072762207\n",
            "0.5\n",
            "0.49997906898861355\n",
            "0.5\n",
            "0.5\n",
            "0.49977044117033265\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.49995833159714986\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.49991701933449506\n",
            "0.5\n",
            "0.4999377722464219\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5013951002092557\n",
            "0.4998754463173628\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.49991695731606045\n",
            "0.4999585199933632\n",
            "0.5066979644536855\n",
            "0.5\n",
            "0.5\n",
            "0.5151883343668864\n",
            "0.5\n",
            "0.49997947202036375\n",
            "0.4999582341394144\n",
            "0.4998967283542631\n",
            "0.5\n",
            "0.49991808985542857\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.4999379755210056\n",
            "0.5\n",
            "0.5\n",
            "0.4999793191876577\n",
            "0.4998969454635393\n",
            "0.4998969454635393\n",
            "0.5\n",
            "0.49962796081187216\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.4999180596525729\n",
            "0.5\n",
            "0.5\n",
            "0.5005623860297338\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.4999386025950637\n",
            "0.5\n",
            "0.49944341372912804\n",
            "0.5060164330946612\n",
            "0.5\n",
            "0.49909304530650944\n",
            "0.5\n",
            "0.5\n",
            "0.4999591252810137\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.49971381847914964\n",
            "0.5\n",
            "0.49989785078042004\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.49530151985618565\n",
            "0.49995914031216804\n",
            "0.5\n",
            "0.5007730709359595\n",
            "0.5\n",
            "0.5046007022426273\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "for i in range(112):\n",
        "  print(roc_auc_score(y_test.to_numpy()[:, i], y_pred[:, i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cZMB880LE4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7909717-4f26-4b1a-927f-7cb924f20a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/100\n",
            "944/944 [==============================] - 5s 4ms/step - loss: 1.5910 - sparse_categorical_accuracy: 0.6545 - val_loss: 1.2088 - val_sparse_categorical_accuracy: 0.7018 - lr: 7.0000e-05\n",
            "Epoch 2/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.2293 - sparse_categorical_accuracy: 0.7104 - val_loss: 1.1475 - val_sparse_categorical_accuracy: 0.7038 - lr: 7.0000e-05\n",
            "Epoch 3/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.1740 - sparse_categorical_accuracy: 0.7155 - val_loss: 1.1166 - val_sparse_categorical_accuracy: 0.7030 - lr: 7.0000e-05\n",
            "Epoch 4/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.1236 - sparse_categorical_accuracy: 0.7168 - val_loss: 1.0768 - val_sparse_categorical_accuracy: 0.7144 - lr: 7.0000e-05\n",
            "Epoch 5/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.1112 - sparse_categorical_accuracy: 0.7192 - val_loss: 1.0744 - val_sparse_categorical_accuracy: 0.7135 - lr: 7.0000e-05\n",
            "Epoch 6/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.1121 - sparse_categorical_accuracy: 0.7207 - val_loss: 1.0731 - val_sparse_categorical_accuracy: 0.7083 - lr: 7.0000e-05\n",
            "Epoch 7/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0891 - sparse_categorical_accuracy: 0.7199 - val_loss: 1.0739 - val_sparse_categorical_accuracy: 0.7102 - lr: 7.0000e-05\n",
            "Epoch 8/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0983 - sparse_categorical_accuracy: 0.7215 - val_loss: 1.0477 - val_sparse_categorical_accuracy: 0.7161 - lr: 7.0000e-05\n",
            "Epoch 9/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0683 - sparse_categorical_accuracy: 0.7208 - val_loss: 1.0660 - val_sparse_categorical_accuracy: 0.7118 - lr: 7.0000e-05\n",
            "Epoch 10/100\n",
            "944/944 [==============================] - 3s 3ms/step - loss: 1.0703 - sparse_categorical_accuracy: 0.7205 - val_loss: 1.0536 - val_sparse_categorical_accuracy: 0.7127 - lr: 7.0000e-05\n",
            "Epoch 11/100\n",
            "944/944 [==============================] - 3s 3ms/step - loss: 1.0773 - sparse_categorical_accuracy: 0.7226 - val_loss: 1.0628 - val_sparse_categorical_accuracy: 0.7107 - lr: 7.0000e-05\n",
            "Epoch 12/100\n",
            "927/944 [============================>.] - ETA: 0s - loss: 1.0682 - sparse_categorical_accuracy: 0.7225\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.100000056088902e-05.\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0675 - sparse_categorical_accuracy: 0.7224 - val_loss: 1.0618 - val_sparse_categorical_accuracy: 0.7100 - lr: 7.0000e-05\n",
            "Epoch 13/100\n",
            "944/944 [==============================] - 3s 3ms/step - loss: 1.0455 - sparse_categorical_accuracy: 0.7231 - val_loss: 1.0467 - val_sparse_categorical_accuracy: 0.7140 - lr: 2.1000e-05\n",
            "Epoch 14/100\n",
            "944/944 [==============================] - 3s 3ms/step - loss: 1.0418 - sparse_categorical_accuracy: 0.7236 - val_loss: 1.0466 - val_sparse_categorical_accuracy: 0.7142 - lr: 2.1000e-05\n",
            "Epoch 15/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0394 - sparse_categorical_accuracy: 0.7236 - val_loss: 1.0444 - val_sparse_categorical_accuracy: 0.7145 - lr: 2.1000e-05\n",
            "Epoch 16/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0412 - sparse_categorical_accuracy: 0.7235 - val_loss: 1.0594 - val_sparse_categorical_accuracy: 0.7096 - lr: 2.1000e-05\n",
            "Epoch 17/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0399 - sparse_categorical_accuracy: 0.7242 - val_loss: 1.0449 - val_sparse_categorical_accuracy: 0.7138 - lr: 2.1000e-05\n",
            "Epoch 18/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0396 - sparse_categorical_accuracy: 0.7238 - val_loss: 1.0468 - val_sparse_categorical_accuracy: 0.7148 - lr: 2.1000e-05\n",
            "Epoch 19/100\n",
            "933/944 [============================>.] - ETA: 0s - loss: 1.0398 - sparse_categorical_accuracy: 0.7250\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 6.299999949987978e-06.\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0395 - sparse_categorical_accuracy: 0.7249 - val_loss: 1.0448 - val_sparse_categorical_accuracy: 0.7142 - lr: 2.1000e-05\n",
            "Epoch 20/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0363 - sparse_categorical_accuracy: 0.7246 - val_loss: 1.0442 - val_sparse_categorical_accuracy: 0.7139 - lr: 6.3000e-06\n",
            "Epoch 21/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0304 - sparse_categorical_accuracy: 0.7242 - val_loss: 1.0442 - val_sparse_categorical_accuracy: 0.7140 - lr: 6.3000e-06\n",
            "Epoch 22/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0319 - sparse_categorical_accuracy: 0.7243 - val_loss: 1.0475 - val_sparse_categorical_accuracy: 0.7126 - lr: 6.3000e-06\n",
            "Epoch 23/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0304 - sparse_categorical_accuracy: 0.7238 - val_loss: 1.0421 - val_sparse_categorical_accuracy: 0.7150 - lr: 6.3000e-06\n",
            "Epoch 24/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0294 - sparse_categorical_accuracy: 0.7239 - val_loss: 1.0412 - val_sparse_categorical_accuracy: 0.7152 - lr: 6.3000e-06\n",
            "Epoch 25/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0294 - sparse_categorical_accuracy: 0.7238 - val_loss: 1.0411 - val_sparse_categorical_accuracy: 0.7148 - lr: 6.3000e-06\n",
            "Epoch 26/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0300 - sparse_categorical_accuracy: 0.7245 - val_loss: 1.0419 - val_sparse_categorical_accuracy: 0.7150 - lr: 6.3000e-06\n",
            "Epoch 27/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0273 - sparse_categorical_accuracy: 0.7246 - val_loss: 1.0426 - val_sparse_categorical_accuracy: 0.7145 - lr: 6.3000e-06\n",
            "Epoch 28/100\n",
            "944/944 [==============================] - ETA: 0s - loss: 1.0266 - sparse_categorical_accuracy: 0.7243\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.8899999304267111e-06.\n",
            "944/944 [==============================] - 3s 3ms/step - loss: 1.0266 - sparse_categorical_accuracy: 0.7243 - val_loss: 1.0444 - val_sparse_categorical_accuracy: 0.7141 - lr: 6.3000e-06\n",
            "Epoch 29/100\n",
            "944/944 [==============================] - 3s 3ms/step - loss: 1.0273 - sparse_categorical_accuracy: 0.7242 - val_loss: 1.0431 - val_sparse_categorical_accuracy: 0.7145 - lr: 1.8900e-06\n",
            "Epoch 30/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0280 - sparse_categorical_accuracy: 0.7249 - val_loss: 1.0420 - val_sparse_categorical_accuracy: 0.7149 - lr: 1.8900e-06\n",
            "Epoch 31/100\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0264 - sparse_categorical_accuracy: 0.7244 - val_loss: 1.0416 - val_sparse_categorical_accuracy: 0.7149 - lr: 1.8900e-06\n",
            "Epoch 32/100\n",
            "939/944 [============================>.] - ETA: 0s - loss: 1.0259 - sparse_categorical_accuracy: 0.7255\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 5.669999723068031e-07.\n",
            "944/944 [==============================] - 3s 4ms/step - loss: 1.0259 - sparse_categorical_accuracy: 0.7254 - val_loss: 1.0414 - val_sparse_categorical_accuracy: 0.7150 - lr: 1.8900e-06\n",
            "Score for fold 1: loss of 1.0477383136749268; sparse_categorical_accuracy of 71.61080837249756%\n"
          ]
        }
      ],
      "source": [
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "fold_no = 1\n",
        "checkpoint_filepath='/tmp/checkpoint'\n",
        "# for train, test in kfold.split(X_train, y_train):\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(len(X_train.iloc[0]),)),\n",
        "    tf.keras.layers.Dense(512),\n",
        "    tf.keras.layers.Dropout(.2),\n",
        "    tf.keras.layers.Dense(256),\n",
        "    tf.keras.layers.Dropout(.2),\n",
        "    tf.keras.layers.Dense(max(y_train)+1, activation='softmax')\n",
        "])\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(7e-5), loss=loss_fn, \n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "print('------------------------------------------------------------------------')\n",
        "print(f'Training for fold {fold_no} ...')\n",
        "history = model.fit(np.array(X_train), np.array(y_train),\n",
        "                    batch_size = 128,\n",
        "                    epochs=100,\n",
        "                    use_multiprocessing=True,\n",
        "                    workers=4,\n",
        "                    validation_data=(np.array(X_test), np.array(y_test)),\n",
        "                    callbacks=[earlystop1, earlystop2,\n",
        "                                tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                                                save_best_only=True,\n",
        "                                                                save_weights_only=True,\n",
        "                                                                monitor='val_sparse_categorical_accuracy',\n",
        "                                                                mode='max')])\n",
        "model.load_weights(checkpoint_filepath)\n",
        "scores = model.evaluate(np.array(X_test), np.array(y_test), verbose=0)\n",
        "print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "acc_per_fold.append(scores[1] * 100)\n",
        "loss_per_fold.append(scores[0])\n",
        "fold_no += 1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}