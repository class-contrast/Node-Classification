{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b98e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7421ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ogb\n",
    "from ogb.nodeproppred import NodePropPredDataset \n",
    "from torch_geometric.data import DataLoader\n",
    "#H:\\\\PhD Research\\Data\\PROTEINS\\PROTEINS_node_attributes.txt\n",
    "# Download and process data at './dataset/ogbg_molhiv/'\n",
    "dataset = NodePropPredDataset(name = \"ogbn-mag\")\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "graph = dataset[0] # pyg graph object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4abfd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "D=graph[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31444687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_0</th>\n",
       "      <th>w_1</th>\n",
       "      <th>w_2</th>\n",
       "      <th>w_3</th>\n",
       "      <th>w_4</th>\n",
       "      <th>w_5</th>\n",
       "      <th>w_6</th>\n",
       "      <th>w_7</th>\n",
       "      <th>w_8</th>\n",
       "      <th>w_9</th>\n",
       "      <th>...</th>\n",
       "      <th>w_118</th>\n",
       "      <th>w_119</th>\n",
       "      <th>w_120</th>\n",
       "      <th>w_121</th>\n",
       "      <th>w_122</th>\n",
       "      <th>w_123</th>\n",
       "      <th>w_124</th>\n",
       "      <th>w_125</th>\n",
       "      <th>w_126</th>\n",
       "      <th>w_127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.095379</td>\n",
       "      <td>0.040758</td>\n",
       "      <td>-0.210948</td>\n",
       "      <td>-0.064362</td>\n",
       "      <td>-0.225940</td>\n",
       "      <td>-0.002323</td>\n",
       "      <td>-0.555826</td>\n",
       "      <td>-0.352909</td>\n",
       "      <td>0.040634</td>\n",
       "      <td>-0.195226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146386</td>\n",
       "      <td>-0.378653</td>\n",
       "      <td>-0.328871</td>\n",
       "      <td>-0.136878</td>\n",
       "      <td>-0.007779</td>\n",
       "      <td>-0.157634</td>\n",
       "      <td>-0.069693</td>\n",
       "      <td>0.061569</td>\n",
       "      <td>-0.027663</td>\n",
       "      <td>-0.133832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.151047</td>\n",
       "      <td>-0.107315</td>\n",
       "      <td>-0.221964</td>\n",
       "      <td>-0.034725</td>\n",
       "      <td>0.010814</td>\n",
       "      <td>-0.009673</td>\n",
       "      <td>-0.434323</td>\n",
       "      <td>-0.461733</td>\n",
       "      <td>0.112732</td>\n",
       "      <td>0.091751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047749</td>\n",
       "      <td>-0.065133</td>\n",
       "      <td>-0.208891</td>\n",
       "      <td>-0.366014</td>\n",
       "      <td>-0.045869</td>\n",
       "      <td>-0.297474</td>\n",
       "      <td>0.056755</td>\n",
       "      <td>0.345754</td>\n",
       "      <td>-0.027737</td>\n",
       "      <td>-0.218527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.114799</td>\n",
       "      <td>-0.175982</td>\n",
       "      <td>-0.260556</td>\n",
       "      <td>0.011920</td>\n",
       "      <td>-0.129273</td>\n",
       "      <td>-0.044518</td>\n",
       "      <td>-0.345423</td>\n",
       "      <td>-0.378261</td>\n",
       "      <td>-0.088449</td>\n",
       "      <td>-0.091060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047763</td>\n",
       "      <td>-0.394512</td>\n",
       "      <td>-0.238776</td>\n",
       "      <td>0.080928</td>\n",
       "      <td>0.057844</td>\n",
       "      <td>-0.205098</td>\n",
       "      <td>-0.067513</td>\n",
       "      <td>0.173058</td>\n",
       "      <td>-0.156445</td>\n",
       "      <td>-0.277954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004506</td>\n",
       "      <td>0.042368</td>\n",
       "      <td>-0.178465</td>\n",
       "      <td>-0.138479</td>\n",
       "      <td>-0.138268</td>\n",
       "      <td>0.024902</td>\n",
       "      <td>-0.438153</td>\n",
       "      <td>-0.450127</td>\n",
       "      <td>0.066984</td>\n",
       "      <td>-0.017753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116500</td>\n",
       "      <td>-0.255289</td>\n",
       "      <td>-0.278228</td>\n",
       "      <td>-0.081235</td>\n",
       "      <td>0.251969</td>\n",
       "      <td>-0.066206</td>\n",
       "      <td>0.095656</td>\n",
       "      <td>0.282228</td>\n",
       "      <td>0.016337</td>\n",
       "      <td>-0.212731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.094474</td>\n",
       "      <td>-0.080044</td>\n",
       "      <td>-0.222468</td>\n",
       "      <td>-0.158952</td>\n",
       "      <td>-0.024708</td>\n",
       "      <td>0.004351</td>\n",
       "      <td>-0.463666</td>\n",
       "      <td>-0.344648</td>\n",
       "      <td>-0.101808</td>\n",
       "      <td>-0.012426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117917</td>\n",
       "      <td>-0.139355</td>\n",
       "      <td>-0.228969</td>\n",
       "      <td>-0.062332</td>\n",
       "      <td>0.132850</td>\n",
       "      <td>-0.269122</td>\n",
       "      <td>0.024864</td>\n",
       "      <td>0.288779</td>\n",
       "      <td>-0.186985</td>\n",
       "      <td>-0.205087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        w_0       w_1       w_2       w_3       w_4       w_5       w_6  \\\n",
       "0 -0.095379  0.040758 -0.210948 -0.064362 -0.225940 -0.002323 -0.555826   \n",
       "1 -0.151047 -0.107315 -0.221964 -0.034725  0.010814 -0.009673 -0.434323   \n",
       "2 -0.114799 -0.175982 -0.260556  0.011920 -0.129273 -0.044518 -0.345423   \n",
       "3  0.004506  0.042368 -0.178465 -0.138479 -0.138268  0.024902 -0.438153   \n",
       "4 -0.094474 -0.080044 -0.222468 -0.158952 -0.024708  0.004351 -0.463666   \n",
       "\n",
       "        w_7       w_8       w_9  ...     w_118     w_119     w_120     w_121  \\\n",
       "0 -0.352909  0.040634 -0.195226  ...  0.146386 -0.378653 -0.328871 -0.136878   \n",
       "1 -0.461733  0.112732  0.091751  ...  0.047749 -0.065133 -0.208891 -0.366014   \n",
       "2 -0.378261 -0.088449 -0.091060  ...  0.047763 -0.394512 -0.238776  0.080928   \n",
       "3 -0.450127  0.066984 -0.017753  ...  0.116500 -0.255289 -0.278228 -0.081235   \n",
       "4 -0.344648 -0.101808 -0.012426  ... -0.117917 -0.139355 -0.228969 -0.062332   \n",
       "\n",
       "      w_122     w_123     w_124     w_125     w_126     w_127  \n",
       "0 -0.007779 -0.157634 -0.069693  0.061569 -0.027663 -0.133832  \n",
       "1 -0.045869 -0.297474  0.056755  0.345754 -0.027737 -0.218527  \n",
       "2  0.057844 -0.205098 -0.067513  0.173058 -0.156445 -0.277954  \n",
       "3  0.251969 -0.066206  0.095656  0.282228  0.016337 -0.212731  \n",
       "4  0.132850 -0.269122  0.024864  0.288779 -0.186985 -0.205087  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Class=graph[1]\n",
    "Cla=Class['paper']\n",
    "Node_Class=Cla[:,0]\n",
    "df1 = pd.DataFrame(Node_Class,columns=[\"Class\"])\n",
    "#df1.head()\n",
    "feature_names = [\"w_{}\".format(ii) for ii in range(128)]\n",
    "#print(feature_names)\n",
    "Node_Fec=list(D['node_feat_dict']['paper'])\n",
    "df2 = pd.DataFrame(Node_Fec,columns=feature_names)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b20218dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class\n",
       "0    246\n",
       "1    131\n",
       "2    189\n",
       "3    131\n",
       "4     95"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Class=graph[1]\n",
    "Cla=Class['paper']\n",
    "Node_Class=Cla[:,0]\n",
    "df1 = pd.DataFrame(Node_Class,columns=[\"Class\"])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fad51ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      0      0 ... 736388 736388 736388]\n",
      "[    88  27449 121051 ... 421711 427339 439864]\n",
      "[2010 2011 2012 2013 2014 2015 2016 2017 2018 2019]\n",
      "41939\n"
     ]
    }
   ],
   "source": [
    "Node_Year=D['node_year']['paper']\n",
    "Node_Year_list=list(Node_Year[:,0])\n",
    "\n",
    "E=D['edge_index_dict'][('paper', 'cites', 'paper')]\n",
    "EdgeL=E[0]\n",
    "EdgeR=E[1]\n",
    "print(EdgeL)\n",
    "print(EdgeR)\n",
    "print(np.unique(Node_Year_list))\n",
    "\n",
    "Node_Year_list.index(2019)\n",
    "list_size = len(Node_Year_list)\n",
    "NIndex_19=[]\n",
    "# declare for loop\n",
    "for itr in range(list_size):\n",
    " \n",
    "      # check the condition\n",
    "    if(Node_Year_list[itr] == 2019):\n",
    "        NIndex_19.append(itr)\n",
    " \n",
    "          # print the indices\n",
    "print(len(NIndex_19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1f8aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_class_train=Node_Class\n",
    "for d in NIndex_19:\n",
    "    N_class_train[d]=349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c83c6f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>691</th>\n",
       "      <th>692</th>\n",
       "      <th>693</th>\n",
       "      <th>694</th>\n",
       "      <th>695</th>\n",
       "      <th>696</th>\n",
       "      <th>697</th>\n",
       "      <th>698</th>\n",
       "      <th>699</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 702 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  0  1  2   3  4  5  6  7  8  ...  691  692  693  694  695  696  \\\n",
       "0           0  0  0  0   0  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "1           1  0  0  0   0  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "2           2  0  0  0   0  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "3           3  0  0  0   0  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "4           4  0  0  0   0  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "5           5  0  0  0   0  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "6           6  0  0  1   0  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "7           7  0  0  0   0  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "8           8  0  0  0   0  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "9           9  0  0  0  14  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "\n",
       "   697  698  699  Class  \n",
       "0    0    0    0    246  \n",
       "1    0    0    0    131  \n",
       "2    0    0    0    189  \n",
       "3    0    0    0    131  \n",
       "4    0    0    0     95  \n",
       "5    0    0    0      9  \n",
       "6    0    0    0     92  \n",
       "7    0    0    0    201  \n",
       "8    0    0    0    165  \n",
       "9    0    0    1    311  \n",
       "\n",
       "[10 rows x 702 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Feature_1it_nbd_mag.csv')\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dae7669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>w_118</th>\n",
       "      <th>w_119</th>\n",
       "      <th>w_120</th>\n",
       "      <th>w_121</th>\n",
       "      <th>w_122</th>\n",
       "      <th>w_123</th>\n",
       "      <th>w_124</th>\n",
       "      <th>w_125</th>\n",
       "      <th>w_126</th>\n",
       "      <th>w_127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146386</td>\n",
       "      <td>-0.378653</td>\n",
       "      <td>-0.328871</td>\n",
       "      <td>-0.136878</td>\n",
       "      <td>-0.007779</td>\n",
       "      <td>-0.157634</td>\n",
       "      <td>-0.069693</td>\n",
       "      <td>0.061569</td>\n",
       "      <td>-0.027663</td>\n",
       "      <td>-0.133832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047749</td>\n",
       "      <td>-0.065133</td>\n",
       "      <td>-0.208891</td>\n",
       "      <td>-0.366014</td>\n",
       "      <td>-0.045869</td>\n",
       "      <td>-0.297474</td>\n",
       "      <td>0.056755</td>\n",
       "      <td>0.345754</td>\n",
       "      <td>-0.027737</td>\n",
       "      <td>-0.218527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047763</td>\n",
       "      <td>-0.394512</td>\n",
       "      <td>-0.238776</td>\n",
       "      <td>0.080928</td>\n",
       "      <td>0.057844</td>\n",
       "      <td>-0.205098</td>\n",
       "      <td>-0.067513</td>\n",
       "      <td>0.173058</td>\n",
       "      <td>-0.156445</td>\n",
       "      <td>-0.277954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116500</td>\n",
       "      <td>-0.255289</td>\n",
       "      <td>-0.278228</td>\n",
       "      <td>-0.081235</td>\n",
       "      <td>0.251969</td>\n",
       "      <td>-0.066206</td>\n",
       "      <td>0.095656</td>\n",
       "      <td>0.282228</td>\n",
       "      <td>0.016337</td>\n",
       "      <td>-0.212731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117917</td>\n",
       "      <td>-0.139355</td>\n",
       "      <td>-0.228969</td>\n",
       "      <td>-0.062332</td>\n",
       "      <td>0.132850</td>\n",
       "      <td>-0.269122</td>\n",
       "      <td>0.024864</td>\n",
       "      <td>0.288779</td>\n",
       "      <td>-0.186985</td>\n",
       "      <td>-0.205087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 830 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  0  1  2  3  4  5  6  7  8  ...     w_118     w_119     w_120  \\\n",
       "0           0  0  0  0  0  0  0  0  0  0  ...  0.146386 -0.378653 -0.328871   \n",
       "1           1  0  0  0  0  0  0  0  0  0  ...  0.047749 -0.065133 -0.208891   \n",
       "2           2  0  0  0  0  0  0  0  0  0  ...  0.047763 -0.394512 -0.238776   \n",
       "3           3  0  0  0  0  0  0  0  0  0  ...  0.116500 -0.255289 -0.278228   \n",
       "4           4  0  0  0  0  0  0  0  0  0  ... -0.117917 -0.139355 -0.228969   \n",
       "\n",
       "      w_121     w_122     w_123     w_124     w_125     w_126     w_127  \n",
       "0 -0.136878 -0.007779 -0.157634 -0.069693  0.061569 -0.027663 -0.133832  \n",
       "1 -0.366014 -0.045869 -0.297474  0.056755  0.345754 -0.027737 -0.218527  \n",
       "2  0.080928  0.057844 -0.205098 -0.067513  0.173058 -0.156445 -0.277954  \n",
       "3 -0.081235  0.251969 -0.066206  0.095656  0.282228  0.016337 -0.212731  \n",
       "4 -0.062332  0.132850 -0.269122  0.024864  0.288779 -0.186985 -0.205087  \n",
       "\n",
       "[5 rows x 830 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=pd.concat([data, df2],axis=1)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00750efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=['0']\n",
    "for i in range(1,700):\n",
    "    feature.append(\"{}\".format(i))\n",
    "for i in range(128):\n",
    "    feature.append(\"w_{}\".format(i))\n",
    "\n",
    "X=result[feature] # Features\n",
    "y=df1['Class']  # Labels\n",
    "X_train=X.iloc[list(train_idx['paper'])+list(valid_idx['paper'])]\n",
    "X_test=X.iloc[test_idx['paper']]\n",
    "y_train=y.iloc[list(train_idx['paper'])+list(valid_idx['paper'])]\n",
    "y_test=y.iloc[test_idx['paper']]\n",
    "\n",
    "# Create train and test features as a numpy array.\n",
    "X_train = X_train[feature].to_numpy()\n",
    "X_test = X_test[feature].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9b94c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359       262\n",
       "411       311\n",
       "608        55\n",
       "873       189\n",
       "11951     346\n",
       "         ... \n",
       "736349    200\n",
       "736354    318\n",
       "736358    115\n",
       "736384    313\n",
       "736385    115\n",
       "Name: Class, Length: 41939, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38d25e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "earlystop1 = EarlyStopping(patience=7)\n",
    "earlystop2 = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               min_lr = 3e-7, \n",
    "                               patience = 4,\n",
    "                               factor=0.3,\n",
    "                               verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c474c414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/100\n",
      "5426/5426 [==============================] - 230s 42ms/step - loss: 3.9132 - sparse_categorical_accuracy: 0.2665 - val_loss: 2.6020 - val_sparse_categorical_accuracy: 0.4101\n",
      "Epoch 2/100\n",
      "5426/5426 [==============================] - 241s 44ms/step - loss: 2.5903 - sparse_categorical_accuracy: 0.4031 - val_loss: 2.5290 - val_sparse_categorical_accuracy: 0.4087\n",
      "Epoch 3/100\n",
      "5426/5426 [==============================] - 249s 46ms/step - loss: 2.4571 - sparse_categorical_accuracy: 0.4188 - val_loss: 2.4752 - val_sparse_categorical_accuracy: 0.4123\n",
      "Epoch 4/100\n",
      "5426/5426 [==============================] - 226s 42ms/step - loss: 2.3972 - sparse_categorical_accuracy: 0.4265 - val_loss: 2.4697 - val_sparse_categorical_accuracy: 0.4100\n",
      "Epoch 5/100\n",
      "5426/5426 [==============================] - 227s 42ms/step - loss: 2.3624 - sparse_categorical_accuracy: 0.4290 - val_loss: 2.4730 - val_sparse_categorical_accuracy: 0.4073\n",
      "Epoch 6/100\n",
      "5426/5426 [==============================] - 232s 43ms/step - loss: 2.3433 - sparse_categorical_accuracy: 0.4327 - val_loss: 2.4668 - val_sparse_categorical_accuracy: 0.4058\n",
      "Epoch 7/100\n",
      "5426/5426 [==============================] - 244s 45ms/step - loss: 2.3256 - sparse_categorical_accuracy: 0.4337 - val_loss: 2.4671 - val_sparse_categorical_accuracy: 0.4072\n",
      "Epoch 8/100\n",
      "5426/5426 [==============================] - 246s 45ms/step - loss: 2.3066 - sparse_categorical_accuracy: 0.4349 - val_loss: 2.4660 - val_sparse_categorical_accuracy: 0.4047\n",
      "Epoch 9/100\n",
      "5426/5426 [==============================] - 247s 45ms/step - loss: 2.2987 - sparse_categorical_accuracy: 0.4361 - val_loss: 2.4630 - val_sparse_categorical_accuracy: 0.4065\n",
      "Epoch 10/100\n",
      "5426/5426 [==============================] - 248s 46ms/step - loss: 2.2883 - sparse_categorical_accuracy: 0.4364 - val_loss: 2.4650 - val_sparse_categorical_accuracy: 0.4057\n",
      "Epoch 11/100\n",
      "5426/5426 [==============================] - 274s 51ms/step - loss: 2.2797 - sparse_categorical_accuracy: 0.4375 - val_loss: 2.4722 - val_sparse_categorical_accuracy: 0.4038\n",
      "Epoch 12/100\n",
      "5426/5426 [==============================] - 257s 47ms/step - loss: 2.2725 - sparse_categorical_accuracy: 0.4371 - val_loss: 2.4668 - val_sparse_categorical_accuracy: 0.4053\n",
      "Epoch 13/100\n",
      "5426/5426 [==============================] - 211s 39ms/step - loss: 2.2697 - sparse_categorical_accuracy: 0.4385 - val_loss: 2.4977 - val_sparse_categorical_accuracy: 0.3988\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.100000056088902e-05.\n",
      "Epoch 14/100\n",
      "5426/5426 [==============================] - 234s 43ms/step - loss: 2.2548 - sparse_categorical_accuracy: 0.4408 - val_loss: 2.4712 - val_sparse_categorical_accuracy: 0.4034\n",
      "Epoch 15/100\n",
      "5426/5426 [==============================] - 228s 42ms/step - loss: 2.2557 - sparse_categorical_accuracy: 0.4393 - val_loss: 2.4603 - val_sparse_categorical_accuracy: 0.4062\n",
      "Epoch 16/100\n",
      "5426/5426 [==============================] - 243s 45ms/step - loss: 2.2449 - sparse_categorical_accuracy: 0.4416 - val_loss: 2.4730 - val_sparse_categorical_accuracy: 0.4040\n",
      "Epoch 17/100\n",
      "5426/5426 [==============================] - 253s 47ms/step - loss: 2.2464 - sparse_categorical_accuracy: 0.4413 - val_loss: 2.4768 - val_sparse_categorical_accuracy: 0.4035\n",
      "Epoch 18/100\n",
      "5426/5426 [==============================] - 269s 50ms/step - loss: 2.2468 - sparse_categorical_accuracy: 0.4411 - val_loss: 2.4862 - val_sparse_categorical_accuracy: 0.4010\n",
      "Epoch 19/100\n",
      "5426/5426 [==============================] - 267s 49ms/step - loss: 2.2402 - sparse_categorical_accuracy: 0.4428 - val_loss: 2.4784 - val_sparse_categorical_accuracy: 0.4037\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.299999949987978e-06.\n",
      "Epoch 20/100\n",
      "5426/5426 [==============================] - 269s 50ms/step - loss: 2.2371 - sparse_categorical_accuracy: 0.4422 - val_loss: 2.4783 - val_sparse_categorical_accuracy: 0.4038\n",
      "Epoch 21/100\n",
      "5426/5426 [==============================] - 276s 51ms/step - loss: 2.2333 - sparse_categorical_accuracy: 0.4424 - val_loss: 2.4759 - val_sparse_categorical_accuracy: 0.4034\n",
      "Epoch 22/100\n",
      "5426/5426 [==============================] - 265s 49ms/step - loss: 2.2380 - sparse_categorical_accuracy: 0.4412 - val_loss: 2.4799 - val_sparse_categorical_accuracy: 0.4022\n",
      "Score for fold 1: loss of 2.4752135276794434; sparse_categorical_accuracy of 41.23131334781647%\n"
     ]
    }
   ],
   "source": [
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "checkpoint_filepath='/tmp/checkpoint'\n",
    "# for train, test in kfold.split(X_train, y_train):\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(828,)),\n",
    "    tf.keras.layers.Dense(512),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(256),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(828, activation='sigmoid')\n",
    "])\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(7e-5), loss=loss_fn, \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "print('------------------------------------------------------------------------')\n",
    "print(f'Training for fold {fold_no} ...')\n",
    "history = model.fit(np.array(X_train), np.array(y_train),\n",
    "                    batch_size = 128,\n",
    "                    epochs=100,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=4,\n",
    "                    validation_data=(np.array(X_test), np.array(y_test)),\n",
    "                    callbacks=[earlystop1, earlystop2,\n",
    "                                tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                                save_best_only=True,\n",
    "                                                                save_weights_only=True,\n",
    "                                                                monitor='val_sparse_categorical_accuracy',\n",
    "                                                                mode='max')])\n",
    "model.load_weights(checkpoint_filepath)\n",
    "scores = model.evaluate(np.array(X_test), np.array(y_test), verbose=0)\n",
    "print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "acc_per_fold.append(scores[1] * 100)\n",
    "loss_per_fold.append(scores[0])\n",
    "fold_no += 1\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99bde712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/10\n",
      "5426/5426 [==============================] - 179s 33ms/step - loss: 4.2177 - sparse_categorical_accuracy: 0.2819 - val_loss: 18.1669 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "5426/5426 [==============================] - 170s 31ms/step - loss: 2.8264 - sparse_categorical_accuracy: 0.3936 - val_loss: 19.7718 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "5426/5426 [==============================] - 175s 32ms/step - loss: 2.6899 - sparse_categorical_accuracy: 0.4105 - val_loss: 20.8038 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "5426/5426 [==============================] - 173s 32ms/step - loss: 2.6380 - sparse_categorical_accuracy: 0.4162 - val_loss: 22.1427 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "5426/5426 [==============================] - 182s 34ms/step - loss: 2.6113 - sparse_categorical_accuracy: 0.4184 - val_loss: 22.6494 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 2.100000056088902e-05.\n",
      "Epoch 6/10\n",
      "5426/5426 [==============================] - 186s 34ms/step - loss: 2.5932 - sparse_categorical_accuracy: 0.4200 - val_loss: 23.0553 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "5426/5426 [==============================] - 190s 35ms/step - loss: 2.5802 - sparse_categorical_accuracy: 0.4217 - val_loss: 23.0316 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "5426/5426 [==============================] - 193s 36ms/step - loss: 2.5727 - sparse_categorical_accuracy: 0.4218 - val_loss: 23.1411 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Score for fold 1: loss of 18.166915893554688; sparse_categorical_accuracy of 0.0%\n"
     ]
    }
   ],
   "source": [
    "feature=['0']\n",
    "for i in range(1,700):\n",
    "    feature.append(\"{}\".format(i))\n",
    "#for i in range(128):\n",
    "#    feature.append(\"w_{}\".format(i))\n",
    "\n",
    "X=result[feature] # Features\n",
    "y=df1['Class']  # Labels\n",
    "X_train=X.iloc[list(train_idx['paper'])+list(valid_idx['paper'])]\n",
    "X_test=X.iloc[test_idx['paper']]\n",
    "y_train=y.iloc[list(train_idx['paper'])+list(valid_idx['paper'])]\n",
    "y_test=y.iloc[test_idx['paper']]\n",
    "\n",
    "# Create train and test features as a numpy array.\n",
    "X_train = X_train[feature].to_numpy()\n",
    "X_test = X_test[feature].to_numpy()\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "checkpoint_filepath='/tmp/checkpoint'\n",
    "# for train, test in kfold.split(X_train, y_train):\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(700,)),\n",
    "    tf.keras.layers.Dense(512),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(256),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(828, activation='sigmoid')\n",
    "])\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(7e-5), loss=loss_fn, \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "print('------------------------------------------------------------------------')\n",
    "print(f'Training for fold {fold_no} ...')\n",
    "history = model.fit(np.array(X_train), np.array(y_train),\n",
    "                    batch_size = 128,\n",
    "                    epochs=10,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=4,\n",
    "                    validation_data=(np.array(X_test), np.array(y_test)),\n",
    "                    callbacks=[earlystop1,earlystop2,\n",
    "                                tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                                save_best_only=True,\n",
    "                                                                save_weights_only=True,\n",
    "                                                                monitor='val_sparse_categorical_accuracy',\n",
    "                                                                mode='max')])\n",
    "model.load_weights(checkpoint_filepath)\n",
    "scores = model.evaluate(np.array(X_test), np.array(y_test), verbose=0)\n",
    "print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "acc_per_fold.append(scores[1] * 100)\n",
    "loss_per_fold.append(scores[0])\n",
    "fold_no += 1\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "556e439f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([262, 311,  55, ..., 115, 313, 115])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45f3faa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311/1311 [==============================] - 7s 5ms/step - loss: 2.8110 - sparse_categorical_accuracy: 0.3957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.8109548091888428, 0.3956699073314667]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature=['0']\n",
    "for i in range(1,700):\n",
    "    feature.append(\"{}\".format(i))\n",
    "#for i in range(128):\n",
    "#    feature.append(\"w_{}\".format(i))\n",
    "\n",
    "X=result[feature] # Features\n",
    "y=df1['Class']  # Labels\n",
    "X_train=X.iloc[list(train_idx['paper'])+list(valid_idx['paper'])]\n",
    "X_test=X.iloc[test_idx['paper']]\n",
    "y_train=y.iloc[list(train_idx['paper'])+list(valid_idx['paper'])]\n",
    "y_test=y.iloc[test_idx['paper']]\n",
    "X_test=X.iloc[test_idx['paper']].to_numpy()\n",
    "scores = model.evaluate(np.array(X_test), np.array(y_test), verbose=1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b5bd325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/10\n",
      "5426/5426 [==============================] - 159s 29ms/step - loss: 4.5026 - sparse_categorical_accuracy: 0.1280 - val_loss: 3.3491 - val_sparse_categorical_accuracy: 0.2367\n",
      "Epoch 2/10\n",
      "5426/5426 [==============================] - 151s 28ms/step - loss: 3.4989 - sparse_categorical_accuracy: 0.2075 - val_loss: 3.2132 - val_sparse_categorical_accuracy: 0.2498\n",
      "Epoch 3/10\n",
      "5426/5426 [==============================] - 168s 31ms/step - loss: 3.3759 - sparse_categorical_accuracy: 0.2218 - val_loss: 3.1637 - val_sparse_categorical_accuracy: 0.2543\n",
      "Epoch 4/10\n",
      "5426/5426 [==============================] - 159s 29ms/step - loss: 3.3193 - sparse_categorical_accuracy: 0.2268 - val_loss: 3.1363 - val_sparse_categorical_accuracy: 0.2558\n",
      "Epoch 5/10\n",
      "5426/5426 [==============================] - 174s 32ms/step - loss: 3.2865 - sparse_categorical_accuracy: 0.2306 - val_loss: 3.1161 - val_sparse_categorical_accuracy: 0.2560\n",
      "Epoch 6/10\n",
      "5426/5426 [==============================] - 169s 31ms/step - loss: 3.2602 - sparse_categorical_accuracy: 0.2342 - val_loss: 3.0952 - val_sparse_categorical_accuracy: 0.2641\n",
      "Epoch 7/10\n",
      "5426/5426 [==============================] - 155s 29ms/step - loss: 3.2474 - sparse_categorical_accuracy: 0.2354 - val_loss: 3.0963 - val_sparse_categorical_accuracy: 0.2627\n",
      "Epoch 8/10\n",
      "5426/5426 [==============================] - 160s 29ms/step - loss: 3.2343 - sparse_categorical_accuracy: 0.2365 - val_loss: 3.0883 - val_sparse_categorical_accuracy: 0.2615\n",
      "Epoch 9/10\n",
      "5426/5426 [==============================] - 169s 31ms/step - loss: 3.2238 - sparse_categorical_accuracy: 0.2379 - val_loss: 3.0907 - val_sparse_categorical_accuracy: 0.2554\n",
      "Epoch 10/10\n",
      "5426/5426 [==============================] - 179s 33ms/step - loss: 3.2118 - sparse_categorical_accuracy: 0.2400 - val_loss: 3.0786 - val_sparse_categorical_accuracy: 0.2591\n",
      "Score for fold 1: loss of 3.0952088832855225; sparse_categorical_accuracy of 26.40978693962097%\n"
     ]
    }
   ],
   "source": [
    "feature=[]\n",
    "#for i in range(1,700):\n",
    "#    feature.append(\"{}\".format(i))\n",
    "for i in range(128):\n",
    "    feature.append(\"w_{}\".format(i))\n",
    "\n",
    "X=result[feature] # Features\n",
    "y=df1['Class']  # Labels\n",
    "X_train=X.iloc[list(train_idx['paper'])+list(valid_idx['paper'])]\n",
    "X_test=X.iloc[test_idx['paper']]\n",
    "y_train=y.iloc[list(train_idx['paper'])+list(valid_idx['paper'])]\n",
    "y_test=y.iloc[test_idx['paper']]\n",
    "\n",
    "# Create train and test features as a numpy array.\n",
    "X_train = X_train[feature].to_numpy()\n",
    "X_test = X_test[feature].to_numpy()\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "checkpoint_filepath='/tmp/checkpoint'\n",
    "# for train, test in kfold.split(X_train, y_train):\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(128,)),\n",
    "    tf.keras.layers.Dense(512),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(256),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(828, activation='sigmoid')\n",
    "])\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(7e-5), loss=loss_fn, \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "print('------------------------------------------------------------------------')\n",
    "print(f'Training for fold {fold_no} ...')\n",
    "history = model.fit(np.array(X_train), np.array(y_train),\n",
    "                    batch_size = 128,\n",
    "                    epochs=10,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=4,\n",
    "                    validation_data=(np.array(X_test), np.array(y_test)),\n",
    "                    callbacks=[earlystop1,earlystop2,\n",
    "                                tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                                save_best_only=True,\n",
    "                                                                save_weights_only=True,\n",
    "                                                                monitor='val_sparse_categorical_accuracy',\n",
    "                                                                mode='max')])\n",
    "model.load_weights(checkpoint_filepath)\n",
    "scores = model.evaluate(np.array(X_test), np.array(y_test), verbose=0)\n",
    "print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "acc_per_fold.append(scores[1] * 100)\n",
    "loss_per_fold.append(scores[0])\n",
    "fold_no += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd225257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcypher/anaconda3/envs/tfflow/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 29.716969884832732 %\n"
     ]
    }
   ],
   "source": [
    "feature=['0']\n",
    "for i in range(1,700):\n",
    "    feature.append(\"{}\".format(i))\n",
    "for i in range(128):\n",
    "    feature.append(\"w_{}\".format(i))\n",
    "\n",
    "X=result[feature] # Features\n",
    "y=df1['Class']  # Labels\n",
    "X_train=X.iloc[list(train_idx['paper'])+list(valid_idx['paper'])]\n",
    "X_test=X.iloc[test_idx['paper']]\n",
    "y_train=y.iloc[list(train_idx['paper'])+list(valid_idx['paper'])]\n",
    "y_test=y.iloc[test_idx['paper']]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)  \n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_test)  \n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-6, hidden_layer_sizes=(1000,),activation='relu', learning_rate='constant', learning_rate_init=0.001, random_state=1, max_iter=600, warm_start=True)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b9650c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/100\n",
      "5426/5426 [==============================] - 257s 47ms/step - loss: 3.8617 - sparse_categorical_accuracy: 0.2936 - val_loss: 2.6970 - val_sparse_categorical_accuracy: 0.3953\n",
      "Epoch 2/100\n",
      "5426/5426 [==============================] - 243s 45ms/step - loss: 2.5276 - sparse_categorical_accuracy: 0.4079 - val_loss: 2.5861 - val_sparse_categorical_accuracy: 0.3964\n",
      "Epoch 3/100\n",
      "5426/5426 [==============================] - 243s 45ms/step - loss: 2.4238 - sparse_categorical_accuracy: 0.4185 - val_loss: 2.5628 - val_sparse_categorical_accuracy: 0.3944\n",
      "Epoch 4/100\n",
      "5426/5426 [==============================] - 250s 46ms/step - loss: 2.3753 - sparse_categorical_accuracy: 0.4231 - val_loss: 2.5713 - val_sparse_categorical_accuracy: 0.3971\n",
      "Epoch 5/100\n",
      "5426/5426 [==============================] - 245s 45ms/step - loss: 2.3361 - sparse_categorical_accuracy: 0.4284 - val_loss: 2.5535 - val_sparse_categorical_accuracy: 0.3933\n",
      "Epoch 6/100\n",
      "5426/5426 [==============================] - 262s 48ms/step - loss: 2.3146 - sparse_categorical_accuracy: 0.4309 - val_loss: 2.5285 - val_sparse_categorical_accuracy: 0.3990\n",
      "Epoch 7/100\n",
      "5426/5426 [==============================] - 263s 48ms/step - loss: 2.3007 - sparse_categorical_accuracy: 0.4330 - val_loss: 2.5324 - val_sparse_categorical_accuracy: 0.3954\n",
      "Epoch 8/100\n",
      "5426/5426 [==============================] - 255s 47ms/step - loss: 2.2883 - sparse_categorical_accuracy: 0.4342 - val_loss: 2.5322 - val_sparse_categorical_accuracy: 0.4001\n",
      "Epoch 9/100\n",
      "5426/5426 [==============================] - 268s 49ms/step - loss: 2.2806 - sparse_categorical_accuracy: 0.4344 - val_loss: 2.5240 - val_sparse_categorical_accuracy: 0.3992\n",
      "Epoch 10/100\n",
      "5426/5426 [==============================] - 213s 39ms/step - loss: 2.2698 - sparse_categorical_accuracy: 0.4368 - val_loss: 2.5376 - val_sparse_categorical_accuracy: 0.3987\n",
      "Epoch 11/100\n",
      "5426/5426 [==============================] - 183s 34ms/step - loss: 2.2637 - sparse_categorical_accuracy: 0.4355 - val_loss: 2.5261 - val_sparse_categorical_accuracy: 0.3993\n",
      "Epoch 12/100\n",
      "5426/5426 [==============================] - 179s 33ms/step - loss: 2.2512 - sparse_categorical_accuracy: 0.4373 - val_loss: 2.5600 - val_sparse_categorical_accuracy: 0.3981\n",
      "Epoch 13/100\n",
      "5426/5426 [==============================] - 169s 31ms/step - loss: 2.2560 - sparse_categorical_accuracy: 0.4365 - val_loss: 2.5510 - val_sparse_categorical_accuracy: 0.3989\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.100000056088902e-05.\n",
      "Epoch 14/100\n",
      "5426/5426 [==============================] - 188s 35ms/step - loss: 2.2338 - sparse_categorical_accuracy: 0.4416 - val_loss: 2.5297 - val_sparse_categorical_accuracy: 0.3984\n",
      "Epoch 15/100\n",
      "5426/5426 [==============================] - 181s 33ms/step - loss: 2.2253 - sparse_categorical_accuracy: 0.4410 - val_loss: 2.5338 - val_sparse_categorical_accuracy: 0.3980\n",
      "Epoch 16/100\n",
      "5426/5426 [==============================] - 187s 35ms/step - loss: 2.2225 - sparse_categorical_accuracy: 0.4419 - val_loss: 2.5372 - val_sparse_categorical_accuracy: 0.3959\n",
      "Epoch 17/100\n",
      "5426/5426 [==============================] - 176s 32ms/step - loss: 2.2229 - sparse_categorical_accuracy: 0.4419 - val_loss: 2.5268 - val_sparse_categorical_accuracy: 0.3996\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.299999949987978e-06.\n",
      "Epoch 18/100\n",
      "5426/5426 [==============================] - 189s 35ms/step - loss: 2.2121 - sparse_categorical_accuracy: 0.4434 - val_loss: 2.5289 - val_sparse_categorical_accuracy: 0.3983\n",
      "Epoch 19/100\n",
      "5426/5426 [==============================] - 177s 33ms/step - loss: 2.2155 - sparse_categorical_accuracy: 0.4419 - val_loss: 2.5288 - val_sparse_categorical_accuracy: 0.3985\n",
      "Epoch 20/100\n",
      "5426/5426 [==============================] - 189s 35ms/step - loss: 2.2161 - sparse_categorical_accuracy: 0.4424 - val_loss: 2.5239 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 21/100\n",
      "5426/5426 [==============================] - 182s 34ms/step - loss: 2.2135 - sparse_categorical_accuracy: 0.4430 - val_loss: 2.5264 - val_sparse_categorical_accuracy: 0.3988\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.8899999304267111e-06.\n",
      "Epoch 22/100\n",
      "5426/5426 [==============================] - 184s 34ms/step - loss: 2.2152 - sparse_categorical_accuracy: 0.4430 - val_loss: 2.5263 - val_sparse_categorical_accuracy: 0.3994\n",
      "Epoch 23/100\n",
      "5426/5426 [==============================] - 182s 33ms/step - loss: 2.2132 - sparse_categorical_accuracy: 0.4425 - val_loss: 2.5264 - val_sparse_categorical_accuracy: 0.3993\n",
      "Epoch 24/100\n",
      "5426/5426 [==============================] - 174s 32ms/step - loss: 2.2179 - sparse_categorical_accuracy: 0.4419 - val_loss: 2.5271 - val_sparse_categorical_accuracy: 0.3995\n",
      "Epoch 25/100\n",
      "5426/5426 [==============================] - 173s 32ms/step - loss: 2.2097 - sparse_categorical_accuracy: 0.4428 - val_loss: 2.5249 - val_sparse_categorical_accuracy: 0.3998\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 5.669999723068031e-07.\n",
      "Epoch 26/100\n",
      "5426/5426 [==============================] - 183s 34ms/step - loss: 2.2107 - sparse_categorical_accuracy: 0.4432 - val_loss: 2.5258 - val_sparse_categorical_accuracy: 0.3997\n",
      "Epoch 27/100\n",
      "5426/5426 [==============================] - 170s 31ms/step - loss: 2.2145 - sparse_categorical_accuracy: 0.4433 - val_loss: 2.5263 - val_sparse_categorical_accuracy: 0.3997\n",
      "Epoch 28/100\n",
      "5426/5426 [==============================] - 170s 31ms/step - loss: 2.2094 - sparse_categorical_accuracy: 0.4434 - val_loss: 2.5261 - val_sparse_categorical_accuracy: 0.3999\n",
      "Epoch 29/100\n",
      "5426/5426 [==============================] - 174s 32ms/step - loss: 2.2082 - sparse_categorical_accuracy: 0.4441 - val_loss: 2.5264 - val_sparse_categorical_accuracy: 0.3995\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 3e-07.\n",
      "Epoch 30/100\n",
      "5426/5426 [==============================] - 261s 48ms/step - loss: 2.2117 - sparse_categorical_accuracy: 0.4428 - val_loss: 2.5267 - val_sparse_categorical_accuracy: 0.3996\n",
      "Epoch 31/100\n",
      "5426/5426 [==============================] - 273s 50ms/step - loss: 2.2130 - sparse_categorical_accuracy: 0.4445 - val_loss: 2.5269 - val_sparse_categorical_accuracy: 0.3996\n",
      "Epoch 32/100\n",
      "5426/5426 [==============================] - 275s 51ms/step - loss: 2.2124 - sparse_categorical_accuracy: 0.4426 - val_loss: 2.5269 - val_sparse_categorical_accuracy: 0.3995\n",
      "Epoch 33/100\n",
      "5426/5426 [==============================] - 265s 49ms/step - loss: 2.2126 - sparse_categorical_accuracy: 0.4434 - val_loss: 2.5269 - val_sparse_categorical_accuracy: 0.3995\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 3e-07.\n",
      "Epoch 34/100\n",
      "5426/5426 [==============================] - 276s 51ms/step - loss: 2.2092 - sparse_categorical_accuracy: 0.4433 - val_loss: 2.5268 - val_sparse_categorical_accuracy: 0.3994\n",
      "Epoch 35/100\n",
      "5426/5426 [==============================] - 264s 49ms/step - loss: 2.2061 - sparse_categorical_accuracy: 0.4442 - val_loss: 2.5270 - val_sparse_categorical_accuracy: 0.3994\n",
      "Epoch 36/100\n",
      "5426/5426 [==============================] - 272s 50ms/step - loss: 2.2077 - sparse_categorical_accuracy: 0.4442 - val_loss: 2.5270 - val_sparse_categorical_accuracy: 0.3995\n",
      "Epoch 37/100\n",
      "5426/5426 [==============================] - 279s 51ms/step - loss: 2.2062 - sparse_categorical_accuracy: 0.4440 - val_loss: 2.5273 - val_sparse_categorical_accuracy: 0.3993\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 3e-07.\n",
      "Epoch 38/100\n",
      "5426/5426 [==============================] - 276s 51ms/step - loss: 2.2098 - sparse_categorical_accuracy: 0.4434 - val_loss: 2.5272 - val_sparse_categorical_accuracy: 0.3993\n",
      "Epoch 39/100\n",
      "5426/5426 [==============================] - 274s 51ms/step - loss: 2.2131 - sparse_categorical_accuracy: 0.4425 - val_loss: 2.5272 - val_sparse_categorical_accuracy: 0.3992\n",
      "Epoch 40/100\n",
      "5426/5426 [==============================] - 286s 53ms/step - loss: 2.2079 - sparse_categorical_accuracy: 0.4440 - val_loss: 2.5271 - val_sparse_categorical_accuracy: 0.3993\n",
      "Epoch 41/100\n",
      "5426/5426 [==============================] - 181s 33ms/step - loss: 2.2078 - sparse_categorical_accuracy: 0.4451 - val_loss: 2.5270 - val_sparse_categorical_accuracy: 0.3995\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 3e-07.\n",
      "Epoch 42/100\n",
      "5426/5426 [==============================] - 179s 33ms/step - loss: 2.2130 - sparse_categorical_accuracy: 0.4429 - val_loss: 2.5267 - val_sparse_categorical_accuracy: 0.3995\n",
      "Epoch 43/100\n",
      "5426/5426 [==============================] - 163s 30ms/step - loss: 2.2111 - sparse_categorical_accuracy: 0.4427 - val_loss: 2.5266 - val_sparse_categorical_accuracy: 0.3996\n",
      "Epoch 44/100\n",
      "5426/5426 [==============================] - 174s 32ms/step - loss: 2.2091 - sparse_categorical_accuracy: 0.4436 - val_loss: 2.5269 - val_sparse_categorical_accuracy: 0.3993\n",
      "Epoch 45/100\n",
      "5426/5426 [==============================] - 168s 31ms/step - loss: 2.2054 - sparse_categorical_accuracy: 0.4444 - val_loss: 2.5268 - val_sparse_categorical_accuracy: 0.3992\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 3e-07.\n",
      "Epoch 46/100\n",
      "5426/5426 [==============================] - 165s 30ms/step - loss: 2.2115 - sparse_categorical_accuracy: 0.4435 - val_loss: 2.5268 - val_sparse_categorical_accuracy: 0.3992\n",
      "Epoch 47/100\n",
      "5426/5426 [==============================] - 173s 32ms/step - loss: 2.2057 - sparse_categorical_accuracy: 0.4443 - val_loss: 2.5268 - val_sparse_categorical_accuracy: 0.3993\n",
      "Epoch 48/100\n",
      "5426/5426 [==============================] - 167s 31ms/step - loss: 2.2070 - sparse_categorical_accuracy: 0.4438 - val_loss: 2.5269 - val_sparse_categorical_accuracy: 0.3993\n",
      "Epoch 49/100\n",
      "5426/5426 [==============================] - 156s 29ms/step - loss: 2.2082 - sparse_categorical_accuracy: 0.4437 - val_loss: 2.5271 - val_sparse_categorical_accuracy: 0.3992\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 3e-07.\n",
      "Epoch 50/100\n",
      "5426/5426 [==============================] - 156s 29ms/step - loss: 2.2079 - sparse_categorical_accuracy: 0.4439 - val_loss: 2.5271 - val_sparse_categorical_accuracy: 0.3993\n",
      "Epoch 51/100\n",
      "5426/5426 [==============================] - 164s 30ms/step - loss: 2.2095 - sparse_categorical_accuracy: 0.4428 - val_loss: 2.5273 - val_sparse_categorical_accuracy: 0.3994\n",
      "Epoch 52/100\n",
      "5426/5426 [==============================] - 177s 33ms/step - loss: 2.2075 - sparse_categorical_accuracy: 0.4443 - val_loss: 2.5274 - val_sparse_categorical_accuracy: 0.3994\n",
      "Epoch 53/100\n",
      "5426/5426 [==============================] - 169s 31ms/step - loss: 2.2104 - sparse_categorical_accuracy: 0.4434 - val_loss: 2.5270 - val_sparse_categorical_accuracy: 0.3993\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 3e-07.\n",
      "Epoch 54/100\n",
      "5426/5426 [==============================] - 174s 32ms/step - loss: 2.2082 - sparse_categorical_accuracy: 0.4435 - val_loss: 2.5270 - val_sparse_categorical_accuracy: 0.3993\n",
      "Epoch 55/100\n",
      "5426/5426 [==============================] - 172s 32ms/step - loss: 2.2104 - sparse_categorical_accuracy: 0.4438 - val_loss: 2.5272 - val_sparse_categorical_accuracy: 0.3991\n",
      "Epoch 56/100\n",
      "5426/5426 [==============================] - 180s 33ms/step - loss: 2.2113 - sparse_categorical_accuracy: 0.4422 - val_loss: 2.5273 - val_sparse_categorical_accuracy: 0.3992\n",
      "Epoch 57/100\n",
      "5426/5426 [==============================] - 214s 39ms/step - loss: 2.2156 - sparse_categorical_accuracy: 0.4427 - val_loss: 2.5274 - val_sparse_categorical_accuracy: 0.3992\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 3e-07.\n",
      "Epoch 58/100\n",
      "5426/5426 [==============================] - 250s 46ms/step - loss: 2.2080 - sparse_categorical_accuracy: 0.4434 - val_loss: 2.5277 - val_sparse_categorical_accuracy: 0.3991\n",
      "Epoch 59/100\n",
      "5426/5426 [==============================] - 263s 48ms/step - loss: 2.2107 - sparse_categorical_accuracy: 0.4442 - val_loss: 2.5278 - val_sparse_categorical_accuracy: 0.3991\n",
      "Epoch 60/100\n",
      "5426/5426 [==============================] - 273s 50ms/step - loss: 2.2128 - sparse_categorical_accuracy: 0.4433 - val_loss: 2.5278 - val_sparse_categorical_accuracy: 0.3991\n",
      "Epoch 61/100\n",
      "5426/5426 [==============================] - 277s 51ms/step - loss: 2.2088 - sparse_categorical_accuracy: 0.4435 - val_loss: 2.5275 - val_sparse_categorical_accuracy: 0.3992\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 3e-07.\n",
      "Epoch 62/100\n",
      "5426/5426 [==============================] - 270s 50ms/step - loss: 2.2127 - sparse_categorical_accuracy: 0.4431 - val_loss: 2.5275 - val_sparse_categorical_accuracy: 0.3992\n",
      "Epoch 63/100\n",
      "5426/5426 [==============================] - 277s 51ms/step - loss: 2.2066 - sparse_categorical_accuracy: 0.4436 - val_loss: 2.5273 - val_sparse_categorical_accuracy: 0.3993\n",
      "Epoch 64/100\n",
      "5426/5426 [==============================] - 267s 49ms/step - loss: 2.2093 - sparse_categorical_accuracy: 0.4426 - val_loss: 2.5273 - val_sparse_categorical_accuracy: 0.3993\n",
      "Epoch 65/100\n",
      "5426/5426 [==============================] - 277s 51ms/step - loss: 2.2097 - sparse_categorical_accuracy: 0.4438 - val_loss: 2.5272 - val_sparse_categorical_accuracy: 0.3994\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 3e-07.\n",
      "Epoch 66/100\n",
      "5426/5426 [==============================] - 254s 47ms/step - loss: 2.2077 - sparse_categorical_accuracy: 0.4435 - val_loss: 2.5273 - val_sparse_categorical_accuracy: 0.3993\n",
      "Epoch 67/100\n",
      "5426/5426 [==============================] - 267s 49ms/step - loss: 2.2083 - sparse_categorical_accuracy: 0.4435 - val_loss: 2.5271 - val_sparse_categorical_accuracy: 0.3991\n",
      "Epoch 68/100\n",
      "5426/5426 [==============================] - 264s 49ms/step - loss: 2.2064 - sparse_categorical_accuracy: 0.4443 - val_loss: 2.5271 - val_sparse_categorical_accuracy: 0.3992\n",
      "Epoch 69/100\n",
      "5426/5426 [==============================] - 265s 49ms/step - loss: 2.2062 - sparse_categorical_accuracy: 0.4435 - val_loss: 2.5271 - val_sparse_categorical_accuracy: 0.3991\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 3e-07.\n",
      "Epoch 70/100\n",
      "5426/5426 [==============================] - 253s 47ms/step - loss: 2.2059 - sparse_categorical_accuracy: 0.4440 - val_loss: 2.5272 - val_sparse_categorical_accuracy: 0.3992\n",
      "Epoch 71/100\n",
      "5426/5426 [==============================] - 267s 49ms/step - loss: 2.2140 - sparse_categorical_accuracy: 0.4424 - val_loss: 2.5271 - val_sparse_categorical_accuracy: 0.3992\n",
      "Epoch 72/100\n",
      "5426/5426 [==============================] - 264s 49ms/step - loss: 2.2096 - sparse_categorical_accuracy: 0.4437 - val_loss: 2.5271 - val_sparse_categorical_accuracy: 0.3991\n",
      "Epoch 73/100\n",
      "5426/5426 [==============================] - 273s 50ms/step - loss: 2.2117 - sparse_categorical_accuracy: 0.4429 - val_loss: 2.5272 - val_sparse_categorical_accuracy: 0.3990\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 3e-07.\n",
      "Epoch 74/100\n",
      "5426/5426 [==============================] - 275s 51ms/step - loss: 2.2049 - sparse_categorical_accuracy: 0.4445 - val_loss: 2.5273 - val_sparse_categorical_accuracy: 0.3990\n",
      "Epoch 75/100\n",
      "5426/5426 [==============================] - 267s 49ms/step - loss: 2.2036 - sparse_categorical_accuracy: 0.4450 - val_loss: 2.5271 - val_sparse_categorical_accuracy: 0.3989\n",
      "Epoch 76/100\n",
      "5426/5426 [==============================] - 269s 50ms/step - loss: 2.2025 - sparse_categorical_accuracy: 0.4438 - val_loss: 2.5274 - val_sparse_categorical_accuracy: 0.3991\n",
      "Epoch 77/100\n",
      "5426/5426 [==============================] - 258s 48ms/step - loss: 2.2071 - sparse_categorical_accuracy: 0.4437 - val_loss: 2.5272 - val_sparse_categorical_accuracy: 0.3990\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 3e-07.\n",
      "Epoch 78/100\n",
      "5426/5426 [==============================] - 270s 50ms/step - loss: 2.2075 - sparse_categorical_accuracy: 0.4438 - val_loss: 2.5271 - val_sparse_categorical_accuracy: 0.3990\n",
      "Epoch 79/100\n",
      "5426/5426 [==============================] - 269s 50ms/step - loss: 2.2070 - sparse_categorical_accuracy: 0.4436 - val_loss: 2.5274 - val_sparse_categorical_accuracy: 0.3988\n",
      "Epoch 80/100\n",
      "5426/5426 [==============================] - 262s 48ms/step - loss: 2.2082 - sparse_categorical_accuracy: 0.4443 - val_loss: 2.5274 - val_sparse_categorical_accuracy: 0.3989\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5426/5426 [==============================] - 167s 31ms/step - loss: 2.2119 - sparse_categorical_accuracy: 0.4431 - val_loss: 2.5274 - val_sparse_categorical_accuracy: 0.3990\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 3e-07.\n",
      "Epoch 82/100\n",
      "5426/5426 [==============================] - 176s 32ms/step - loss: 2.2058 - sparse_categorical_accuracy: 0.4446 - val_loss: 2.5274 - val_sparse_categorical_accuracy: 0.3992\n",
      "Epoch 83/100\n",
      "5426/5426 [==============================] - 171s 32ms/step - loss: 2.2107 - sparse_categorical_accuracy: 0.4433 - val_loss: 2.5274 - val_sparse_categorical_accuracy: 0.3989\n",
      "Epoch 84/100\n",
      "5426/5426 [==============================] - 165s 30ms/step - loss: 2.2066 - sparse_categorical_accuracy: 0.4447 - val_loss: 2.5272 - val_sparse_categorical_accuracy: 0.3991\n",
      "Epoch 85/100\n",
      "5426/5426 [==============================] - 166s 31ms/step - loss: 2.2131 - sparse_categorical_accuracy: 0.4430 - val_loss: 2.5272 - val_sparse_categorical_accuracy: 0.3991\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 3e-07.\n",
      "Epoch 86/100\n",
      "5426/5426 [==============================] - 166s 31ms/step - loss: 2.2072 - sparse_categorical_accuracy: 0.4433 - val_loss: 2.5271 - val_sparse_categorical_accuracy: 0.3991\n",
      "Epoch 87/100\n",
      "5426/5426 [==============================] - 176s 33ms/step - loss: 2.2036 - sparse_categorical_accuracy: 0.4448 - val_loss: 2.5269 - val_sparse_categorical_accuracy: 0.3992\n",
      "Epoch 88/100\n",
      "5426/5426 [==============================] - 245s 45ms/step - loss: 2.2096 - sparse_categorical_accuracy: 0.4433 - val_loss: 2.5273 - val_sparse_categorical_accuracy: 0.3990\n",
      "Epoch 89/100\n",
      "5426/5426 [==============================] - 252s 46ms/step - loss: 2.2104 - sparse_categorical_accuracy: 0.4437 - val_loss: 2.5275 - val_sparse_categorical_accuracy: 0.3991\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 3e-07.\n",
      "Epoch 90/100\n",
      "5426/5426 [==============================] - 240s 44ms/step - loss: 2.2080 - sparse_categorical_accuracy: 0.4438 - val_loss: 2.5278 - val_sparse_categorical_accuracy: 0.3989\n",
      "Epoch 91/100\n",
      "5426/5426 [==============================] - 177s 33ms/step - loss: 2.2095 - sparse_categorical_accuracy: 0.4438 - val_loss: 2.5280 - val_sparse_categorical_accuracy: 0.3989\n",
      "Epoch 92/100\n",
      "5426/5426 [==============================] - 169s 31ms/step - loss: 2.2116 - sparse_categorical_accuracy: 0.4427 - val_loss: 2.5281 - val_sparse_categorical_accuracy: 0.3989\n",
      "Epoch 93/100\n",
      "5426/5426 [==============================] - 178s 33ms/step - loss: 2.2061 - sparse_categorical_accuracy: 0.4435 - val_loss: 2.5276 - val_sparse_categorical_accuracy: 0.3992\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 3e-07.\n",
      "Epoch 94/100\n",
      "5426/5426 [==============================] - 175s 32ms/step - loss: 2.2100 - sparse_categorical_accuracy: 0.4435 - val_loss: 2.5276 - val_sparse_categorical_accuracy: 0.3990\n",
      "Epoch 95/100\n",
      "5426/5426 [==============================] - 181s 33ms/step - loss: 2.2082 - sparse_categorical_accuracy: 0.4440 - val_loss: 2.5277 - val_sparse_categorical_accuracy: 0.3991\n",
      "Epoch 96/100\n",
      "5426/5426 [==============================] - 176s 32ms/step - loss: 2.2072 - sparse_categorical_accuracy: 0.4445 - val_loss: 2.5279 - val_sparse_categorical_accuracy: 0.3991\n",
      "Epoch 97/100\n",
      "5426/5426 [==============================] - 182s 33ms/step - loss: 2.2123 - sparse_categorical_accuracy: 0.4428 - val_loss: 2.5279 - val_sparse_categorical_accuracy: 0.3990\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 3e-07.\n",
      "Epoch 98/100\n",
      "5426/5426 [==============================] - 188s 35ms/step - loss: 2.2078 - sparse_categorical_accuracy: 0.4428 - val_loss: 2.5279 - val_sparse_categorical_accuracy: 0.3991\n",
      "Epoch 99/100\n",
      "5426/5426 [==============================] - 195s 36ms/step - loss: 2.2098 - sparse_categorical_accuracy: 0.4433 - val_loss: 2.5280 - val_sparse_categorical_accuracy: 0.3990\n",
      "Epoch 100/100\n",
      "5426/5426 [==============================] - 268s 49ms/step - loss: 2.2089 - sparse_categorical_accuracy: 0.4432 - val_loss: 2.5282 - val_sparse_categorical_accuracy: 0.3989\n",
      "Score for fold 1: loss of 2.5321521759033203; sparse_categorical_accuracy of 40.005722641944885%\n"
     ]
    }
   ],
   "source": [
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "checkpoint_filepath='/tmp/checkpoint'\n",
    "# for train, test in kfold.split(X_train, y_train):\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(828,)),\n",
    "    tf.keras.layers.Dense(512),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(256),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(828, activation='sigmoid')\n",
    "])\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(7e-5), loss=loss_fn, \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "print('------------------------------------------------------------------------')\n",
    "print(f'Training for fold {fold_no} ...')\n",
    "history = model.fit(np.array(X_train), np.array(y_train),\n",
    "                    batch_size = 128,\n",
    "                    epochs=100,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=4,\n",
    "                    validation_data=(np.array(X_test), np.array(y_test)),\n",
    "                    callbacks=[earlystop2,\n",
    "                                tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                                save_best_only=True,\n",
    "                                                                save_weights_only=True,\n",
    "                                                                monitor='val_sparse_categorical_accuracy',\n",
    "                                                                mode='max')])\n",
    "model.load_weights(checkpoint_filepath)\n",
    "scores = model.evaluate(np.array(X_test), np.array(y_test), verbose=0)\n",
    "print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "acc_per_fold.append(scores[1] * 100)\n",
    "loss_per_fold.append(scores[0])\n",
    "fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1277ec9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
